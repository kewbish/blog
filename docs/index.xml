<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Yours, Kewbish - a collection of articles on tech and thought.</title>
    <link>https://kewbi.sh/blog/</link>
    <description>Latest Yours, Kewbish posts</description>
    <managingEditor>(Emilie Ma (Kewbish))</managingEditor>
    
	<atom:link href="https://kewbi.sh/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Hanky-Janky</title>
      <link>https://kewbi.sh/blog/posts/240303/</link>
      <pubDate>03 Mar 2024</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On mischief and a hacker&#39;s mindset.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p><a href="https://jvns.ca/blog/2022/03/08/tiny-programs/">Julia Evans</a> wrote a blog a while ago about writing tiny personal programs — the kind of thing where a website or service has some friction in behaving as you want it to, and you bust out some Python or Bash to wrestle it into compliance. Because the original site wasn&rsquo;t working as intended, these scripts tend to use features not intended for general consumption, since if the features were integrated into the main software you&rsquo;d probably not be writing the script in the first place. Some examples include manually inspecting web requests to hit the same internal API endpoint, or scraping HTML and parsing it with BeautifulSoup. As well, these scripts are usually written for a single user or maybe a small group of users, so it&rsquo;s reasonable to slap it together as fast as possible without much regard for its scalability or maintainability. If you only have a couple users, it&rsquo;s easier just to give them a detailed list of instructions and constraints (&lsquo;don&rsquo;t press the big red button until you&rsquo;ve typed into this text field!&rsquo;) than worry about handling edge conditions gracefully. When you see someone write a script like this, what words come to mind?</p>
<p>Two that spring to mind for me are <code>hacky</code> and <code>janky</code>: they&rsquo;re hacky, because they work around the limitations of what&rsquo;s presented, usually in an unintended way; and they&rsquo;re janky, because they&rsquo;re delicately cobbled together and fragile. I also find that <code>hacky</code> and <code>janky</code> both tend to be synonyms of <code>mischief</code>, and this sort of well-intentioned mischief and app misuse is what I&rsquo;d like to touch on today.</p>
<p>This janky mischief has a spectrum of seriousness. On one hand, you have Evans&rsquo; scripts, which mostly serve some real-world problems, like finding vaccine appointments. On the other, you have satirical (sorry, I meant very deeply serious) conferences like <a href="https://sigbovik.org/">SIGBOVIK</a> and <a href="https://programmingwithstyle.com/posts/howihackedmycar/">humorous stories on HN</a> that just hack for the sake of it. The stories I&rsquo;ll share in this post lie somewhere in between — my workarounds all do serve a genuine purpose, but I also find the way I went about implementing them very comedic<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>This is a post about my recent hacky hanky-panky and a hacker&rsquo;s mindset. You shouldn&rsquo;t do any of the following, in order to save time and have more confidence in your workflows, but maybe they&rsquo;ll inspire you to pull some hacky mischief yourself.</p>
<h2 id="copy-as-png">Copy as PNG</h2>
<p>I&rsquo;ve recently been building <a href="https://nested.name">NestedName</a>, a site to find <a href="https://en.wikipedia.org/wiki/Domain_hack">domain hacks</a> with your name. For example, it&rsquo;d help me find the domains <code>emil.ie</code> and <code>emilie.ma</code>, the latter of which I do own. I&rsquo;ve been planning for a soft launch and some outreach, so I&rsquo;ve been working on an animation for Twitter describing NestedName and its features as a little intro reel.</p>
<p>The sane thing to do would be to use a video recorder app, as my friend quickly pointed out. There are several tools that record your screen, then zoom in on your cursor and where you&rsquo;re typing to generate smooth, polished demo videos. But I didn&rsquo;t know of these beforehand, and anyways I wanted some specific animations in my video, so I thought I&rsquo;d just hand-animate it.</p>
<p>All my design for NestedName happens in Figma, so I thought I&rsquo;d look into plugins for animation within Figma so I could easily reuse design assets. I&rsquo;d already <a href="https://kewbi.sh/blog/posts/231231/">abused Figma for presentations before</a>, so I knew animations wasn&rsquo;t too far of a stretch. I was able to find a couple, including <a href="https://jitter.video/">Jitter.video</a>, <a href="https://www.figma.com/community/plugin/733025261168520714/figmotion">Figmotion</a>, and <a href="https://www.figma.com/community/plugin/889777319208467032/motion-ui-and-games-animation">Motion</a>. Jitter&rsquo;s free offering had a watermark, Figmotion was nice but wasn&rsquo;t able to animate between several frames, and Motion, while being the most intuitive, had a free tier with a 2s export limit, far too low for my ~20s goal. These tools also all relied on manually creating keyframes and adjusting animation durations, which was tedious and frustrating.</p>
<p><a href="https://canva.com">Canva</a> is another design tool I&rsquo;ve used. It boasts an impressive selection of community-created templates, useful for when I need an impressive-looking poster for a class without wanting to start from scratch. They also have a video editing tool and basic animations available: think &lsquo;pan&rsquo;, &lsquo;appear&rsquo;, and &lsquo;rise&rsquo;. After fighting various Figma plugins for an afternoon, I decided to just roll with whatever Canva had available and try animating with Figma instead.</p>
<p>Canva&rsquo;s free design tools are less powerful than Figma&rsquo;s though, since they&rsquo;re aimed at different markets. For one, Canva doesn&rsquo;t allow you to import custom fonts if you&rsquo;re not on their paid tier, and its font library, while extensive, also lacks the Google fonts that I&rsquo;m using with NestedName. A good idea at this point would perhaps to go back to find an appropriate screen recorder so I&rsquo;d be able to just record the NestedName interface and use Canva to edit on top of it. However, I decided a reasonable, rational, and clearly-thought-out alternative was to go into Figma, copy each text block as a PNG, and paste it into Canva as an image. I&rsquo;d then animate the individual textblocks as if they were text elements, and stitch the final animation together with Canva. This required a lot of exporting and copy-pasting: if you&rsquo;re ever in my boat, a good Figma shortcut to know is <code>Ctrl-Shift-C</code> for &lsquo;copy as PNG&rsquo;.</p>
<p>Canva&rsquo;s animation interface is more intuitive than manual keyframes, as it&rsquo;s mostly drag-and-drop and click-to-select for animations. This also means it&rsquo;s less powerful unless you&rsquo;re on the paid version, but even then the additional features are very limited.</p>
<ul>
<li>For one, you can&rsquo;t delay animations, so they all play in sequence at the start of the page. I wanted to delay some animations, though, so I&rsquo;d duplicate the page in Canva, set the first page&rsquo;s duration to be longer, and only apply the animation to the second page.</li>
<li>If I wanted to delay an animation after a page transition like a crossfade or wipe, I&rsquo;d create an empty interstitial page, set it to have a short duration of 0.3s, then have my main animated page.</li>
<li>Canva&rsquo;s animations on each page play in sequence following a heuristic from top down, from left to right. I had to rearrange some of my pages so the animation order would be correct, or otherwise use my workaround of creating several pages to animate one &lsquo;visual&rsquo; page.</li>
<li>You can&rsquo;t change the direction of certain animations on the free tier, so if you want to have an element fly in, it can only fly in from the left. Take this into consideration when laying out slides.</li>
</ul>
<p>On the whole, the animation experience was quite straightforward, and I found the point-and-click interface to be a better workflow than manually creating keyframes. Even if it required a lot of hacky text rasterization and animation tool misuse, you can&rsquo;t really tell in the final video. You can see the finished product <a href="https://twitter.com/nestedname">here</a> — while you&rsquo;re there, feel free to follow and stay tuned for more updates!</p>
<h2 id="githubdb">GitHubDB</h2>
<p>I wrote a <a href="https://github.com/kewbish/matter">static RSS feed aggregator</a> a few years ago, and as part of that project I wanted to add bookmarks. However, I wanted to avoid setting up another server as much as possible, because I was already using up all my then-free Heroku credits on running the CORS proxy for the site. Of course, I realized that I could just add a few endpoints to the CORS proxy app to handle bookmarks as well, but I also wanted to avoid setting up my own authentication as much as possible, which would have required setting up MongoDB or another free database provider<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Too much effort, I reckoned.</p>
<p>Clearly, though, outsourcing authentication to a GitHub OAuth app was much easier. Then, I could just store my bookmarks as comments on a GitHub issue in the same private repo I already use to store my notes, so my bookmarks would be accessible from GitHub as well! <a href="https://twitter.com/fortysevenfx/status/1343587407799738368">There&rsquo;s even prior art</a> for the idea, though I came up with it separately.</p>
<p>Using GitHub issue comments to store and read bookmarks from is perhaps my most egregious misuse of GitHub, but I&rsquo;ve also used it for sharing unlisted files and portfolios. Last year, I was applying to research assistant positions at my university and needed to submit a portfolio of prior work. I could have set up a separate unlinked portfolio page, but I also wanted to host several large demo videos, and while I could do that with Netlify, I wanted to send the portfolio ASAP rather than fiddling with styling another page. So, I threw everything into a private, unlisted Gist and sent the link to my professor. Little known fact: Gists can be cloned and committed to just like normal Git repos, so while the Gist interface doesn&rsquo;t let you upload binary files directly, you can just push them from the command line.</p>
<p>Recently, I&rsquo;ve also been considering using GitHub Mobile as a mobile text editor app for my blog posts. I make this arbitrary delineation between my time at home: &lsquo;upstairs&rsquo; being work in my office, and &lsquo;downstairs&rsquo; being time in the living room, maybe with a tablet. I&rsquo;d like to better utilize some of my &lsquo;downstairs&rsquo; doomscrolling time, so I&rsquo;ve downloaded GitHub mobile and plan to use it to read through and edit some of my drafts, which are themselves committed into my private notes repo.</p>
<p>I have this concept of &lsquo;free-driven development&rsquo;: making software architecture or process decisions motivated purely on keeping everything within the free tier of service providers. Using GitHub as a free, private database was one such decision. I think this concept also gels well with the hacker&rsquo;s mindset of finding workarounds to artificial pricing limits.</p>
<h2 id="smtp-please">SMTP, Please</h2>
<p>When I first bought the <code>kewbi.sh</code> domain, I wanted to set up email so I could send and receive emails from a nice <code>hey@kewbi.sh</code> address. Receiving email to this address was easy enough with mail forwarding from Namecheap, but sending mail was a little more complicated. I didn&rsquo;t want to sign up for Google Workspace, which is paid, and I also didn&rsquo;t want to switch to another email provider, which would also likely be paid.</p>
<p>However, there&rsquo;s a relatively well-known workaround to send mail from another domain via the Gmail SMTP servers. It involves generating an app password for the Gmail account you want to use to send emails from, then selecting the Gmail SMTP servers in the configuration and and using that app password as authentication. You can read more about it <a href="https://emailforwardmx.com/knowledgebase/14/Send-mail-with-your-domain-using-Gmail.html">here</a>. I&rsquo;m convinced this probably isn&rsquo;t against ToS, but I&rsquo;m also very aware it&rsquo;s not supported and is likely unintended. Like with most of the other workarounds above, I&rsquo;m relying on undocumented behaviour, which I realize could change any time, taking my whole workflow with it. But if that happens, I&rsquo;ll just hack together another solution — no biggie.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Part of being a hacker is this ability and willingness to bend (software) boundaries and go beyond what you&rsquo;re given at face value. A friend once said they had a thesis that the world is malleable, and I think that&rsquo;s even more so for self-described hackers. We have the skills, or determination to pick up the skills, to navigate beyond what&rsquo;s expressly presented: to misuse Canva, GitHub, Gmail, and more. Even if it&rsquo;s janky, I think that hacky workarounds have their own charm.</p>
<p>An example of free-driven development in the real world: I recently soft-launched <a href="https://nested.name">NestedName</a>, a site to help you find unique domains with domain hacks and unusual TLDs. I think this blog&rsquo;s domain (<code>kewbi.sh</code>) is pretty clean, and I own my full name as a domain (<code>emilie.ma</code>) as well. Quirky domains are something that I nerd out about often, so I wanted to make a site to help folks find them too — check it out, if you haven&rsquo;t already.</p>
<p>I run NestedName for completely free, and there&rsquo;s a fair bit of hackiness behind the scenes. For one, the frontend, dynamic open graph image generation function, DB, and backend are each hosted on separate providers (Cloudflare Pages, Vercel, Supabase, and Fly.io, respectively). For another, I was using an awkward heuristic from the free Cloudflare DNS API to determine if a domain was taken, which proved to be insufficient, as I kept receiving messages about during launch. None of the code follows good design patterns, and when adding new features I try to bodge them in with as little refactoring as possible. It&rsquo;s a fairly small codebase, so it&rsquo;s been feasible so far, and it&rsquo;s been nice not to have to think too hard and just keep shipping.</p>
<p>I find myself dealing with perfectionism and a desire to &lsquo;do things right&rsquo; sometimes. A little mischief around what&rsquo;s possible to make happen tends to take the edge off some of that navel-gazing. I think the hacker mindset embodies this almost rebellious attitude towards the prescriptivism and limits of software: it brings some of the fun back to building. It&rsquo;s just plain fun to dive deep into odd backward compatibility details or be proud of yourself for figuring out a complicated, multi-step, workaround not knowing that another tool exists. As corporate, walled-garden software has grown entrenched in every aspect of our lives, I think we need a little more hanky-panky and creativity in how we (mis)use it, and I hope this collection of mischievous ideas has inspired you to try breaking some limits and exploiting little-known features yourself<sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I&rsquo;ve been reading about design patterns lately for my Software Engineering class, and I take no small amount of satisfaction in my small rebellions against the prescribed best practices. Cohesion, avoiding duplicated code, and refactoring magic numbers? Who needs that?&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Assuming good faith, of course!&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>The QoS of QS</title>
      <link>https://kewbi.sh/blog/posts/240225/</link>
      <pubDate>25 Feb 2024</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On self-tracking UX and how we can improve it.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I came across <a href="https://ericchiang.github.io/post/spotify/">this post by Eric Chiang</a> recently. They downloaded their past ten years of Spotify listening data into a big ZIP and conducted their own version of Spotify Wrapped. They graphed their most listened-to artists, how those artists changed over time, their listening time distribution across the day, and their favourite albums from a particular year. It looks like a fun time capsule and nostalgia trip — the perfect application of some hacky scripting skills.</p>
<p>The post ends off with a call to explore your own data a little more, which got me thinking about the work Chiang did to retrieve all their data, write scripts to process it, and visualize it. All these steps are manual processes: if you want to do something like this, you&rsquo;d better have some time on your hands and a hankering to wrangle with Matplotlib.</p>
<p>You should also have some idea of what exactly you want to find or visualize — otherwise, wading through the hundreds of thousands of raw data points without a goal in sight gets overwhelming. Clearly, as seen on the <a href="https://news.ycombinator.com/item?id=39350541">HN discussion</a>, folks do have a lot of ideas for what they&rsquo;d like to visualize (e.g. finding one-hit wonders or songs that are correlated with some other data dimension like the weather). What&rsquo;s the barrier, then? Why aren&rsquo;t we seeing everyone&rsquo;s unique graphs?</p>
<p>Right now, extracting your data from cloud services like Spotify, YouTube, GoodReads, or others requires a lot of <em>effort</em>. Services like Spotify that provide a one-click download button are already making it easier, compared to having to roll your own scraper, but there&rsquo;s still activation energy in seeking out your data and taking the time to visualize it. Because the bottleneck is in the data, I think people tend to end up collecting the data for a particular visualization in mind, rather than the other way around.</p>
<p>But I think that&rsquo;s backwards — to me, it makes more sense to explore your data with visualizations to aid you, unless you have a particular research question in place. For folks who&rsquo;re just trying to get a sense of their data without a specific goal,</p>
<p>This is a post about navigating your data, the Quantified Self community, and how we can make data spelunking more compelling.</p>
<h2 id="quantified-self">Quantified Self</h2>
<p><a href="https://quantifiedself.com/">Quantified Self</a> is a movement broadly centered around <em>tracking</em>. Large swathes of the community are focused on health tracking: one&rsquo;s weight, bodyfat percentage, number of calories burned per day. However, other types of tracking are common: usage of time, mood, carbon footprint due to flights taken, and so on.</p>
<p>People interested in self-experimenting (or inspired by the pretty result graphs) tend to be drawn to QS: it presents some order in our lived experiences, and gives us levers to continue improving our lives. I recently wrote about <a href="https://kewbi.sh/blog/posts/240218/">checkpoints</a>, and I think QS data collection is the extreme manifestation of checkpoints. Collecting tens or hundreds of data points on ourselves a day gives us something to look back on and helps visualize the deltas between timesteps.</p>
<p>QS took off with the adoption of IoT devices and trackers, like the popular FitBit or Apple Watch. These made health data salient and readily available, for the first time. With the advent of SaaS companies and their general trend towards walled gardens, though, our data is becoming more inaccessible and opaque.</p>
<h2 id="quality-of-service">Quality of Service</h2>
<p>I&rsquo;d say the user experience of quantified self tracking is generally very poor. Take the Spotify example: Chiang had to submit a request on a form probably created solely for compliance, then wait up to thirty days for their data to be processed and returned to them. Then, they had to comb through the data to identify points of interest and write a whole bunch of visualization scripts.</p>
<p>This was for a relatively open data faucet, and a single app at that, though. There are folks who&rsquo;ve written whole tool libraries to process and collate every aspect of their lives. <a href="https://beepb00p.xyz/hpi.html">Karlicoss&rsquo;s HPI</a> package brings together their browser history, texts, health data, TODOs, and more into a nice Python interface. I particularly like their motivation for the project:</p>
<blockquote>
<p>[O]nce the data is available as Python objects, I can easily plug it into existing tools, libraries and frameworks. It makes building new tools considerably easier and opens up new ways of interacting with the data.</p>
</blockquote>
<p>They emphasize the ad-hoc-ness and interactivity that I think the QS experience should be like. Our data are artifacts that we created, and I think we should be able to seamlessly pick and choose from what we&rsquo;ve made to augment and inform what we&rsquo;ll continue to do.</p>
<p>On the other hand, I understand that making straightforward ways to access raw user data probably isn&rsquo;t the best use of engineering resources for a business, who&rsquo;d rather be building their core product instead. There are few who are motivated enough to want their data, so to a business a rarely-used &lsquo;Export my data&rsquo; form suffices.</p>
<p>If most apps won&rsquo;t support the extensive data tracking and collation QS relies on, then, what will? The answer, in practice, is a spreadsheet. Julian Lehr <a href="https://julian.digital/2020/02/23/my-quantified-self-setup/">wrote about their Airtable-based setup</a>, and Felix Krause <a href="https://krausefx.com//blog/how-i-put-my-whole-life-into-a-single-database">wrote about their Telegram bot → SQL database workflow</a>. Both have automated aspects of their data collection based on publically available APIs, but both also have some sort of manual update habit.</p>
<p>In some sense, bringing all your life&rsquo;s data into spreadsheets is the opposite extreme of keeping it all locked away in some SaaS: it&rsquo;s now extremely easy to process and pull into other visualizations or projects, like Karlicoss&rsquo;s work. The user experience is intuitive, though decidedly less captivating than most aesthetic tracker-specific apps.</p>
<p>In my ideal world, we wouldn&rsquo;t have to be explicitly collecting all of our own data: it&rsquo;d export itself, and we&rsquo;d be able to access it anytime from some central, private store. There&rsquo;d be visualizations automatically generated from data<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, reminders and ideas for trends that were detected, and more straightforward data connections between apps. But, for now, spreadsheets are a start.</p>
<h2 id="conclusion">Conclusion</h2>
<p>To me, current QS tools feel clunky, clinical, and both overwhelming and underpowered. However, I think reframing QS as an inquisitive and explorative activity can help us design better interfaces and processes for it. As well, viewing it through a lens of nostalgia and rediscovery makes for some interesting ideas. I once built <a href="https://github.com/kewbish/phasis">a tool</a> to scan through your notes in a Git repository and resurface notes that you hadn&rsquo;t edited in a while or reflected on, like spaced repetition for your thoughts. While the data I was working off of was less granular than daily health updates and relied on the heuristics available in Git history, this data was also collected <em>ambiently</em>, unlike today&rsquo;s QS tooling.</p>
<p>QS ties into many of my thoughts on <a href="https://kewbi.sh/blog/posts/211114/">metadata</a> and <a href="https://kewbi.sh/blog/posts/210124/">personalizable software</a>, and it&rsquo;s no surprise to me that the ideas that immediately come to mind revolve around richer interactive data formats and <a href="https://kewbi.sh/blog/posts/231126/">translating between data sources</a>. As I mentioned in the introduction, self-tracking also speaks to me as a form of reflection on how I&rsquo;ve changed, but in a quantitative format that&rsquo;s harder to handwave. While I won&rsquo;t be creating a <a href="https://howisfelix.today/">full public life dashboard</a> anytime soon, I&rsquo;m inspired by that level of self-understanding and dedication to making some sense of the strange way of being we call life.</p>
<p>I used to create QS-level stats on my writing output on this blog, and in a now-unpublished post, even stats on the reading I&rsquo;d done over a year. I don&rsquo;t compute any metrics on my writing anymore, since I think it&rsquo;d be fairly disappointing to see my few-and-far-between posts. I&rsquo;d like to change that though: I think lately my perfectionism has been leading me to take this blog a little more seriously than I should. I&rsquo;d like to start writing smaller, less polished posts more frequently, as opposed to forcing out 2k-word-long vomits whose core theses I get too attached to but can&rsquo;t seem to express properly. Instead, here&rsquo;s to the <a href="https://austinkleon.com/2020/12/10/quantity-leads-to-quality-the-origin-of-a-parable/">pottery parable for prolific work</a> and Alice Maz&rsquo;s recent reminder to me that <a href="https://alicemaz.substack.com/p/you-can-just-do-stuff">I can just do stuff</a>!</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Perhaps in the era of ChatGPT, automatically creating little scripts or visualizations like this might be feasible.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Checkpointing</title>
      <link>https://kewbi.sh/blog/posts/240218/</link>
      <pubDate>18 Feb 2024</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On finding reminders to reflect.</description>
      <content:encoded><![CDATA[<p>Checkpoints are ubiquitous in games. I grew up playing <a href="https://roblox.com">Roblox</a>, and a popular genre of games I&rsquo;d play was &ldquo;obbies&rdquo;, or obstacle courses<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. These had hundreds or thousands of stages, where your blocky character would leap from precariously angled platform to platform. You&rsquo;d dodge the &rsquo;lava&rsquo; tiles and the rotating Wipeout arm, holding your breath until you landed safely on the spawnpoint, emblazoned with a sawblade icon. Sometimes, you wouldn&rsquo;t quite make it: you&rsquo;d clip the edge of an obnoxiously saturated red block. You&rsquo;d teleport back to the previous checkpoint, groan, and start delicately maneuvering again.</p>
<p>Checkpoints in games were primarily used for saving the current state of the game to disk so the player can load it again in the future. I think most people expect savepoints in games nowadays. Games without checkpoints, like Bennett Foddy&rsquo;s <a href="https://en.wikipedia.org/wiki/Getting_Over_It_with_Bennett_Foddy">Getting Over It</a> feel extra frustrating: you make all this progress, only to not have any record of it and no way to get back to where you were before.</p>
<p>Productivity and mindfulness habits like journalling and weekly reviews bring video game checkpoints into our everyday lives. When you think back to the past year, what does your mind land on? Folks naturally fall back on the start and end of projects, new adventures, and major milestones as a sort of personal checkpoint in their life.</p>
<p>I think it&rsquo;s fairly common for people to get caught up in the swing of things, jump from task to task, forget the wins they&rsquo;ve earned, and end up feeling like they haven&rsquo;t made any progress towards their goals and intentions at the end of the year (itself another checkpoint). Explicit checkpoints serve to highlight these landmarks, even if they&rsquo;re not as grandiose as what one set out to accomplish. Just like Roblox obby spawnpoints, checkpoints give us a chance to appreciate the progress we&rsquo;ve made and create opportunities for reflection. Checkpoints let us stop and <em>think</em> a little, before continuing to move forward.</p>
<p>This is a post about framing the ways we self-reflect as checkpoints. While forcibly gamifying productivity is usually a bit of a gimmick, the concept of game checkpoints is one that I think clearly maps to the way our minds center around past milestones.</p>
<h2 id="checkpoints-as-deltas">Checkpoints as Deltas</h2>
<p>Intuitively, checkpoints are like landmarks that demarcate single, instantaneous moments in time. The New Year might be a checkpoint. Graduation, finding your first job, or hitting a milestone of newsletter subscribers might be as well. They&rsquo;re a natural way for your brain to keep track of time and organize events: checkpoint X happened, then next checkpoint Y, and so on. However, I also see checkpoints as a way to visualize progress. To me, checkpoints are more about recalling the deltas in between checkpoints — about reflecting on the journey, not the final destination.</p>
<p>If you&rsquo;ve ever visited the visual, more artsy, Bullet Journal community, you&rsquo;ll know about habit trackers. The Bullet Journal method is a popular way to organize your planning, and habit trackers are a common extension to the core &lsquo;method&rsquo;. Most folks create grids or bar charts each month with a row for each habit to track and columns for each day, then find creative ways to decorate their tracker throughout the month. Many have noted that the visual cues of the tracker and its presence close to their daily planning pages remind them to complete their habit, if only so they can have the fun of completing a tangible marker of progress. When you&rsquo;re in between checkpoints in Roblox obbies, you want to keep going successfully through to the next checkpoint. With bullet journalling, habit trackers play the same role: people are motivated to make it to the next checkpoint, especially with such a visible reminder each day. Habit trackers serve as progress bars IRL, and the process of creating a new tracker for each month&rsquo;s setup acts as a checkpoint.</p>
<p>Steph Ango&rsquo;s <a href="https://stephango.com/40-questions">40 questions to ask yourself every year</a> is another example of using checkpoints to reflect on deltas. I particularly like question 18: &ldquo;Compared to this time last year, are you: happier or sadder? Thinner or fatter? Richer or poorer?&rdquo; While these are shallow, arbitrary binaries, these questions tacitly invite us to think about the events along the year that caused us to turn out happier (or sadder) and why. Some questions are also rather targetted (question 26: &ldquo;What was your greatest musical discovery of the year?&rdquo;) so your answer might not be from the last few months. I find that I typically suffer from recency bias when reflecting, so questions like these helps to zoom out from the hot new discoveries fresh in my mind from the later bit of the year, to think about my mindset from the beginning of the year. Ango&rsquo;s call for us to complete these questions each year makes the yearly habit a checkpoint and opens up opportunities to compare your life delta across years.</p>
<h2 id="checkpoints-as-interrupts">Checkpoints as Interrupts</h2>
<p>A core idea of Daniel Kahneman&rsquo;s <em>Thinking, Fast and Slow</em> is that our brains operate in two tracks: System 1, the impulsive, fast-acting mode that handles emotional reactions and quick decisions; and System 2, the slow, logical mode that activates when we do deeper thinking and visualize mental models. Our mind&rsquo;s default track is System 1, and part of what Kahneman shows is that it takes some effort to engage System 2. For example, our brains often operate with inherent stereotyping (System 1), and we need to take conscious action and be aware of our biases in order to treat people fairly (System 2).</p>
<p>Productivity checkpoints, like the reflection activities mentioned above, are opportunities for this context switching to occur. It&rsquo;s easy to run in System 1 all the time, but we need some System 2 thinking every so often to learn from our past mistakes. To borrow my operating system class&rsquo;s terminology, checkpoints are hardware interrupts to let our System 2 software run. Checkpoints force a stricter delineation between your typical state of action and a reflective state of mind. Because checkpoints are like landmarks, they&rsquo;re times for us to catch our breath, spinning down System 1 for a bit, which gives System 2 an opportunity to jump in.</p>
<p>Another common productivity habit is the weekly review. I most like Ben Kuhn&rsquo;s <a href="https://www.benkuhn.net/weekly/">take on the process</a>: reading life advice essays that resonate and motivate you, review what happened over the week since the last review (a checkpoint!), then write on a list of impromptu and recurring prompts. Reviewing your progress and reminding yourself about your intentions and goals week-to-week is useful, since otherwise you often forget about your resolutions and get caught up easily in the daily monotony. Even small, granular checkpoints like weekly reviews can be useful — checkpoints aren&rsquo;t just for yearly, exhaustive, or otherwise mentally &rsquo;expensive&rsquo; reflection.</p>
<p>Making checkpoints a habit curiously allows you to leverage your System 1 to shut itself down. By making checkpoints a weekly, recurring process, your System 1 can start to automatically internalize that it needs to let your System 2 get a word in edgewise. This is also why habit trackers seem so effective for folks: filling in the habit tracker becomes a habit, so it feels odd if you haven&rsquo;t completed the habit and can&rsquo;t tick the box.</p>
<h2 id="checkpoint-creation">Checkpoint Creation</h2>
<p>While I was talking through the idea of this post with a good friend, they asked if checkpoints were encountered or actively created. I think there are examples of both. Birthdays, the start of a new quarter, and New Year&rsquo;s are sort of societally imposed checkpoints. You don&rsquo;t choose to pass them by: they&rsquo;re stamped into your calendar as givens. These types of checkpoints are not actively initiated, but are still just as valid for checking in with yourself. As a bonus, their socially recognized nature makes you more likely to be in a thoughtful mood, making it less effortful for your System 2 to take over to reflect.</p>
<p>On the other hand, creating checkpoints via productivity habits for yourself is intentional. These require more activation energy to get started with and to build the habit for: you&rsquo;re doing it for you, and no one is reminding you to commit.</p>
<p>One unique activity I see as a &ldquo;created checkpoint&rdquo; is applying to jobs and programs. I have a personal thesis that people should submit at least one application per year (swap out &lsquo;one&rsquo; and &lsquo;year&rsquo; for the frequency appropriate to your current life phase). Every time I fill in an application for something, I get to really dial in on my values and how they&rsquo;ve changed since the last form I filled out. I take the opportunity to &ldquo;Tell me about yourself&rdquo; to think about what makes me <em>me</em> now, what made me <em>me</em> previously in my last application, and what&rsquo;s changed in between. I add new lines to my resume, remove old ones to make room for new achievements, and reword bullet points to better match what I&rsquo;m interested in now. Each application is one of my checkpoints, and even if I don&rsquo;t get to see what I wrote ever again, I still find it a useful exercise in recalling how I&rsquo;ve grown over time. If you choose to create more reflection checkpoints via this route, a nice side effect is that you&rsquo;ll likely get access to some new resources and opportunities along the way.</p>
<p>Creating checkpoints should be done carefully and mindfully, though. Some checkpoints are more emotionally charged than others. For me, career-focused applications are a delicate balance: I try to be proud of what I&rsquo;ve achieved recently, but find it hard to write about things effectively. (&lsquo;Effectiveness&rsquo; is also subjective here, and depends what my intention for the checkpoint is.) It&rsquo;s hard because you have all the vibes and vague ideas of personal missions and ambitions in your head, but reifying that into words on paper is challenging. For opportunities I&rsquo;m really excited about, I also naturally focus on my successes and spinning my experiences a certain way. If I fill in a form and realize I haven&rsquo;t really done anything new, or that there haven&rsquo;t been any recent relevant achievements, that can feel a little disappointing. This all puts some more stress into the process, which really shouldn&rsquo;t be what checkpoints are about.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I think checkpoints speak to me especially because <a href="https://kewbi.sh/blog/posts/210725/">I&rsquo;m so drawn to lists and neat organization</a>. Framing my personal productivity habits as checkpoints helps me compartmentalize and create structure on which I can reflect. I surround myself with a lot of busy people — there&rsquo;s a whole other discussion to be had on what the point of all this busyness is, but busy people in particular need checkpoints. I know all too well that being busy makes me go into whack-a-mole mode, where I&rsquo;m just putting out fires for the day to day without thinking about my overarching goals. Little checkpoints, like trackers, weekly reviews, and job applications, bring a reminder of intentionality back to my life.</p>
<p>Maybe I&rsquo;ll amend my thesis from above: people should create at least one checkpoint each year, just for the sake of having a checkpoint. Checkpoints should be about pushing yourself to break out of your usual cycles of work without taking yourself too seriously. Reflect on how you&rsquo;ve changed and what&rsquo;s fueled that change since the last checkpoint, and take a pause. Then, just like in the Roblox obbies of my childhood: keep going, keep growing, and keep making your way onwards to your next checkpoint.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>When I was in elementary school, we had to share laptops in pairs, so obbies were a way both students could play at the same time. We&rsquo;d have one of us manning the spacebar to jump and the other controlling the character&rsquo;s WASD movement. It made for good bonding.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Presenting in Figma</title>
      <link>https://kewbi.sh/blog/posts/231231/</link>
      <pubDate>31 Dec 2023</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On NeovimConf 2023 and making slides in Figma.</description>
      <content:encoded><![CDATA[<p>I gave a lightning talk recently at <a href="https://neovimconf.live/">NeovimConf 2023</a>, sharing a bit about my personal notetaking system in Vim. The content of the talk was similar to my previous <a href="https://kewbi.sh/blog/posts/210815/">A Plaintext Zettelkasten</a> post, with less Zettelkasten theory and more Vim keybinds. The conference was streamed live on Twitch, and I got to chat a bit with folks while watching my (prerecorded) talk. Here&rsquo;s the embed:</p>


<div style="display: flex; justify-content: center; margin-bottom: 1em">
	<iframe width="560" height="315" src="https://www.youtube.com/embed/1a6AEJxH_Dk?si=KuoX7d_z8oiCxX96" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>


<p>I&rsquo;d highly recommend checking out some of the other talks — the talk playlist will be updated <a href="https://www.youtube.com/playlist?list=PLhlaLyAlbLlr-usEauWLPy4O2ggAvZuKl">here</a>.</p>
<p>People seemed to like my setup and appreciate how I nerded out over it, which was heartwarming<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I also got some good feedback on my slides&rsquo; aesthetic (you can see them in the video) and a few questions on how I made them.</p>
<p>This is a short post on creating presentations in Figma, with a few links to resources I&rsquo;ve used that might make your design experience a little easier.</p>
<h2 id="why-figma">Why Figma?</h2>
<p>I designed and exported them all in Figma, which I think is a fairly unconventional use for the tool. I&rsquo;ve previously done my Directed Studies (a research course) <a href="https://gist.github.com/kewbish/fcf9f3e4b919a3cb1fa3c889611ce9e2">slides in Figma</a><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> and had good experience doing so. Figma is already the defacto design tool for many web developers, so it&rsquo;s a good choice for presentations too if you have Figma components or libraries you want to reuse.</p>
<p>I don&rsquo;t use traditional presentation tools like Powerpoint or LibreOffice Impress, since I find it hard to get started with a blank (or very generic) slate. In the past, I&rsquo;ve used Canva for small presentations like these since it has such a vast library of templates — the little things like extra clip art or background assets really makes slides look polished.</p>
<p>I tried Figma for slides recently, first for my Directed Studies slides, then for this lightning talk, because I&rsquo;ve had pre-existing assets in Figma that I wanted to reuse in high quality in my presentations. For my Directed Studies project, I had diagrams from our paper; for my lightning talk, I wanted to use the branding elements from my website, like my gradient and sparkles. Figma makes it easier to design things more precisely than Canva with autolayout, and it&rsquo;s nice to be able to pull from my Figma library without converting to a flat-file image format and back.</p>
<h2 id="workflow">Workflow</h2>
<p>Throughout this post, I&rsquo;ll be using my Directed Studies slides as a running example. Here&rsquo;s what my Figma file looked like:</p>
<figure><img src="/img/231231/figma-overview.png"
         alt="Figure 1. Slides overview"/><figcaption>
            <p><em>Figure 1. Slides overview</em></p>
        </figcaption>
</figure>

<p>You can create slides with Frames in Figma. Click the grid Frame icon, or press <!-- raw HTML omitted -->F<!-- raw HTML omitted -->. Select <code>Presentation &gt; Slide 16:9</code>.</p>
<p>I like to create a base frame for my slides, so I can have a consistent background. Once you&rsquo;ve designed this, you can select frames and <code>Ctrl-C</code> / <code>Ctrl-V</code> to place them in series. Figma lays them out automatically in a nice line, which makes scrolling through a presentation easier. Creating slides out-of-order is a little more annoying, since you&rsquo;ll have to drag all the frames into line, so I tend to work through my slides in-order.</p>
<p>After I&rsquo;m done with my slides, I use Figma&rsquo;s Prototype tool to wire the transitions up. You can create a new Flow by clicking on your title slide frame, then right-clicking and selecting &lsquo;Add Starting Point&rsquo;. Then, in Prototype mode, you can hover over the side of a frame to wire it to the next slide. I set each transition to &lsquo;On click, navigate to [frame for next slide], instant&rsquo;. There are some animation options available though, like wipes, dissolves, and notably, Smart Animate, which smoothly animates between objects duplicated across frames. This part is a little tedious, but I haven&rsquo;t found a plugin that&rsquo;ll do it for me yet.</p>
<figure><img src="/img/231231/slide-transition.png"
         alt="Figure 2. Transitioning between slides"/><figcaption>
            <p><em>Figure 2. Transitioning between slides</em></p>
        </figcaption>
</figure>

<p>Finally, you can present with the Play button in the upper-right hand corner. You can move between slides with the arrow keys, as in Powerpoint.</p>
<figure><img src="/img/231231/press-play.gif"
         alt="Figure 3. Demoing the presentation"/><figcaption>
            <p><em>Figure 3. Demoing the presentation</em></p>
        </figcaption>
</figure>

<p>You can also export each slide as a PNG by selecting all your frames and heading to <code>Design &gt; Export &gt; PNG &gt; Export X layers</code>. I used this in my NeovimConf talk, as I recorded my webcam separately from my slides.</p>
<h2 id="miscellaneous-tips">Miscellaneous Tips</h2>
<p>For in-slide animations, I duplicated a slide multiple times and added Prototype transitions between each subpart of the slide. I used this for animating bullet points that appeared on each keypress. You might be able to implement this more efficiently with Variables, but I typically only have at most three subparts per slide, so I haven&rsquo;t explored this yet.</p>
<figure><img src="/img/231231/inslide-transition.png"
         alt="Figure 4. Not a very DRY presentation"/><figcaption>
            <p><em>Figure 4. Not a very DRY presentation</em></p>
        </figcaption>
</figure>

<p>For page numbering, I&rsquo;ve used <a href="https://www.hypermatic.com/pitchdeck/">Pitchdeck</a>, a Figma plugin, in the past. You can add the plugin normally via the Figma Components menu, but beware some features like PDF export and such are paywalled. Pitchdeck is quite fully-featured and appears to do the in-slide animations I&rsquo;d be looking for, but I found their interface unintuitive and a little overpowered for my needs.</p>
<p>To add slide numbering, open Pitchdeck and click the Page icon in the upper-left of the plugin window. Toggle &lsquo;Enable auto slide numbers&rsquo; to on. You can customize slide numbering styling here as well, which I think is a nice way to tie into the rest of your presentation branding. If you&rsquo;re using my janky method of duplicating slides for in-slide animations, Pitchdeck will see each individual frame as a new slide to number, so I resorted to deleting everything except the last subpart of my animation, running the auto-slide numbers, then recreating my animation. Try to add slide numbers once at the very end if you forsee this happening.</p>
<figure><img src="/img/231231/pitchdeck-numbering.png"
         alt="Figure 5. Adding slide numbering in Pitchdeck"/><figcaption>
            <p><em>Figure 5. Adding slide numbering in Pitchdeck</em></p>
        </figcaption>
</figure>

<p>A parting tip I&rsquo;d give is that it really helps if little things like asset theming ties in well together. I was able to reuse the metallic gradient I use for titles on this blog (see this article header) for my titles as well as for my webcam frame and its decorations<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I&rsquo;m far from a Figma power user, but it&rsquo;s fairly easy to create cohesive presentations in Figma even with basic tools. I&rsquo;d love to reuse my NeovimConf template for future talks (with different content, of course!)</p>
<p>Speaking of speaking, I&rsquo;d like to apply for more opportunities in 2024. Writing and rehearsing my NeovimConf talk was a great learning experience in terms of Vim content, even though I&rsquo;d already done quite a bit of tinkering myself, not to mention very validating to get to chat with other Neovim-adjacent folks and be able to share a bit about my unique workflows. I have a lot to learn in terms of storytelling and talk structure — I got feedback from a friend mentioning how they thought I was listing off keymaps without showing how they fit together well in a system. Figuring out how to explain things you&rsquo;re passionate about in an accessible way is trickier than it seems, especially since you have all the pictures and mental models in your head and it&rsquo;s easy to assume others do too. Public speaking is also far out of my comfort zone. This was a pre-recorded talk, but I&rsquo;d like to challenge myself to give something live if I have the opportunity.</p>
<p>Thank you again to the NeovimConf team for putting together and hosting such a fun conference! I met plenty of fellow Vim nerds and learned many fun tricks, and all in all had a great time. Can&rsquo;t wait to rewatch the talks and see what NeovimConf 2024 holds!</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I will try not to fangirl too hard over the fact that the <a href="https://www.youtube.com/c/theprimeagen">Primeagen</a> said, and I quote: &ldquo;this notetaking stuff is pretty dang cool&rdquo;.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Did you know that Gists on GitHub are just like full repositories? You can <code>git clone</code>, commit other files, and push to them. The default Gist web UI doesn&rsquo;t allow for uploading binary files, so I used this workaround to host my slides in a Gist repo.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>You can click any element, go to <code>Fill &gt; Styles [the four dots icon] &gt; +</code> to copy an element&rsquo;s fill for reuse. This saved a lot of time compared to having to copy-paste fills between everything.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>End-Of-Life</title>
      <link>https://kewbi.sh/blog/posts/231224/</link>
      <pubDate>24 Dec 2023</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On bitrot, deprecation, and deletion.</description>
      <content:encoded><![CDATA[<p>I&rsquo;ve been thinking about mortality and longevity recently. Today, I&rsquo;d like to think about durability of our data, the lifespan of the websites we rely on, and the process of software reaching End-Of-Life.</p>
<p>A natural final destination for software is deprecation and deletion. Sure, some mission-critical software will stay in use for decades to come, but even the essential tools of the 70s have been replaced just fifty years later. This is understandable, since computer science is such a young field, but during this evolution, I&rsquo;m sure many lines of BASIC, Pascal, and all those languages now regarded as ancient have been wiped and lost to time.</p>
<p>There are initiatives that aim to prevent or delay that from happening. The <a href="https://archive.org/">Internet Archive</a> is perhaps the most well-known example of this I can think of. The <a href="https://archiveprogram.github.com/arctic-vault/">GitHub Arctic Vault</a> program similarly strives to preserve current-day code as far into the future as possible. In 2020, all active public repos were archived into an Arctic vault, deep in the permafrost. I&rsquo;ll note, though, that GitHub&rsquo;s own site points to the possibility of climate change affecting the storage site (albeit only a thin layer of the permafrost under which the vault lies) among other factors.</p>
<p>Even if our data far outlasts us, is there value in holding onto it beyond historical curiosity? I think sentimentality can apply to software too. We all have childhood memories that have deeply affected us, so it makes sense that our data and the software we hold dear would as well. In this post, I&rsquo;ll primarily discuss personal data and websites, since I&rsquo;ve seen more examples of them experiencing this slow EOL, but there are parallels to be drawn with binary software and hardware as well.</p>
<p>It&rsquo;s painful to watch things we care about fade into obscurity, then stop working or lack support, then enter the digital ether. Same goes for people. Just as we reflect on the impact of those who have passed away on our own lives, I think it&rsquo;s interesting to think about how the makeup of our toolkits will shift as software hits its EOL.</p>
<h2 id="elementary-my-dear-watson">Elementary, my dear Watson</h2>
<p>I named my first laptop Watson. I got it in the summer before sixth grade, and used it almost til my senior year of high school. The summer before I started high school, I dual-booted Watson (originally running Windows) with Linux, and I quickly turned to using Linux daily over Windows.</p>
<p>However, at some point after I dual-booted with Linux, my Windows became completely sluggish. Logging in would take about three minutes. When it&rsquo;d finally load, I&rsquo;d get a black screen with just a cursor, and even the shortcuts to open Task Manager weren&rsquo;t working.</p>
<p>About a year ago, my dad&rsquo;s laptop, a very old Toshiba bought not long after I was born, also started slowing down. I volunteered my old laptop, Watson, for him to use, and set to getting it ready for him.</p>
<p>I was trying to fix the Windows partition of my system while only reformatting what was necessary. I&rsquo;d transferred over the contents of my Linux partition to my new device, so there was no sentimentality there, but there were still some old screenshots and game files on the Windows side that I&rsquo;d have preferred to keep. Over the course of a month, I tried to fix Windows without wiping everything. I&rsquo;d never looked at those files after switching to Linux, and I don&rsquo;t know why I was so attached to them. In the end, in a Herculean display of rationality, I wiped it all and factory reset my laptop. It works now, and my dad&rsquo;s happy with his &rsquo;new&rsquo; machine. I still think about what I&rsquo;ve lost in that process though — the files that were on that drive that I&rsquo;ll never get back.</p>
<p>Computers have afforded both digital abundance and digital hoarding. There are few reasons not to just hang onto everything, and it feels <em>wrong</em> to let files go. Just buy a hard disk and copy files over, regardless of if you&rsquo;ll look at them again. There&rsquo;s a niggling voice in my head wanting to keep things around for the sake of some nebulous &lsquo;future me&rsquo;. There are folks that seem to have similar hangups: I have a systems professor who said that every time his disk gets close to filling up, he buys a new laptop with twice as much storage and copies everything over. Per Murphy&rsquo;s law, it&rsquo;s worked out okay so far.</p>
<p>The files I deleted on my Windows drive were from my formative years of learning to use a computer. I weirdly sometimes want them back as keepsakes of how much I&rsquo;ve grown, but I think I&rsquo;m coming to terms with the fact that knowing I&rsquo;ve had those experiences is enough. Yet it still feels wrong to hard-delete files, like I&rsquo;m actively cutting the lifespan of my data short.</p>
<p>Even if you&rsquo;re not the one pulling the trigger and hitting <code>Del</code>, I wonder how much data online is continuously being lost passively. It doesn&rsquo;t make financial sense to retain records forever — data is cheap, but at scale, I realize that storing it can add up. Google is deleting inactive Gmail accounts, and reportedly, so does Instagram. This, more passive, type of deletion is also interesting to consider — it&rsquo;s like the data is slowly marching towards its deletion.</p>
<p>Today, there are on the order of 120 zettabytes (2^70 bytes) of data in the world, but I don&rsquo;t know if this statistic accounts for deleted or inactive data. That&rsquo;s more difficult to estimate, but if there&rsquo;s 330 million terabytes of data created per day, there&rsquo;s got to be at least a few million deleted. I wonder what we lose each day. The 330 million terabytes is primarily video data, so there&rsquo;s probably plenty of old video content in what&rsquo;s deleted, but perhaps some meaningful software too.</p>
<h2 id="davids-ipad">David&rsquo;s iPad</h2>
<p>My family still has one of the original iPad Airs from a company gift almost a decade ago. The limited set of apps I use runs perfectly fine, and for the most part websites work alright too. But as the web, or really, JavaScript standards, move onwards, website after website has stopped quite working as it used to. Reddit doesn&rsquo;t load comments, ad-heavy recipe sites keep throwing &lsquo;A problem repeatedly occurred&rsquo;, and a class of sites that appear to be using React show the same slap in the face: &lsquo;Application error&rsquo; and &lsquo;Browser not supported&rsquo;.</p>
<p>I&rsquo;m for change and innovation in the web space. As someone who&rsquo;s blindly thrown ES2023 features into code without worrying too much about browser support or interoperability, I get it. It&rsquo;s not the fault of web maintainers in any way. Yet it feels odd to have that reminder that things on the Internet aren&rsquo;t here, in the same state that they are now, accessible in the same ways they are now, forever.</p>
<p>The rest of my devices are fairly up-to-date, so I haven&rsquo;t suffered too much from device support issues beyond using this old iPad. It&rsquo;s a good reminder to me, though, that even if software sticks around for a long time, the hardware we have may not always fully support it. GitHub has decided to archive so many repositories in its Arctic Code Vault: in the future, will we even have the hardware to run it? We&rsquo;ll have to rely on emulators and apocryphal knowledge of processor, browser, and operating system quirks.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<h2 id="this-domain-is-for-sale">This domain is for sale</h2>
<p>To keep software innovating, sometimes we can&rsquo;t support all devices. To some extent, that&rsquo;s acceptable. The core functionality still works, we get new devices, the world goes on. But what happens when the app itself goes down?</p>
<p>There&rsquo;s websites out there that were in a &lsquo;it works now but don&rsquo;t touch it&rsquo; state, abandoned or forgotten. I came across <a href="https://stablequarters.org/">this equine center site</a> that appeared to use to have live horse cams, which are understandably no longer activated, as the center shut down in 2018. I wonder how the site&rsquo;s still running, five years later. Granted, it&rsquo;s very Web 1.0, so I doubt there were many critical dependencies, but the domain and hosting&rsquo;s still up.</p>
<p>Sites like these suffer from something similar to, but not entirely like, bit rot. With bit rot, functionality itself glitches or corrupts, but here it&rsquo;s like piece by piece of the site fades away. First the outlinks die, then some iframe source no longer connects, and so on. Because of backwards compatibility, most things keep working, so it&rsquo;s like a slowly decaying time capsule with a ticking timer for when it&rsquo;ll disappear.</p>
<p>Archive.org does a good job at capturing most sites on the internet to preserve snapshots before they go down, but they don&rsquo;t capture the full interactivity of pages. Outlinks aren&rsquo;t captured by default, so even if a page loads, we might not be able to access the websites in its latent space. As well, apps that require authentication won&rsquo;t get captured. Fifty years down the line, we&rsquo;ll only have screenshots and video recordings left.</p>
<p>As well, hosting costs someone somewhere money, even if it&rsquo;s ostensibly offered for free, so it makes sense that apps aren&rsquo;t hosted forever either. However, it&rsquo;s a lot easier to justify keeping an app up if it&rsquo;s running for free, as was possible with Heroku and its competitors. I&rsquo;d be interested in an estimate of what small percentage of the Internet <a href="https://www.heroku.com/">Heroku</a> took down just by removing its free tier. It&rsquo;s likely small, but biased towards personal passion projects. I&rsquo;d think work like this is highly sentimental to their creators, but perhaps not so much so that it&rsquo;s worth spending extra on hosting<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Finally, I&rsquo;d like to consider domain names. It&rsquo;s impossible to buy a domain name forever — we&rsquo;re just renting them by the year<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Gilles Castel, notable for their Vim + LaTeX notetaking workflow, unfortunately passed away in 2022, but <a href="https://castel.dev">their site</a> remains up. Perhaps they prepaid for a domain for many years, or perhaps someone close is taking care of the registration for them. I can&rsquo;t help but wonder what happens as long-held domains and hosting plans expire, particularly for proprietary websites where the original source may be lost entirely.</p>
<h2 id="conclusion">Conclusion</h2>
<p>One open-source project that inspired many of the deprecation-related thoughts in this post is <a href="https://github.com/jdecked/twemoji/">twemoji</a>, Twitter&rsquo;s signature emoji library, now forked from the prior Twitter open-source project. A few months ago, I saw <a href="https://github.com/twitter/twemoji/issues/570">this issue</a>, noting that there were problems with licensing prior emoji assets for reuse, so the project would stagnate. I use Twemoji as my default emoji font, and I realized that while previously released emojis would still work, more and more emojis would appear as <a href="https://en.wikipedia.org/wiki/Noto_fonts#Etymology">tofus</a> as time went on. I would literally be able to see the font decay.</p>
<p>Happily though, <a href="https://github.com/jdecked/twemoji/pull/51">this PR</a> recently got merged with the Unicode 15.0 updates and what I assume was approval from Twitter to continue the project. It&rsquo;s still a volunteer-run effort, but Discord as a company seems invested in contributing, so I&rsquo;m optimistic that Twemoji will continue to be updated until the inevitable process of software EOL kicks in yet again.</p>
<p>My dad once very thoughtfully reflected that everything needs maintenance: health, physical objects, relationships. So does software. When there&rsquo;s no one there, or no more resources available, to maintain it, the metaphorical health of the sites we frequent today will begin to decline. Eventually, we won&rsquo;t be able to locate them anymore, when their domains expire; to run them anymore, when their backends stop being hosted or our new processors ditch support. I&rsquo;d reckon they&rsquo;ll eventually all be deleted as well, despite our best efforts to memorialize and archive them.</p>
<p>As they say, though, such is life. While our software still runs (or hobbles along) for us today, we can learn to appreciate its quirks and the marks it&rsquo;s left on us. They say life is fleeting, and maybe it&rsquo;s okay that software is too.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The game emulator communities give me hope in this respect, as well as those working on emulating classic systems like <a href="https://lisa.sunder.net/">the Lisa</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>After Heroku announced the end of its free tier, many switched to <a href="https://fly.io">Fly.io</a>, which also offers a reasonable free tier. I made the switch for my CORS proxy for <a href="https://github.com/kewbish/matter">Matter</a>, but that was because I was actively using Matter. I suspect there were many little tools like Matter that went down just because someone didn&rsquo;t bother with manually porting things over.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>See also this post by Chuck Grimmett on <a href="https://cagrimmett.com/tech/2023/11/04/domain-longevity/">how we can keep our domains around after death</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Serialization</title>
      <link>https://kewbi.sh/blog/posts/231126/</link>
      <pubDate>26 Nov 2023</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On reducing dimensions and preserving semantics.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I remember when I first started learning Python and realized what an <a href="https://peps.python.org/pep-0498/">f-string</a> was. It was mind-blowing to me back then that not only could you print variables in a certain format, but also modify those variables and do other computation within the brackets, and get it to all display nicely. I was amazed that I could get variables of all different types to pretty-print themselves with an f-string.</p>
<p>I now know that under the hood, the f-string formatting is just calling <code>__str__()</code>, and that all the types I tried just had good <code>__str__()</code>s defined. This is an example of serialization: formally, transforming an object to a different representation so it can be saved to disk or transmitted over the wire. I like to think of it as dimension reduction in a representation — kind of like squashing a cube into a square, or in this case taking a photo of the cube (converting it into 2D data) to be faxed<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. To bring this dimension reduction back to Python, if I ran the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>dict <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#34;a&#34;</span>: <span style="color:#ae81ff">1</span>, <span style="color:#e6db74">&#34;b&#34;</span>: <span style="color:#ae81ff">2</span>}
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>dict<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>I&rsquo;d get <code>{&quot;a&quot;: 1, &quot;b&quot;: 2}</code> as the output. This converts the dictionary into a string so it can be transmitted via printing, but in doing so, the string loses some of the properties of the original dictionary. You can&rsquo;t call <code>.items()</code> on the string, nor can you add new key-value pairs. During serialization, the object&rsquo;s lost some of its intrinsic properties while retaining the same core information.</p>
<p>This is an interesting problem (feature?) of serialization, and it&rsquo;s something I&rsquo;d like to explore further, especially in the context of exporting metadata from apps and tool interoperability. In this post, I&rsquo;ll dive into JavaScript&rsquo;s infamous <code>[object Object]</code>, JavaScript&rsquo;s JSON serialization, and alternative serialization methods, like dehydration of data, before pivoting a little into what it means to really own our data (spoiler alert: it has to do with serialization too!)</p>
<h2 id="object-object">[object Object]</h2>
<p>I was once helping <a href="https://maplebacon.org/">Maple Bacon</a> run their UBC-specific CTF, SaplingCTF. I was working primarily on the CTFd theme, and for this iteration of SaplingCTF in particular, I was trying to get some custom styling working for progression challenges. I thought I had it all working, until things inevitably broke during the competition and I had to do some debugging and hotfixing. While trying to deploy a fix as soon as possible, I left an <code>alert(obj)</code> in there somewhere, which meant that each time someone reloaded the challenge page they&rsquo;d be greeted with <code>[object Object]</code>. Not my best work.</p>
<p><code>[object Object]</code> has been ubiquitous in my JavaScript experiences. Forgot to wrap something in <code>JSON.stringify()</code> before <code>console.log()</code>-ing it? <code>[object Object]</code><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p><code>[object Object]</code> comes from the <code>Object</code>&rsquo;s prototype&rsquo;s <code>toString()</code> method returning <code>[object Object]</code>. Functions get serialized as <code>[object Function]</code> and date objects as <code>[object Date]</code>. While all of these are objects, the second word in their serialization depends on their constructor type.</p>
<p>But this all changes if you <code>JSON.stringify()</code> the object. If you try it on <code>{}</code>, you&rsquo;ll get <code>&quot;{}&quot;</code>. If you try it on a date, you&rsquo;ll get a date. What gives?</p>
<p>For one, <code>Date</code>s implement the <code>toJSON()</code> method, so <code>JSON.stringify()</code> knows to show the ISO representation of the date as its serialized value. In general, properties that have <code>.toJSON()</code> will have that method called to determine how to serialize them, and others, like <code>undefined</code>, <code>Map</code>s, and <code>Set</code>s, will be ignored. <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#description">MDN</a> has more about the specifics of the algorithm here.</p>
<p>I recently learned that you can also provide your own <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#the_replacer_parameter">replacer function</a> to <code>JSON.stringify()</code> to tell it how to serialize certain types, like <code>ArrayBuffer</code>s or the aforementioned <code>Map</code>s and <code>Set</code>s. It&rsquo;s called on the object being stringified, then called recursively on each of the object&rsquo;s properties. You can check the type of the object (e.g. <code>object instanceof SpecialClass</code>) and return a value satisfactorily serializing the object&rsquo;s properties to be included into the JSON. <code>JSON.parse()</code> also has a reciprocal function called the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse#using_the_reviver_parameter">reviver function</a>. This is useful for including things like <code>Set</code>s in a JSON string, which I typically serialize as an array and rebuild into a <code>Set</code> on the other side.</p>
<h2 id="serialization-in-the-wild">Serialization in the Wild</h2>
<p>There are other ways to approach serialization in JavaScript that avoid having to create your own custom reducers for common datatypes and that handle cyclical references well. For example, Cloudflare&rsquo;s local Workers simulator, <code>miniflare</code>, uses <a href="https://github.com/Rich-Harris/devalue"><code>devalue</code></a> to flatten objects representing Workers abstractions into JSON so they can be piped through to different parts of the simulator<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. <code>devalue</code> brings support for <code>JSON.stringify</code>ing common objects like <code>Map</code>s and handles cyclical references, which you&rsquo;d otherwise have to write replacer functions for. A nice bonus is that it can even unflatten values that are part of a larger string. This is called rehydration: if we think of serializing values as vacuum-packing and drying food for easier storage and later consumption, rehydration is the &lsquo;just add water&rsquo; part of eating the MREs. While using it, I noted that <code>devalue</code> has some pretty neat raw output as well. If I recall correctly, it outputs seemingly nonsensical nested arrays of numbers and string keys — think something like <code>[[0, &quot;a&quot;, []], &quot;b&quot;]</code>. The project goals state that it&rsquo;s intentionally not human readable, but it&rsquo;s interesting that if you squinted hard enough, you can kinda tell where the structure comes from.</p>
<p>On the more theoretical PL side, I also recently learned about <a href="https://en.wikipedia.org/wiki/Thunk">thunks</a>. Thunks are a way to delay evaluation of an expensive function (and historically, to delay evaluation of its arguments) until later. In JavaScript, they can be implemented quite easily with arrow functions wrapping some function with other arguments and passing the variable name of the thunk around.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-js" data-lang="js"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">expensiveFunction</span> <span style="color:#f92672">=</span> (<span style="color:#a6e22e">n</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">int</span>) =&gt; {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/* calculate factorization of n */</span>
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">thunk</span> <span style="color:#f92672">=</span> () =&gt; <span style="color:#a6e22e">expensiveFunction</span>(<span style="color:#ae81ff">1337</span>);
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">doSomethingElse</span>(<span style="color:#a6e22e">thunk</span>); <span style="color:#75715e">// can pass in the thunk function to later be evaluated
</span></span></span></code></pre></div><p>Thunks are mostly used to avoid executing code, but I&rsquo;ve seen them used in serializing expensive or unreliable function results as well. I was <a href="https://github.com/jepsen-io/maelstrom/blob/main/doc/05-datomic/03-persistent-trees.md">optimizing a toy distributed KV store</a> recently and I was using &rsquo;thunks&rsquo; to store mappings of unique IDs to values. This let me only occasionally retrieve the underlying values when needed to hydrate parts of the KV map while keeping other parts unevaluated and ready for computation later. To me, thunks feel like a type of serialization too, since they package up a function in a representation for use (evaluation) in another context. However, since they&rsquo;re usually implemented with basic built-in language features and are usually never read in their bytecode form outside of the program&rsquo;s execution, maybe this one&rsquo;s a bit of a stretch.</p>
<p>While Python&rsquo;s <a href="https://docs.python.org/3/library/pickle.html">pickling</a> is in an entirely different language, it also bears mentioning in a post about serialization. This past semester, I was working on a research project that had been started by another student the summer before. <a href="https://github.com/ubcdlab/pr-issue-topology-project">The project</a> involved a lot of web scraping and I wasn&rsquo;t looking forward to having to do it again, but the previous student had the foresight to save all the scraped Python objects as pickles! This made it incredibly easy to load in a big class object and start manipulating data. The scraping had also been performed with the help of some other libraries, and Pickle preserves the functions defined on each object, so even without the libraries installed I was able to call basic functions and get started quickly.</p>
<p>Pickling in Python is the richest form of serialization I&rsquo;ve worked with yet - the fact that the object and all its properties and functions can be recreated from a simple file means that none of the original data or behaviour is lost. At the start of this article, I mentioned how serialization often feels like dimension reduction: after data is serialized, it typically loses some behaviour or some data attributes, even if it&rsquo;s parsed and reconstructed later. Pickling makes serialization without this reduction practical.</p>
<p>A section on the forms of serialization I&rsquo;ve encountered so far wouldn&rsquo;t be complete without a final little hat-tip to <a href="https://en.wikipedia.org/wiki/Racket_(programming_language)">Racket</a> and its Lispy concepts of data as code and code as data with S-expressions. I can&rsquo;t put it into words, but there seems to be something intrinsically connecting the concepts of serializability and having your code live as data and vice versa.</p>
<h2 id="iframe-pickling-the-web"><code>&lt;iframe&gt;</code>: Pickling the Web</h2>
<p>If serializing is converting something into a form that can be transmitted, there&rsquo;s also something interesting in primitives that don&rsquo;t have to be converted to be transmitted. Pickling is one such modality, but so are <code>&lt;iframe&gt;</code>s. Pardon my continual gross misuse of &ldquo;serialization&rdquo;, but I also think <code>&lt;iframe&gt;</code> embed tags are, if not a form of serialization, at least something very closely adjacent. They&rsquo;re arguably one of the most ubiquitous and well-embedded (pun not intended) on the web. They were introduced in 1997<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> (after Python&rsquo;s <code>pickle</code> was implemented!)</p>
<p>In some ways, they&rsquo;re similar to pickle files — they preserve the entire functionality of the object and allow the site to be integrated into the rest of another object. They enable websites to be part of each other in a rich way like pickle files, with some extra strict container boundaries for security.</p>
<p>On the other hand, they&rsquo;re not persistent like pickle files, even if the hosting website is a local file. They depend on the current iteration of the website, and if the embedded site goes down, the hosting site won&rsquo;t display properly as well. You could embed an <code>&lt;iframe&gt;</code> to the <code>archive.org</code> as well, but that might not necessarily reflect the most recent updates to the site. Maybe embedding an <code>archive.org</code> link is somewhat closer to serialization than live <code>&lt;iframe&gt;</code>s.</p>
<h2 id="tool-interoperability">Tool Interoperability</h2>
<p>At the core of serialization is the idea that data <em>moves</em>: between scripts (Pickling), between obscured code and developer-facing output (JSON), and between domains on the web (<code>&lt;iframe&gt;</code>s). We&rsquo;ve seen in this post all the ways serialization can enable interesting theoretical behaviour, but what happens in the real world?</p>
<p>I think serialization-forward software is almost necessarily at odds with the walled-garden, mystery-cloud approach of most SaaS tools. Nowadays, most tools support some way to export your data, but moving between software typically causes you to lose something. I once did a big migration from OneNote to raw Markdown, which, to state the obvious, meant losing all my image positioning, coloured highlights, and so on. That&rsquo;s a big fidelity jump, so I&rsquo;ll forgive OneNote, but there&rsquo;s so many more examples online. You can export webpages to PDF, losing easy access to their hyperlinks or to interactive media. Depending on the service, exports can range from CSVs to JSON — you might get all the required data for your use case, but you also might not. You&rsquo;ll certainly have to recreate the underlying functionality of the data, or find a tool to do so. If you find another app and switch, it&rsquo;ll often take significant work to convert to the serialization format expected by the new program.</p>
<p>Serialization, and ways to extract rich metadata, is key for true interoperability. In an ideal world, we&rsquo;d also be able to get some base idea of the object&rsquo;s original interactivity models. Today, we&rsquo;re stuck with copy-and-pasting raw unformatted text and taking static screenshots that don&rsquo;t encode any of a tool&rsquo;s behaviour.</p>
<p>The performance of ways to do this is another issue to tackle. To enable a practical workflow where you&rsquo;re able to switch seamlessly between apps, your context-switching processing time should be as low as possible. This is a challenge when you&rsquo;ll likely have to convert between file formats and reconcile differences in structure on the fly, all of which appear very expensive time-wise.</p>
<p>I see aspects of this interoperability in tools already — MS Word allows you to embed and interact with MS Excel charts, for example. There are also a plethora of sketchy scripts on GitHub that allow you to convert and import between tools. But they lack the authoritative support, polish, and ease of use that I think are necessary to bring this potential ecosystem together.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Serialization and representation are so closely intertwined that if I ran <code>s/serialize/represent/g</code> on this post it&rsquo;d still make sense (and I&rsquo;d still have to apologize for my overly stretched usage of either word). I don&rsquo;t know how to differentiate between them, and I think in this post I&rsquo;ve mixed both up and added a few more tablespoons of general interest in data to boot.</p>
<p>I&rsquo;m interested in thinking about more open ways to move data around, relying perhaps on more easily serialized forms of data, like JSON, and figuring out how to codify original behaviour or intent. Ink And Switch&rsquo;s <a href="https://www.inkandswitch.com/potluck/">Potluck</a> and <a href="https://www.inkandswitch.com/cambria/">Cambria</a> projects both fit closely to this space, and I&rsquo;ve also been inspired by Alexander Obenauer&rsquo;s <a href="https://alexanderobenauer.com/labnotes/002/">idea of universal data portability</a> and thoughts on <a href="https://alexanderobenauer.com/labnotes/000/#:~:text=Having%20fun%20with%20item%20views">data views</a>. <a href="https://streamlit.io/">Streamlit</a>, a Python framework to build data-based apps, seems like an adjacent step towards what I&rsquo;m envisioning as well. I&rsquo;d like to dive specifically into how to represent original intent at a rich level sometime — we&rsquo;ll see what comes out of that thought.</p>
<p>Also, on a final note, I&rsquo;ll be giving a lightning talk at <a href="https://neovimconf.live/">Neovimconf 2023</a> about my personal knowledge management system in Vim! Tickets are free, so tune in on December 8th, 2023 if you&rsquo;re interested in learning more about taking notes with Vim, a little splash of Ripgrep, and some FZF.vim too.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>By &lsquo;dimension&rsquo; here, I mean one &lsquo;aspect&rsquo; or &lsquo;axis&rsquo; of data. I loosely also include &rsquo;the ability to do something&rsquo; - something like an instance function - as a dimension. I think the term &lsquo;dimension&rsquo; is probably overloaded here, and there&rsquo;s probably a better way to express this sort of &lsquo;squishing&rsquo;.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>This mistake once derailed an entire hackathon project for about 6 of the 36 hours. It was extremely frustrating to diagnose as a JavaScript beginner - what, was I supposed to know that <code>fetch()</code> was expecting a string for a request&rsquo;s body?&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>When I was working on updating <a href="https://github.com/cloudflare/miniflare/pull/641">the Queues implementation</a>, I looked into it for sending the Queue&rsquo;s messages around. To be honest, when making the PR, all the serialization and buffer manipulation felt a bit like black magic, primarily because I was unfamiliar with how Buffers and ArrayBuffers worked. Learning more of the JS internals, like this, is something I want to improve at.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>It was a surprise to me that Python&rsquo;s pickle library <a href="https://github.com/python/cpython/commit/a48061a5804418a63aac24bfce444fd555e3ffe7">predates <code>&lt;iframe&gt;</code>s</a>. The first commit in the Cpython Pickle library file was in 1995, but there are references to an even older &lsquo;flatten&rsquo; version of the library.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Highlighting Text in Vim</title>
      <link>https://kewbi.sh/blog/posts/230807/</link>
      <pubDate>07 Aug 2023</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On highlighting (the Sharpie and Hi-Liter kind).</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I&rsquo;ve always liked text-based interfaces like TUIs and interactive CLIs. They&rsquo;re consistent, familiar, and themeable (since they&rsquo;re just text). I associate TUIs and text-based interfaces in general with a bit of an initial learning curve but also with a conceptual simplicity and most importantly, a lot of power. Interfaces like these are easy to make your own and to slip into.</p>
<p>Take Vim, for example. It&rsquo;s infamous for its comparatively esoteric keybinds - how do you quit again? But once you take a moment to learn its modes and its keybind &lsquo;vocabulary&rsquo;, you&rsquo;ll find that it&rsquo;s predictable and dependable. I won&rsquo;t go far as to say the keybinds are intuitive, but they <em>can</em> be reasonably added to your intuition model.</p>
<p>I started using Vim around 2020, when I was transfering all my notes from OneNote to Markdown. I was still in high school, so I had the liberty of not being as serious about my notes. I had grand ideals of being efficient and learning a new skill, and I&rsquo;d heard about Vim from all the jokes online. It seemed like a fun challenge to learn. For a while, I used Vim bindings within VSCode, but when I switched to Linux in 2021, I made Vim my daily-driver editor.</p>
<p>I recently ported my configuration files over to NeoVim, since I&rsquo;ve been seeing more and more plugins that rely on some NeoVim-specific features. Take the <a href="https://github.com/giusgad/pets.nvim">pets.nvim</a> extension for example. Most plugins also limit support to NeoVim for some nice QOL features. <a href="https://github.com/neoclide/coc.nvim">COC.nvim</a> type annotations display better and don&rsquo;t break on NeoVim, and the <a href="https://github.com/iamcco/coc-spell-checker">spelling plugin</a> I use underlines better. Most of my config has stayed the same - it&rsquo;s been a super easy port, and that says a lot about the level of care to maintain Vim interop.</p>
<p>I&rsquo;ve also started adding more personal touches to my notetaking Vim config. I thought it&rsquo;d be cool to add some color to my setup, which is currently extremely grey, and added some snippets for colouring text in my notes. I&rsquo;ve always wondered if it&rsquo;d be possible to replicate the OneNote / typical word processor features of highlighting. I&rsquo;ve thought about replicating the ease of use of text colouring in OneNote via a visual selection → highlight mechanism in Vim, and I&rsquo;ve just lately figured out how to do it.</p>
<figure><img src="/img/230807/my-highlighting-setup.png"
         alt="Figure 1. My current highlighting setup."/><figcaption>
            <p><em>Figure 1. My current highlighting setup.</em></p>
        </figcaption>
</figure>

<p>This is a post about implementing a reasonably usable text highlighting feature in Vim, and the other fun Vim features I discovered along the way.</p>
<h2 id="snippet-expansions">Snippet Expansions</h2>
<p>There are loads of Vim plugins for inserting snippets, like <a href="https://github.com/honza/vim-snippets">vim-snippets</a> or <a href="https://github.com/SirVer/ultisnips">Ultisnips</a>. However, for the simple text highlighting that I use in my notes, I&rsquo;ve found it easier to just use insert mode level remappings natively in Vim.</p>
<p>For my insert mode remaps, I tend to map combinations starting with my leader key, <!-- raw HTML omitted -->&lt;/kbd&gt;. Starting combos with your leader avoids the situation where you really do want to type a sequence of keys instead of execute your keymap. My leader key&rsquo;s not something that I&rsquo;d typically type in writing, so the short delay Vim imposes when I want to type the single character is bearable.</p>
<p>Here&rsquo;s the basic form of one of my native snippet expansions:</p>
<pre tabindex="0"><code>inoremap &lt;leader&gt;[shortcut] [text to insert]
</code></pre><ul>
<li><code>i-</code> denotes that it&rsquo;s a remapping that only applies in insert mode.</li>
<li><code>-no-</code> denotes that we shouldn&rsquo;t substitute any of the following characters for remapped versions, effectively making it non-recursive. For example, if we&rsquo;d defined &rsquo;s&rsquo; elsewhere to insert &lsquo;ß&rsquo; in insert mode, adding <code>-no-</code> makes the remap insert &rsquo;s&rsquo; if the remap itself contains &rsquo;s&rsquo;.</li>
<li><code>-remap</code> denotes the remap.</li>
<li>The second bit here is the keymap to press. I use my leader key (<code>\</code>) followed by a quick shortcut.</li>
<li>The third part is the text to insert.</li>
</ul>
<p>For example, to insert <code>(CN)</code> in a note, I use the following keybind.</p>
<pre tabindex="0"><code>inoremap &lt;leader&gt;cn (CN)
</code></pre><p>I only make a snippet mapping when I find myself having to repeatedly type long or physically awkward phrases. These types of snippets are useful for movements that would otherwise require shifting and wrapping and generally more finger movement than desired. Instead of holding <code>shift</code> and pressing <code>9-c-n</code>, I can just tap <code>leader-c-n</code><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<h2 id="text-styling">Text Styling</h2>
<p>Onto the fun part - text styling. In Vim, you can recreate text highlights (changing the background colour of text), font colour changes (changing the foreground colour of text), bolding, italicizing, underlining, and striking through text. There&rsquo;s probably more to this list - there are a <em>lot</em> of terminal escape sequences.</p>
<p>To do this, you can add <code>autogroup</code>s in your <code>.vimrc</code> or <code>init.vim</code>. If you want, you can also <a href="https://web.archive.org/web/20230130221652/http://learnvimscriptthehardway.stevelosh.com/">create your own Vim plugin</a> to keep things organized, and so you can more easily distribute your updates.</p>
<p>Here&rsquo;s a basic skeleton for how to change the colour of text:</p>
<pre tabindex="0"><code>augroup notes
    autocmd!
    autocmd FileType markdown syntax match CorrodeClassmateNote /\v\(CN\)/
    autocmd FileType markdown hi CorrodeClassmateNote ctermfg=152 guifg=#afd7d7
augroup END
</code></pre><p>This renders to:</p>
<figure><img src="/img/230807/highlighting-example.png"
         alt="Figure 2. An example of highlighting (CN) in light blue."/><figcaption>
            <p><em>Figure 2. An example of highlighting (CN) in light blue.</em></p>
        </figcaption>
</figure>

<p>The first <a href="https://blog.sidebits.tech/vim-autocommands/"><code>autocmd</code></a> line creates a syntax match &lsquo;class&rsquo;, and the second <code>autocmd</code> <code>hi</code>ghlights the text. The syntax match class is a regex - you can use the <code>\v</code> escape option to avoid escaping all the regex special characters manually. Here, I&rsquo;m matching the literal <code>(CN)</code><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Each match can be added to a group (<code>CorrodeClassmateNote</code> is a match group, for example), and the name of the match group is the identifier you&rsquo;ll use to style it. Avoid using <a href="https://jordanelver.co.uk/blog/2015/05/27/working-with-vim-colorschemes/">common group names</a> so you don&rsquo;t override your existing theme. The <code>FileType markdown</code> also makes this match group only apply in Markdown files, though you can use filename globs or choose another Vim filetype.</p>
<p>The second line highlights the <code>CorrodeClassmateNote</code> group with the given <code>ctermfg</code> (foreground colour used in the terminal) or <code>guifg</code> (colour used if you use GUI Vim instead). <code>guifg</code> can be in hex, but <code>ctermfg</code> needs to be one of the Xterm prompt colours <a href="https://www.ditig.com/256-colors-cheat-sheet">supported by your terminal</a>.</p>
<p>You can change <code>ctermfg</code> and <code>guifg</code> to <code>ctermbg</code> and <code>guibg</code> respectively to change the <em>background</em> colour used in the terminal or GUI. This gets you a typical &lsquo;highlighter&rsquo; functionality.</p>
<figure><img src="/img/230807/background-highlighting-example.png"
         alt="Figure 3. Highlighting (CN)&#39;s background in light blue."/><figcaption>
            <p><em>Figure 3. Highlighting (CN)&rsquo;s background in light blue.</em></p>
        </figcaption>
</figure>

<p>If you want to bold or italicize text, just add <code>cterm=bold gui=bold</code> or <code>cterm=italic gui=italic</code> to the end of the <code>hi</code> <code>autocmd</code>. And if you&rsquo;d like to apply both, <code>cterm=bold,italic gui=bold,italic</code> will do the trick. See <a href="https://vimdoc.sourceforge.net/htmldoc/syntax.html#attr-list"><code>:help attr-list</code></a> for more information on the attributes you can use to style text here.</p>
<h2 id="ctrl-shift-c-or-changing-font-colour">Ctrl-Shift-C (or, Changing Font Colour)</h2>
<p>If you want to colour not just specific text, but replicate a general &lsquo;change colour&rsquo; functionality in Vim, define a match group like so:</p>
<pre tabindex="0"><code>autocmd FileType markdown syntax match GreenHighlight /\v\(\#G(.*)\)/
autocmd FileType markdown hi GreenHighlight ctermfg=121 guifg=#88ff88
</code></pre><p>This highlights all matches of <code>(#G text)</code> a special shade of green. In Vim, it renders to this:</p>
<figure><img src="/img/230807/green-highlighting-example.png"
         alt="Figure 4. Highlighting some text in WebWork green."/><figcaption>
            <p><em>Figure 4. Highlighting some text in WebWork green.</em></p>
        </figcaption>
</figure>

<p>You can define multiple match groups with different prefixes - say, <code>(#Y text)</code> for yellow instead of green - for whatever you want to use. You can also define a remap in visual mode to wrap the current selection with the appropriate syntax to highlight it:</p>
<pre tabindex="0"><code>vnoremap &lt;leader&gt;hg c(#G &lt;C-r&gt;&#34;)&lt;C-c&gt;
</code></pre><p>Select some text in visual mode, then hit <code>&lt;leader&gt;hg</code> to add the highlighting markup. This makes use of vim&rsquo;s default register with the &lsquo;c&rsquo; command to replace text selected in visual mode with the wrapper <code>(#G ... )</code>, and uses <code>&lt;C-r&gt;&quot;</code> (Ctrl-r) to paste the contents that you just selected back into the wrapper. The final <code>&lt;C-c&gt;</code> exits insert mode for you for convenience.</p>
<p>The issue with this approach is that you&rsquo;ll have to add markup to your text to get it to highlight. While it&rsquo;ll still be there in the raw file contents, let&rsquo;s address the visual aspect and hide the <code>(#G ... )</code> wrapper in-editor.</p>
<h2 id="a-cleaner-look-with-conceal">A Cleaner Look with <code>conceal</code></h2>
<p>This&rsquo;ll make use of Vim&rsquo;s <a href="https://vimdoc.sourceforge.net/htmldoc/syntax.html#conceal">conceal</a> feature. It leverages match groups, similarly to text highlighting, to hide text that matches some pattern until you move your cursor to that line. People typically use this to replace syntax with more aesthetically pleasing characters, like replacing <code>lambda x: </code> with <code>λ x:</code>. It can also be used to hide comments that aren&rsquo;t distracting, make inline flashcards that only preview when you hover on a line, and prettifies Markdown markup and <a href="https://github.com/jalvesaq/zotcite">Zotcite</a> citations.</p>
<p>To hide the highlighting wrapper markup:</p>
<pre tabindex="0"><code>autocmd FileType markdown syntax match GreenHLConceal /\v(\(\#G\s)/ conceal
autocmd FileType markdown syntax match GreenHLConceal /\v(\(\#G\s(.*))@&lt;=\)/ conceal
autocmd FileType markdown syntax match GreenHighlight /\v(\(\#G\s)@&lt;=([^\)]*)\)@=/
autocmd FileType markdown setlocal conceallevel=3
</code></pre><p>The first <code>syntax match</code> line matches the first part of the wrapper, <code>(#G</code>, and the second uses Vim&rsquo;s lookback syntax to match any <code>)</code> preceded by a <code>(#G</code>. The <code>GreenHighlight</code> line has been extended a bit to deal with multiple markups per line too.</p>
<p>The fourth line sets the file&rsquo;s <code>concealllevel</code> to 3. Concealled groups have &rsquo;levels&rsquo; of display, which can be controlled on a buffer-level basis. The default <code>conceallevel=0</code> means that all concealled text is still shown in-editor. <code>conceallevel=3</code>, what we&rsquo;re using, means that all concealled text is completely hidden until you move your cursor to that line. In between, <code>conceallevel</code> 1 and 2 can also display a single character replacement for the hidden text. For example, you can add <code>cchar=🟩</code> to the first syntax match to replace the concealled text (the <code>(#G</code>) with a green square emoji.</p>
<p>If you&rsquo;re adding multiple highlighting syntax matches, you can hide all their markup prefixes in one command by replacing the <code>G</code> in each of the first three <code>syntax match</code> lines to something like <code>[RGB]</code>. This will hide the markup for all <code>(#G ...)</code>, <code>(#B ...)</code>, and <code>(#R ...)</code> highlight groups.</p>
<p>This renders to this:</p>
<figure><img src="/img/230807/conceallevel.gif"
         alt="Figure 5. Hiding the highlighting markup on cursor move."/><figcaption>
            <p><em>Figure 5. Hiding the highlighting markup on cursor move.</em></p>
        </figcaption>
</figure>

<h2 id="conclusion">Conclusion</h2>
<p>These highlighting features have helped me keep track of class discussions more easily and make my terminal-based notetaking system a little more fun. I only have two of these highlighting shortcuts set up (for &ldquo;my notes&rdquo; and &ldquo;classmate&rsquo;s note&rdquo;), but I use them fairly frequently during classes.</p>
<p>There are probably plugins to automate the creation of snippets and of highlighting commands, but I don&rsquo;t create new highlighting groups often enough to make it worth understanding them. Vim is known for its steep learning curve and batteries-not-included approach: I think the fact that the &lsquo;proper&rsquo; approach to this custom highlighting is a couple of plugins or quite a few lines of Vimscript is a testament to that. But I think learning to make custom highlighting groups and learning a bit more about Vim&rsquo;s syntax matching is a great way to get started with Vimscript. For those with a bit of regex knowledge, the syntax is relatively clear and the <code>autocmd</code>s are a starting point for <a href="https://learnvimscriptthehardway.stevelosh.com/chapters/12.html">adding plenty of custom behaviour</a>.</p>
<p>Another feature I&rsquo;d like to explore now since I&rsquo;m using NeoVim is <a href="https://neovim.io/doc/user/api.html#api-extmark">virtual text, officially known as extmarks</a>. I first learned about this when the GitHub Copilot Vim plugin came out and I realized it wouldn&rsquo;t work with vanilla Vim<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. While Vim 9 <a href="https://vimhelp.org/textprop.txt.html#virtual-text">supports this feature</a>, there were a good few other reasons to switch to NeoVim, so I never tried it out in vanilla Vim.</p>
<p>I&rsquo;d like to continue to explore more Vim quirks on this blog - it&rsquo;s amusing to see how far I can push things. For a while, I tried to replicate a basic flashcard system in Vim, and I also have a couple updates to my <a href="https://kewbi.sh/blog/posts/210815/">FZF + RG</a> setup, specifically for for development. Recently, I even saw an interesting <a href="https://github.com/sigpwny/UIUCTF-2023-Public/tree/main/challenges/misc/vimjail1">CTF challenge</a> written in Vim. I&rsquo;ve been thinking of covering these, perhaps in a shorter format, but we&rsquo;ll see when I&rsquo;ll get around to it.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Not having to hold down shift makes adding these annotations in my notes a lot faster.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>I use this to denote &lsquo;classmate&rsquo;s note&rsquo; in discussion-heavy classes.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>I have yet to seriously try the plugin, even with virtual text support.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Everything I Know About Stacked PRs</title>
      <link>https://kewbi.sh/blog/posts/230611/</link>
      <pubDate>11 Jun 2023</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On a summer of shipping in stacks.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I spent last summer interning at <a href="https://replit.com">Repl.it</a>, the browser-based coding platform that makes it easy to build and collaborate. I interned on their Workspace team, and primarily worked on <a href="https://blog.replit.com/nix-github-imports">porting their GitHub import flow to Nix</a> (and another super-secret project that hasn&rsquo;t been shipped yet). It was an incredible learning experience – I was mentored by insanely smart people and granted the autonomy to own development of an improved product flow. Check their platform out if you haven&rsquo;t already: it&rsquo;s just as amazing as the team behind it!</p>
<p>It&rsquo;s ironic that while working on GitHub imports to support Replit users&rsquo; dev workflows, a major technical challenge would be wrangling GitHub to support <em>my</em> dev workflow. While Replit&rsquo;s engineering team has no prescribed pull request submission process, I quickly learned that the most efficient way to get PRs reviewed quickly was to make them small. But when you&rsquo;re working on adding a new feature or flow, the amount of code changes needed is generally big. How do you split up a huge PR into smaller ones while making sure that they&rsquo;ll get merged in order and that they make sense as smaller units?</p>
<p>The solution was stacked pull requests. Instead of making a larger PR, split the PRs up into logical working chunks and stack them on top of each other. Let&rsquo;s say you&rsquo;re working on adding a new modal dialog for some flow. Inside, there&rsquo;s some interaction that calls out to a new API that you also implement, and some interaction that uses an existing API in a new way. Instead of submitting this all as one big PR, you can create a base PR with just the UI changes (<code>git checkout -b add_modal_ui</code> from <code>main</code>). Then, you can create another PR on a new branch off of the base PR with an implementation of the new API and hooking it up to the UI (<code>git checkout -b add_new_api</code> from <code>add_modal_ui</code>). After that, you can branch off this second PR again to integrate the existing API (<code>git checkout -b add_existing_api</code> from <code>add_new_api</code>).</p>
<p>The PR stack ends up looking like this:</p>
<pre tabindex="0"><code>main
└── add_modal_ui
    └── add_new_api
        └── add_existing_api
</code></pre><p>GitHub has a good UI for submitting stacked PRs that you might not have ever noticed. When submitting a new PR on a branch, you can choose the base branch that you submit your PR to. For example, when submitting the PR on the <code>add_new_api</code> branch, choose <code>add_modal_ui</code>. If you daisy-chain these, GitHub will automatically update the base branch of each PR in the stack as they get merged.</p>
<figure><img src="/img/230611/base-changes.png"
         alt="Figure 1. GitHub automatically changing a PR&#39;s base branch."/><figcaption>
            <p><em>Figure 1. GitHub automatically changing a PR&rsquo;s base branch.</em></p>
        </figcaption>
</figure>

<p>Because each individual PR builds on the previous one, but is a logically coherent and small addition, each PR can be reviewed individually. This speeds up PR review since reviewers don&rsquo;t have to comb through a hundred changed files trying to make sense of what affects what. It&rsquo;s easier to articulate intention with smaller PRs too, leading to better communication.</p>
<p>A PR stack typically gets merged from the leaf back down to the root PR (in the example, from <code>add_existing_api</code> to <code>add_modal_ui</code>) and back to the main development branch<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This means that all your changes can still end up on the main branch as a single unit, as in the &ldquo;good ol&rsquo; Big PR&rdquo; approach, but they&rsquo;ve likely been easier to review and work on.</p>
<p>Sometimes the PRs can even be as small as a single commit, and the PR stack is essentially a PR of smaller PRs. Think of stacked PRs like an extension of the commit history feature within the GitHub code review pane. When reviewing big PRs, you can look through commit history to see how things were put together. Stacked PRs operate on the same principle: they isolate changes to their smallest logical units, but just do so more explicitly than with multiple commits.</p>
<p>Stacked PRs also kept me unblocked during the summer, even when I had lots of changes on the go that depended on each other. I didn&rsquo;t have to wait for a feature submitted as a large PR to be reviewed before working on something that built on top of it. This is especially nice when I submitted the base PRs for review before starting to work on PRs that build on it, since this way you can keep the stack small but keep the momentum of feature development going.</p>
<p>Stacked PR workflows aren&rsquo;t perfect. I spent a lot of time painstakingly resolving branch conflicts this summer<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup><sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, especially after PRs lower in the stack had significant changes requested. When you&rsquo;re working on many different features within a feature, your PR stack can also turn into a gnarly PR tree. With more complicated changes to base PRs and inter-PR stack dependencies, we ran into what was lovingly known as &lsquo;rebase hell&rsquo;. As well, because PRs get merged into their parent PRs, the root PR still lands a big diff on the main branch, so take care to review changes in staging carefully before merging down. With stacked PRs, you also can&rsquo;t test individual PRs in production (unlike in short-lived branch workflows) which might be a deal-breaker if your local environment is limited.</p>
<p>In spite of all this, I still think stacked PRs are a useful tool in managing large PRs efficiently. This post covers everything I&rsquo;ve learned about working with stacked PRs, so you can skip the rebase hell and take advantage of some hard-learned workflows.</p>
<h2 id="merging-upstream-changes">Merging Upstream Changes</h2>
<p>Let&rsquo;s say you&rsquo;ve branched off main like so:</p>
<pre tabindex="0"><code>main
└── branch1
    └── branch2
</code></pre><p>You&rsquo;ve made some changes in <code>branch1</code> that you also want to incorporate into your changes in <code>branch2</code>: for example, <code>branch1</code> was reviewed and someone requested changes on underlying code that was developed in <code>branch1</code> but also depended on in <code>branch2</code>. Or perhaps <code>main</code> has had some significant updates that change your development environment, and you want to get those into your <code>branch2</code> as well.</p>
<p>The typical solution for this is while in <code>branch2</code>, run <code>git merge branch1</code> to get the new commits of <code>branch1</code> into <code>branch2</code>. Alternatively<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, you can <code>git rebase branch1</code> on <code>branch2</code>, resolve merge conflicts, then <code>git push -f</code> onto <code>branch2</code>.</p>
<p>Another strategy is to run <code>git rebase --onto=main branch1 branch2</code> on any branch, then <code>git push -f</code>. If <code>branch1</code> has already been merged, you might need to find the <code>merge-base</code>, or the &lsquo;common ancestor&rsquo; between <code>main</code> and <code>branch2</code> with <code>git merge-base branch1 branch2</code> and run <code>git rebase --onto=main [merge-base-result] branch2</code>.</p>
<h2 id="avoiding-squashed-upstream-changes-in-bottom-of-stack">Avoiding Squashed Upstream Changes in Bottom of Stack</h2>
<p>In this footnote<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, I said to avoid merging from the bottom of the stack up since this usually leaves a bunch of duplicate commits in the branches on the top of the stack as the commit hashes change on merge. But let&rsquo;s say you&rsquo;ve gone ahead and done this anyway, resulting in:</p>
<pre tabindex="0"><code>main (with branch1 changes)
└── branch2 (now with duplicate commits)
</code></pre><p>This gets tricky. My strategy was to try to keep a list of commits from <code>branch1</code> somewhere pre-merge, so that these commit messages can be compared then against <code>branch2</code>. Run <code>git rebase -i HEAD~x</code>, where <code>x</code> is the point at which you branched off <code>branch1</code> to <code>branch2</code>. Then in the interactive menu, drop all <code>branch1</code> commits. After running <code>git rebase main</code> and resolving merge conflicts, <code>branch2</code> should now only contain the changes unique to <code>branch2</code>. Run <code>git push -f</code> and you should be good to go! Phew.</p>
<h2 id="cherry-picking">Cherry-picking</h2>
<p>Another alternative fix for the above situation relies on careful cherry-picking. Let&rsquo;s say you&rsquo;ve branched off of <code>main</code> like the previous example but have merged down <code>branch1</code>:</p>
<pre tabindex="0"><code>main (with branch1 changes)
└── branch2
</code></pre><p>And you&rsquo;re in the same scenario: you need to get rid of duplicate commits in the new base PRs of the stack. Sometimes, when there are a few commits, it&rsquo;s easier to build a new branch with cherry-picked changes from the old <code>branch2</code>.</p>
<p>Run <code>git checkout main</code> and <code>git checkout -b branch2-new</code> to create a new branch incorporating the <code>branch1</code> changes with their new commit hashes. Then as with the previous section, note commit hashes of changes on <code>branch2</code> and cherry-pick them over with <code>git cherry-pick [commit_hash]</code>. You&rsquo;ll have to resolve conflicts along the way, but with smaller branches this can result in less resolution work than dropping commits and rebasing.</p>
<p>If all your <code>branch2</code> commits are consecutive, you can cherry-pick a range of commits all in one go. Run <code>git cherry-pick commit_hash_start^..commit_hash_end</code>. The <code>^</code> denotes to include the first hash, and the <code>..</code> denotes a continuous range between those two commits, inclusive.</p>
<h2 id="merging-changes-from-downstream">Merging Changes From Downstream</h2>
<p>Finally, let&rsquo;s cover how to merge changes down properly. Let&rsquo;s go back to the first example, and let&rsquo;s say you&rsquo;ve branched off main like so:</p>
<pre tabindex="0"><code>main
└── branch1
    └── branch2 ✓
</code></pre><p><code>branch2</code> has been approved. (Maybe <code>branch1</code> has as well, exciting!) The easiest way to merge things down to main from here is to go from the top of the stack (i.e. to go from <code>branch2</code>). This maintains commit hashes and avoids the complex rebasing strategies in the section above.</p>
<p>However, this results in larger diffs being applied <em>all at once</em> to main, so this may not be ideal for continually deploying environments where you&rsquo;d like to test incrementally. This also might not be a great idea if <code>main</code> is significantly ahead of <code>branch1</code> or <code>branch2</code>, which means there&rsquo;s more opportunities for untested breakage due to new <code>main</code> updates. My strategy was to merge down into the second-to-last PR on the stack (<code>branch1</code>), and rebase <code>main</code> into that so I&rsquo;d only have to resolve conflicts once. Then I&rsquo;d test, and once I was sure things were working, I&rsquo;d merge everything into main.</p>
<h2 id="conclusion">Conclusion</h2>
<p>These strategies should be enough to cover most stacked PR workflows - the commands are relatively straightforward, and carried me through a successful internship. However, I&rsquo;ve neglected to mention that there are tools out there that automate most of this workflow for you. While I haven&rsquo;t used it, many of my coworkers at Replit were playing around with <a href="https://graphite.dev/">Graphite.dev</a> at the time. It&rsquo;s a CLI that builds on top of git to handle this lower-level rebasing for you, and automates creating stacked PRs complete with a stack summary message in each PR. It looked useful, especially for the automatic rebasing, but I didn&rsquo;t want to bother migrating my workflow and learning new Git commands just then. I might check it out in the future though - if it can help me avoid rebase hell, I&rsquo;m all for it.</p>
<p>There are also some Git plugins that don&rsquo;t go quite to the extent of automating PR creation as Graphite does, but helps facilitate the details. I&rsquo;ve seen <a href="https://github.com/gitext-rs/git-stack">git-stack</a> and <a href="https://github.com/VirtusLab/git-machete">git-machete</a> mentioned before, as well as <a href="https://github.com/ezyang/ghstack/">ghstack</a> as a lightweight Graphite alternative.</p>
<p>Despite all the intricacies of a stacked PR workflow, I&rsquo;m still strongly convinced that these smaller PRs lead to more efficient PR review and faster development-feedback-ship loops. With it, I was able to ship features consistently and quickly last summer, and am still applying the same workflows at <a href="https://cloudflare.com">Cloudflare</a> this summer. I&rsquo;m sure this&rsquo;ll also be the case in future projects and work. The tooling supporting stacked PR workflows is becoming more robust and mature, and I&rsquo;m betting stacked PRs will become more and more prevalent in the coming years.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>This leads to the caveat that the base few PRs must be approved before the leaf PRs can be merged in. It&rsquo;s good to communicate that to your team when working with stacked PRs! Several times during my summer, my fellow intern and I made slow progress because we were constantly waiting for the base PRs to be approved and shipped before we could build on them again. Also try to avoid merging from the base up - this leads to a bunch of duplicated commits especially if your team uses the &lsquo;squash and merge&rsquo; strategy.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>It got so bad that at one point my fellow intern and I Slack huddled for a couple hours just picking through rebase conflicts. We called it a rebase party (complete with :partyparrot:s). Near the end of my internship, &lsquo;rebase hell&rsquo; became a running joke with my manager and some of my team.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>I recently learned about <code>git rerere</code>, which can help with the repeated rebase conflicts that can arise with stacked PRs. <code>git rerere</code> persists conflict resolutions and automatically tries to re-apply them if the same conflict comes up again later on in the rebase process.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>My preferred strategy, because it didn&rsquo;t leave merge commits in the history.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>The Secret Garden</title>
      <link>https://kewbi.sh/blog/posts/220130/</link>
      <pubDate>30 Jan 2022</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On public and private thought cultivation.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>In the field of personal knowledge management, a popular term&rsquo;s popped up to describe knowledge bases: digital gardens. It&rsquo;s cute and endearly quaint - perhaps it reflects a sort of <a href="https://en.wikipedia.org/wiki/Walden">Walden-esque</a> desire to step away from the hustle of grind culture and bustle of digital life and returning to a humbler life of tending one&rsquo;s knowledge garden. There&rsquo;s a growing trend of publishing your personal wikis online, often complete with little Sprout / Sapling / Tree / Evergreen labels to denote the state of thoughts. The quintessential example I see linked the most is <a href="https://notes.andymatuschak.org/About_these_notes">Andy Matuschak&rsquo;s notes</a>. My good friend <a href="https://knowledge.uzpg.me/">Uzay Girit&rsquo;s</a> started one with his tool <a href="https://github.com/archivy/archivy">Archivy</a>. And many, many more - <a href="https://maggieappleton.com/garden">Maggie Appleton&rsquo;s</a>, <a href="https://www.mentalnodes.com/">Anne-Laure Le Cunff&rsquo;s</a>, and <a href="https://jzhao.xyz/thoughts/">Jacky Zhao&rsquo;s</a>, just to name a few.</p>
<p>These public gardens of thought fill a liminal space between a messy notebook, and more polished blog posts. It&rsquo;s part of the larger trend to work in public, ship in public, and now, think in public - gardens like this spark thoughts and conversations, and can open up room for more experimentation and play. Some blogs can feel corporate and stale, and lack the freshness of digital gardens that are updated weekly, or even daily. Digital gardens take away the pressure to perfect every last word - the phrase &lsquo;garden&rsquo; itself comes with connotations of a certain type of dirtiness, but good dirtiness. They come with the expectation that not everything will be perfect, but that eventually, every little thought and insight will grow, and provide joy and beauty and inspiration.</p>
<p>I could go on about the benefits of digital gardening, but I think plenty of people can do that better than I can<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Instead, I&rsquo;ll discuss some of to preserve your knowledge only for yourself, and garden in private, not public. It sounds selfish and counterintuitive at first - after all, I&rsquo;m sure everyone&rsquo;s had at least one solid insight that&rsquo;d be of use to someone else. And even notwithstanding the value of thoughts and of publishing, there&rsquo;s a certain merit in encouraging people to expand their thinking habits. I know some of the course notes I took likely would be very useful to incoming students; and maybe some of my longer musings on tech culture could be interesting. But with all the practicality and advantages of digital gardens, I think there&rsquo;s a case for walled, secret gardens as well.</p>
<p>There&rsquo;s a novel I used to love as a kid - <a href="https://en.wikipedia.org/wiki/The_Secret_Garden">The Secret Garden</a> by Frances Hodgson Burnett. The main character begins as a spoilt little girl, forced to live with her uncle in a dreary corner of England. She hates her new home, and the people she&rsquo;s made to interact with. The rest of the story isn&rsquo;t really relevant, but the major finding and focal point of the story later becomes a secret garden she finds, tucked away into a corner of the manor. It&rsquo;s locked, but she somehow finds the key. From then on, the main character gradually becomes more carefree and joyous, spending her hours playing in the beautiful garden and having little escapades with the animals there. It&rsquo;s a cute story, but I think it&rsquo;s an apt metaphor for the maintenance and wonders of private knowledge.</p>
<p>This article is a collection of some of my thoughts on private and public memory, thought, and ideation. For the rest of this post, &lsquo;walled garden&rsquo;, or &lsquo;secret garden&rsquo; will refer to private wikis and knowledge bases whose primary intent isn&rsquo;t to be shared, or plainly isn&rsquo;t shared. I&rsquo;ll discuss the tending of these gardens, their benefits, and how they can work together with public digital gardens as well.</p>
<h2 id="pre-emptive-curation">Pre-emptive Curation</h2>
<p>I don&rsquo;t know if it&rsquo;s just me, but I feel that when I write for an audience, and for any person that isn&rsquo;t myself, my tone and my content and my voice changes. When I&rsquo;m writing these articles, I do feel like I&rsquo;m talking to a friend, but it&rsquo;s different than writing my own notes or scribbling away in my personal journal. I worry that if I&rsquo;d start a public garden, I&rsquo;d end up curating for others - imposing structures and optimizing for someone else&rsquo;s experience, not mine. And it&rsquo;s easy to say, &ldquo;Oh, just don&rsquo;t do that! Write as if you&rsquo;re writing for yourself, and no one else!&rdquo;, but to me, putting something out there in the world, even if it&rsquo;s something as small as a post here, is associated with a certain level of polish. That level of polish doesn&rsquo;t have to be very high - read some of my first couple blog posts for a great example of &rsquo;literally only spellchecked&rsquo;. But I&rsquo;d like to think that I do things now with a bit more intention, and that implicit drive to fulfill that resolution shapes how I write.</p>
<p>Having an audience shapes how you write, and how you take notes. At least for me, I felt that when I was working through my <a href="https://kewbi.sh/blog/posts/200629/">CS50</a> or <a href="https://kewbi.sh/blog/posts/201213/">CPSC 110</a> posts, I was writing actively with helping someone in mind. I was including basic things that were glossed over in lectures, and things that I myself already understood. This is good - if I&rsquo;d returned to my notes at any point in time, I&rsquo;d be able to get a bit more of an overview and brush up on the basics. But that&rsquo;s a small example, at least, of my perception of how my own writing changes with more technical explanations that are aimed at people, instead of just for myself. I found myself embedding lots more context - I did this a lot too when I started writing about my notetaking system. Almost every post would include a &lsquo;if you haven&rsquo;t heard of the Zettelkasten system&rsquo;, with the same links and the same references to Ahren&rsquo;s book and Luhmann himself.</p>
<p>In one of his tweets, Linus Lee said <a href="https://twitter.com/thesephist/status/1480274175545724928">that it seems like digital gardens and note dumps are moving to replace longer-form blog writing</a>. I agree - I feel like a good portion of the value of ideas comes from the context they occupy, and the potential they hold to spark future thoughts and ideas. I feel that public gardens tend to shift this focus from the context to the content itself, where often the context surrounding certain ideas is left out of notes entirely, and we&rsquo;re focusing just on the raw ideas. I was introduced to the concept of <a href="https://en.wikipedia.org/wiki/The_Death_of_the_Author">the death of the author</a> in English class last term, and I can see how that concept applies here. Notes in digital gardens can sometimes feel detached from the contexts they came out of, and because they&rsquo;re just published as-is by the author, who&rsquo;s retained all the implicit context but perhaps hasn&rsquo;t written it explicitly, it feels like they&rsquo;re being viewed solely as detached points.</p>
<p>One of the ways digital and secret gardens can work in concert is a sort of mixed publication method. People usually set it up so that they have some public folder in their knowledge base that gets published, leaving their own personal notes with potentially private information unpublicized. This unfortunately means that everything needs to be processed manually before you set up your notes to publish - this leads to more friction, and more time that someone could&rsquo;ve spent tending their own secret garden. However, it&rsquo;s also a good opportunity to revisit notes and think from others&rsquo; perspectives, allowing for opportunities to revise based on new contexts, or based on what others. While it&rsquo;s important to be careful not to overthink the review too much, I think it can also be a useful step of knowledge management regardless.</p>
<h2 id="into-your-mind">Into Your Mind</h2>
<p>Besides the privacy of the content, with publishing anything on the internet, I feel a slight moral obligation to at least double check what I&rsquo;ve written for major factual issues. I feel that, in that case, where I&rsquo;m reviewing even just for editorial errors and the like, I may as well polish things a bit more and turn it into more refined posts that can stand on their own. There&rsquo;s always going to be tacit judgement (? evaluation? there&rsquo;s probably a better word for it) of what you put out there on the internet. I personally feel that it&rsquo;s nicer to put more intention into things like that - I&rsquo;m sharing my voice, after all, and I&rsquo;d like to communicate it as clearly and truthfully as possible.</p>
<p>I tend to feel uncomfortable with taking responsibility for my unfinished work - I remember when I was working on projects last summer, I was loathe to share with friends. When I did, it was always after a caveat or two that &rsquo;this wasn&rsquo;t the final product!&rsquo;, just in case. This is something I&rsquo;m working on - as I mentioned in my <a href="https://kewbi.sh/blog/posts/220102/">2022 goals post</a>, I&rsquo;d like to share what I&rsquo;m doing more often, and gather more perspectives while my work is in progress. Right now, I&rsquo;m still working with this sense of uneasiness - I used to hate it when my friends would read my blog posts. It took me a long time, and I still cringe when they decide to link my posts in chat, but I&rsquo;m starting to feel more comfortable with that type of sharing.</p>
<p>Most of my articles here are works that are at least somewhat finished, and done with having a reader in mind. However, with digital gardens, notes are often a step or two under finished articles or coherent thoughts. If I felt this disconcerted by sharing work that I was already decently proud of, I don&rsquo;t think I&rsquo;d be alright with dumping all my thoughts out into the big, bad Web<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Maybe this is an issue with my personal mindset, but I tend to not like presenting ideas, or versions of things that I don&rsquo;t see as complete. I like having things I share be working at some minimial-viable-thought level at all times - maybe that&rsquo;s just me. For some people, digital gardens allowing them to share incomplete thoughts might inspire them to write more and post more often, but I don&rsquo;t feel that way. Digital gardens offer a window into the running state of consciousness of someone - into how they take notes, and into their mind. Some folks might find this liberating and empowering, but I find that this forces my ideas into certain streams of thinking over and over again. Especially with more personal views or unfinished, brewing thoughts, I think it&rsquo;s alright to leave those in private, secret gardens.</p>
<h2 id="conclusion">Conclusion</h2>
<p>All this lends a sense of responsibility, and of weight, to the task of tending one&rsquo;s digital garden. As an extension of your online identity, you&rsquo;re now in charge of maintaining your wiki. Sure, you could slap a giant notice that this is all to be taken at face value, and that you&rsquo;re not responsible for any errors or liability or whatever, but I still feel that it&rsquo;s too much pressure. I know plenty of people have their own views on this, and their own workflows where they just publish whatever and don&rsquo;t feel like they have to shape their thoughts to fit a specific voice. But for now, setting up a digital garden just isn&rsquo;t for me - perhaps that&rsquo;ll change in the future, I don&rsquo;t know. I think I prefer the quiet tending of a secret garden - one that I can, like in the novel, lock away, yet return to, and find joy in, whenever I like. I like writing for an audience of none (or, well, one) because it gives me freedom to leave thoughts tangled up, in the contexts they came from, and in the phrasing that they first occurred in. It takes away the pressure of having to polish each thought as I write it: I can leave that for another stage of tending my garden.</p>
<p>On one hand of the spectrum, digital gardens that are straight stream-of-consciousness, and true extensions of their landscaper&rsquo;s mind, suffer from high noise : signal ratios. By diluting core thoughts with a network of unfinished, work-in-progress thoughts that haven&rsquo;t fully bloomed yet, it&rsquo;s harder to make information useful, both to the author and to readers. More formal writing can feel distant, and repetitive at times, especially as you&rsquo;ll have to integrate context and evidence and properly support arguments. In short, public digital gardens can feel a bit brain-dumpy, and long-form content can be a bit stifling and formal. Secret gardens, and gardens that are a mix of private and public all across this spectrum, embrace thought&rsquo;s inherent lifecycle well. Secret gardens welcome the inherent stages of thought - because not all thoughts are immediately ready to share. They&rsquo;re a bit more informal and casual, as the primary audience is still just the author. But they allow room for thoughts to grow, take root, become hardy, and eventually be able to be transplanted gently into public gardens.</p>
<p>I see the larger movement towards digital gardens as a sort of reverse &rsquo;tragedy of the commons&rsquo;. Whereas it&rsquo;s usually that people neglect a shared resource for the sake of their own personal gains, assuming that others will take care of it, with digital gardens, I find that there&rsquo;s a lot more room for thought if you assume that you need to help no others, and that you should put writing for yourself at the forefront. There&rsquo;s a fine balance here, between oversharing and undersharing - between not tending a digital garden with the same care as longer, more formal writing, and putting too much thought into the publishing and overthinking it. I&rsquo;m still working on this, but with this blog, I think I&rsquo;ve found that good balance. Most of my articles come from well-connected thoughts that I&rsquo;ve chained together, and almost all of my more complex notes are derivatives of my posts. This way, I can still share the thoughts that I&rsquo;ve worked on the most, and tended the most, but leave the messier, less coherent work in my own secret garden.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Just Google &lsquo;digital gardens&rsquo;, click around a few links, and you&rsquo;ll be greeted with examples of people who are truly experts of thought horticulture.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>There&rsquo;s also something to say about this sense of resistance. Maybe that fact that I&rsquo;m scared, in a way, of sharing like this is a reason to finally start doing so more often.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Time in Writing</title>
      <link>https://kewbi.sh/blog/posts/220116/</link>
      <pubDate>16 Jan 2022</pubDate>
      <author>Emilie Ma (Kewbish)</author>
      <description>On the role of time in iterative writing.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Over my break between my fall and spring terms of university, I&rsquo;d been writing a lot - mostly thinking of new article ideas for this blog. I&rsquo;d finally had more time to read through the huge backlog of interesting articles I&rsquo;d found for myself, so I spent some time riffing off of concepts that I&rsquo;d encountered and wanted to discuss. It was very peaceful to be able to sit down, unencumbered by the prospect of having to grind through endless maths problems, and just write. I honestly felt like I did a lot of good thinking over that break - it was like all the noise finally quieted down, and my brain decided to overcompensate for not doing much concrete work by coming up with a lot of thoughts. I decided to transform some of those thoughtchains into articles, and some into personal notes for myself. Bottom line - I spent a lot of time reading, writing, and musing this break: it was very enjoyable, and a good mental rest before I was thrown back into term two.</p>
<p>One of the things that was on my mind near the start of break was, as usual, still schoolwork. After classes let out for exam period, I still had one assignment left: my English paper<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This was something I&rsquo;d been working on for almost half the term, and was worth a rather significant 25% of our grade. Needless to say, I was stressed about it, even after I&rsquo;d finally sent it off and started studying for other things. But after the chaos of exams faded away, I was still thinking about some of the pain points I&rsquo;d experienced while writing that essay, and specifically about the role of time on my writing. I don&rsquo;t mean time as in the time crunch, though that was certainly fun - I mean how time impacted my the contents of my writing, how my essay went from an outline to an actual paper, and how it changed over that period of time. There were other English assignments for the same class where I followed a similar process - with each piece, I realized just how drastically they&rsquo;d changed with editing; how they&rsquo;d changed over time.</p>
<p>There&rsquo;s a lot of buzzwords surrounding tools for thought, especially those referencing software that claim to bring new mediums for thought, elevating the human consciousness to unlock some magical thinking powers that we didn&rsquo;t see possible. I&rsquo;m only joking, but I think there&rsquo;s opportunities to explore how time is a significant effect on writing and on thought. Building software to be more &lsquo;aware&rsquo;, in a sense, of time has the potential to drive new innovations in tools for thought.</p>
<p>This post is a collection of a few ideas that I came up with while reflecting on writing my essay, particularly focusing on the role of time, history, and perspective on content and expression.</p>
<h2 id="semantic-version-control">Semantic Version Control</h2>
<p>With writing, I usually like having some way to access the history of my files. With Word, I used to be able to enable some option to be able to access the version history - I think a friend recently mentioned this is somehow built directly into the Office 365 product now. However, I currently use Vim for most of my personal notetaking, and LibreOffice for more formal schoolwork. Both of these softwares have ways that I&rsquo;m aware of that could enable me to &lsquo;step through&rsquo; these files in time, sort of like a literary debugger. Within Vim, I could enable the infinite undo tree and be able to track changes that way. LibreOffice, on the other hand, there&rsquo;s a single backup that&rsquo;s on by default, but also a Versions feature that&rsquo;s somewhat reminiscent of source control like Git. Both of these methods are a bit overkill for me at this point - for my Vim writing, it&rsquo;s backed up to a Git repo that syncs automatically each day, and I usually don&rsquo;t update more frequently than that. For my formal schoolwork that I have to write up, I generally just copy paste my main points below any new drafts, or litter my editing with comments that refer back to older versions of the document.</p>
<p>An interesting use case that I found myself thinking about recently is what I&rsquo;d term semantic version control. Maybe &lsquo;semantic&rsquo; isn&rsquo;t a great description for it, but you&rsquo;ll see. My guiding question for this whole thing was &lsquo;why isn&rsquo;t it possible to keep file chunks separated, so I can Ctrl-Z changes in one part of my writing, but not others?&rsquo;.</p>
<p>My reference model of the typical version control software is the ubiquitous Git. As far as I can tell, it operates on line-based diffs, essentially comparing individual lines within files to see where new chunks have been added or removed<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. This works well for most (almost all?) software development, where it&rsquo;s not logical to have files represent any intermediate states in between code changes. If something is committed, we want it to reflect that update. But for writing, and projects with more semantic nuance, it&rsquo;s hard to preserve these &lsquo;in-between&rsquo; states. For example, let&rsquo;s say I have three paragraphs, and I&rsquo;m editing each one. Before I start working, I commit my changes, and when I&rsquo;m done, I also commit my changes. At the end of my revisions, maybe I&rsquo;ve decided that I don&rsquo;t like my changes in paragraph one. Fine - I can revert incremental changes, even in typical VCS like Git (with <code>git checkout -p</code>), but this process is a bit complicated. I&rsquo;ve only tried this once (with a non-binary file), and managing merge conflicts was a nightmare. Perhaps I did the entire thing completely wrong: we&rsquo;ll give it the benefit of the doubt. However, where Git starts breaking apart, or at least being very complicated for this workflow, is when you&rsquo;d be pulling parts of commits all over the commit tree. Maybe you even want to fast-forward a paragraph or two down in the tree and start working off those changes, but how can you apply commits from the future? That&rsquo;s a rhetorical question - I think with enough <code>git checkout</code>ing and <code>git rebase -i</code>ing, a system like this&rsquo;d be possible.</p>
<p>But think of a semantic version control system, where each little atomic piece of writing could be individually manipulated, with its own version history. One way to implement this would be a system where each paragraph (or each sentence, each word, each character, even!) was a unique document, in Git terms. While you could edit the entire thing in one piece, each sub-document, with some arbitrary level of smallest unit, would be able to have its own history and own undo tree. I&rsquo;m reminded of software like Roam and other block-based note-taking systems, which could ostensibly integrate individual history systems for each block. If I understand their system correctly, <a href="https://remnote.com/">RemNote</a> could also do something similar with its &rsquo;everything is a Rem&rsquo; model.</p>
<p>This ties into the post I previously wrote about <a href="https://kewbi.sh/blog/posts/211114/">metadata</a> - here, the aspect of metadata I&rsquo;d be looking to enrich is time. As it stands, the most time-related metadata available for most notetaking systems is the date created, and date last updated. History, another facet of metadata involved in the above system, is also usually not very <em>rich</em>. It can&rsquo;t be manipulated very easily, nor is it intended usually as anything more than a simple worst-case-scenario-only backup system. But in writing, time usually plays a pretty big role, at least in my thought processes. I felt this a lot this past term, especially in some of my writing classes, as I mentioned in the introduction. Sometimes I need to step away from an essay for a couple days, or to keep writing page after page of useless drivel to finally hone down my actual point. With current systems, I&rsquo;m not able to cherry-pick paragraphs from a couple paper versions ago, or use time, in a way, as best as I could be.</p>
<p>There are trade-offs for this model - a major one would be the insane amount of data storage needed to keep infinite undo trees. Even if the scope was limited to the last couple edits, having each individual atomic block have its own history would add many orders of magnitude of both code complexity and storage required. Power users likely have tens of thousands of blocks - storing diffs that may never be used for each of those is likely unfeasible. But I can dream, and I can come up with slightly shoddy systems to replicate behaviour like this with my current systems. As I mentioned, with LibreOffice, I first work on an outline, then copy that entire outline above itself, and work on drafting that into coherent language. Then, when I edit, I either use Track Changes, or if that gets too messy, just make notes of old sentences that might be useful with comments. It gets a bit messy sometimes<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, but it works, and it&rsquo;s pretty satisfying to finally delete everything right before I hand in an essay.</p>
<h2 id="recency-bias">Recency Bias</h2>
<p>In terms of what I write about, one thing I&rsquo;ve noticed about the role of time is that whenever I write, there&rsquo;s a strong influence of wanting to write about what&rsquo;s currently on the top of my head. Over the past few blog posts, I think this&rsquo;s really manifested - I connect to recent conversations I&rsquo;ve had with friends more frequently than, let&rsquo;s say, something I read in a tech book a couple months ago. Maybe that&rsquo;s to say that the books weren&rsquo;t as interesting or as memorable as discussing with friends. Regardless, that memorability, or lack thereof, lends itself to a recency bias that tends to show up in what I write about, and what I draw on to support it.</p>
<p>One example of this, bringing it back to the English essay, was the way I chose the angle from which I decided to study it. We&rsquo;d read several books throughout the term, and I was starting to think about the essay somewhere through finishing the third. That third book happened to be a <a href="https://en.wikipedia.org/wiki/The_Curious_Incident_of_the_Dog_in_the_Night-Time_(play)">play adaptation</a> of <a href="https://en.wikipedia.org/wiki/The_Curious_Incident_of_the_Dog_in_the_Night-Time">Mark Haddon&rsquo;s <em>A Curious Incident of the Dog in the Night-Time</em></a>. I remember feeling like I really wanted to analyze this play - especially as I&rsquo;d read it before for other purposes. I think that was the recency bias kicking in, because I eventually settled on a different work, <a href="https://en.wikipedia.org/wiki/The_Best_We_Could_Do">Thi Bui&rsquo;s <em>The Best We Could Do</em>.</a>. Even though I&rsquo;d initially planned to study the role of memory in <em>TBWCD</em>, I ended up focusing on the themes of family, which happened to be what we were discussing while reading <em>A Curious Incident</em>. Perhaps this is just a coincidence, and maybe I really did end up analyzing Bui&rsquo;s depiction of family simply because that was what I found to be the most interesting and held the most potential for a unique reading. I can&rsquo;t help, however, noticing examples of this throughout the rest of my writing, and wondering if this is one of the strongest effects of time in sharing ideas.</p>
<p>This focus on fresher topics isn&rsquo;t a problem per se, but I&rsquo;ve realized one way to combat this recency would be to have a resurfacing mechanism that brought up old thoughts for you to process again. I think this is why systems like the original Zettelkasten, then workflows like Roam&rsquo;s or Notion&rsquo;s, hold so much promise and are so frequently used. With bidirectional backlinks and endless possibilities for you to stumble onto an old idea that you&rsquo;ll see anew, there&rsquo;s more serendipity at play here to rediscover thoughts. As well, the danger of forgetting ideas that weren&rsquo;t fleshed out as much is diminished with systems like this. Users can be gently reminded of them in due time, when they explore adjacent subjects. I think this is why so many people feel so attached to their personal knowledge management systems - they offer an assurance that their ideas won&rsquo;t be relegated to the bottom of the proverbial bucket. Write up a quick synopsis on this or that, link it and/or tag it up, and forget about it until you magically need it again. For me, I don&rsquo;t use typical PKM software, so I have to do this a bit more manually, but there&rsquo;s a certain sense of happy chance that happens when I go through old folders in search of something. With my system, I suppose this resurfacing is a lot more active rather than passive, but who knows - maybe that strengthens the ideas&rsquo; connections in my own brain.</p>
<h2 id="editing-is-writing">Editing is Writing</h2>
<p>On the other hand, I can also definitely see how time plays a role in editing of my writing as well. Of course, the point of editing is that you can take the literal time to improve your work, and see how it changes over time, but I think time also works to hone your ideas. I&rsquo;ve talked about my <a href="https://kewbi.sh/blog/posts/210516/">outlining system</a> before, but again, going back to the English essay, I&rsquo;ve noticed how my ideas significantly changed over time and through editing. At first, I had ideas all over the place - tying in memory, identity, race, culture, second-hand experiences through a very wobbly thesis. When I first tried to edit things down, I blindly picked the subcategory that had the most sub-points and that I thought would be most relevant (second-hand memory) and chopped up my essay to deal with only that. My thesis got no stronger, and my writing was frankly even more messy - there just weren&rsquo;t that many examples that I could tie into a single overarching statement. But as time went on, as I edited more and pulled in different examples, I somehow had several eureka moments, and I finally realized what it was that I was trying to say.</p>
<p>Part of this comes down to the feeling that sometimes I have an idea, but I can&rsquo;t express it, and I don&rsquo;t even know what it is. It took time (a lot of it, might I add) to distill my analysis down to one line of argument. The thing is, all of my examples <em>had</em> been connected by a central theme (family and identity), but without taking loads of time to write and rewrite, I couldn&rsquo;t come up with the words to put it down, nor the realization of what I actually wanted to write about. When there&rsquo;s a lot of ideas swirling around in my head, it takes time for me to compartmentalize and learn to actually communicate them. In Ahren&rsquo;s famous <a href="https://takesmartnotes.com/"><em>Take Smart Notes</em></a>, he writes that &lsquo;writing is the thinking&rsquo;. My version, I guess, is &rsquo;editing is the writing&rsquo;. My point is that throughout coming up with an idea, and refining that idea, there&rsquo;s always a role of time: of iteration and of interconnection.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I&rsquo;m happy to say, I did much better on the English essay than I expected, and hey, writing it even sparked a long chain of thoughts about the role of time in writing, which turned into yet more writing! Even as I edit this article, I&rsquo;m realizing it is itself a result of the recency bias, and that I went through much the same process of turning a messy brain dump into something slightly more coherent while writing it. I think exploring how time shapes ideas, and how it lets them mull and grow and change completely, is an interesting aspect of thought to consider with regards to the whole tools for thought phenomenon.</p>
<p>While, as I mentioned in the arrangement section, most Zettelkasten-like software already brings some backlinking feature, I&rsquo;d like to see software that plays better with time, history, and resurfacing context. For the semantic version control system I proposed, this might be possible with a very deeply-nested Git-like model. There&rsquo;re possible applications of NLP in doing better backlinking and idea retrieval, in a more serendipitous way. As well, there might be other possibilities in NLP in summarizing thoughts and suggesting potential &lsquo;what was it that you really wanted to say&rsquo;, to help users distill their messages. Those are just a few of the posible ways more time-sensitive tools for thought could be built - and I might start looking into proofs-of-concepts for some of these.</p>
<p>I wrote this post while procrastinating on all the work that&rsquo;s hit with the start of Term 2 here at UBC. It&rsquo;s been kind of crazy the last week - I feel like through the past 5 days of classes I&rsquo;ve done the equivalent of 10+ days of break-time work. It&rsquo;s felt slightly overwhelming - there&rsquo;s been a lot of information and syllabi and course structures thrown at me at once, but we&rsquo;ll get through it. I&rsquo;m enjoying all my classes so far, and all my professors have been super wholesome. We&rsquo;ll see what this new term brings, but my goal is to reach out more - to friends, to professors, to peers. We&rsquo;ll see how that goes.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Interestingly enough, all the parts that I thought my TA would criticize for weak analysis were the parts that they liked, and the introduction, something I was pretty happy with, ended up being the main point of commentary.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Binary files notwithstanding, which according to the <a href="https://git-scm.com/docs/git-diff">git-diff documentation</a> use something like 64-byte chunks.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Cue the <a href="https://www.reddit.com/r/UBC/comments/rpxyo1/essayfinalnomoreeditsv2/">essayfinalnomoreeditsv2.docx</a> memes.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
