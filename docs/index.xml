<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Yours, Kewbish - a collection of articles on tech and thought.</title>
    <link>https://kewbi.sh/blog/</link>
    <description>Latest Yours, Kewbish posts</description>
    <managingEditor></managingEditor>
    
	<atom:link href="https://kewbi.sh/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Cité des Dômes et du Design</title>
      <link>https://kewbi.sh/blog/fr/posts/250413/</link>
      <pubDate>03 Apr 2025</pubDate>
      
      <description>Sur l&#39;exploration de Paris.</description>
      <content:encoded><![CDATA[

<div class="grid-element" style="margin-bottom: 0.5em;margin-top: 2em">
	Hi there! I wanted to practice my French writing, so I decided to work on this blog post about exploring Paris's various domes. This post is only available in French for now, but an English version is coming shortly and will be linked here as soon as it's up.
</div>


<h2 id="introduction">Introduction</h2>
<p>Comme tu peux voir, cet article est un peu different de ceux que j&rsquo;écrivais d&rsquo;habitude. Je suis actuellement à Paris afin de faire un stage à la Sorbonne Université. J&rsquo;avais tellement hâte de m&rsquo;installer dans un nouveau pays et environnement de recherche. De plus, j&rsquo;espérais améliorer mon français. Anecdote : ma matière secondaire à UBC est le français, alors je suis cénsé pouvoir parler français plus ou moins courrament (c&rsquo;est pas le cas).</p>
<p>Je ne connaissais personne quand je suis arrivée. Je suis toujours une personne independante, alors j&rsquo;ai vraiment profité des moments seules en découvrant des nouveaux endroits et musées. Je passais beaucoup de week-ends en flânant autour de ville. Je viens de Vancouver, où il n&rsquo;y a pas beaucoup des vieux bâtiments. C&rsquo;est la raison pour laquelle j&rsquo;étais toujours étonnée par ce que je voyais. La bibliothèque où je travaille de temps en temps est plus vieille que mon pays — c&rsquo;est une dinguerie ! Je marcherais n&rsquo;import où et je trouverais d&rsquo;architecture magnifique : des sculptures au-dessus des portes, des colonnes Corinthiennes, et, le plus attrayant, des dômes.</p>
<p>J&rsquo;explorerais en regardant le horizon et en cherchant des flèches intéressantes. J&rsquo;apprenais à me diriger par les dômes et les autres repères de Paris. Si j&rsquo;ai vu une flèche en or, je saurais que c&rsquo;était le dôme du Hôtel des Invalides. Si je savais que j&rsquo;étais dans le 5e arrondissement environ, je saurais que j&rsquo;étais près du Panthéon. C&rsquo;était un peu comme un jeux : quels sont les endroits historiques que je peux repérer ?</p>
<p>Mais, écoute, quand on est au milieu d&rsquo;une dizaine des dômes, ils commencent à se ressembler. Je voudrais une liste de contrôle : s&rsquo;il y a d&rsquo;or, c&rsquo;est les Invalides; si le dôme est droit et petit et à côté de la Seine, c&rsquo;est l&rsquo;Institut de France; etc. Ainsi j&rsquo;ai cherché une telle liste des dômes, et j&rsquo;étais surprise de trouver <a href="https://en.wikipedia.org/wiki/List_of_d%C3%B4mes_in_France">ce liste</a> sur Wikipedia (ironiquement seulement disponible en anglais, mais c&rsquo;est juste une liste des noms en français, alors ça va). C&rsquo;était plûtot drôle qu&rsquo;on a pris le temps de faire ça, mais ça reste insuffissant de réperer efficacement les dômes. Alors, j&rsquo;ai décidé d&rsquo;écrire cet article pour les décrire et partager un peu des histoires que j&rsquo;ai apprises pendant mon séjour ici.</p>
<p>Concernant le nom d&rsquo;article, j&rsquo;ai constaté qu&rsquo;à Paris, il y a beaucoup de programmes et des bâtiments qui s&rsquo;appelle genre « Cité de &hellip; ». Il y a le site web <a href="https://www.cite-sciences.fr/fr/au-programme/lieux-ressources/cite-des-metiers">Cité des métiers</a>, et je passais tous les jours le <a href="https://www.citemodedesign.fr/fr/">Cité de la Mode et du Design</a> en bus. Selon ChatGPT, c&rsquo;est parce que « cité » indique l&rsquo;idée d&rsquo;un espace central et spécialisé dans quelque chose — ça, je ne crois pas entièrement, mais peut-être ça a du sens. Bref, j&rsquo;ai décidé d&rsquo;appeler cet article « Cité des Dômes et du Design », parce que Paris est une ville vraiment spécialisée dans les dômes magnifiques.</p>
<p>D&rsquo;abord, il faut que je m&rsquo;excuse : désolée pour les fautes eventuelles en français. Ce n&rsquo;est evidemment pas ma langue maternelle, et même si j&rsquo;ai pris trois ans des cours jusqu&rsquo;à un niveau présumé B1, je continue à faire des erreurs fondamentales. J&rsquo;ai essayé de ne pas utiliser ChatGPT etc., j&rsquo;étais seulement accompagné par <a href="https://www.linguee.com/">Linguee</a> — j&rsquo;aime bien son moteur de recherche qui présente immédiatement les résultats en tapant. J&rsquo;ai fait mon mieux de corriger cet article moi-même. Alors, merci pour ta compréhension et allons découvrir les dômes de Paris !</p>
<h2 id="panthéon">Panthéon</h2>
<p>Je crois que le Panthéon est le dôme le plus connu — c&rsquo;est dans le 5e près du Jardin du Luxembourg. C&rsquo;est l&rsquo;endroit où on a enterré des grands hommes et femmes de France, comme Victor Hugo, Voltaire, et Marie Curie. C&rsquo;est très grand, alors c&rsquo;est facile à voir et c&rsquo;est un bon repère pour se diriger dans Paris.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/8/80/Pantheon_of_Paris_007.JPG"
         alt="Figure 1. Panthéon (Moonik, CC BY-SA 3.0, via Wikimedia Commons)"/><figcaption>
            <p><em>Figure 1. Panthéon (Moonik, CC BY-SA 3.0, via Wikimedia Commons)</em></p>
        </figcaption>
</figure>

<p>Le Panthéon était construit par Louis XV qui a juré qu&rsquo;il rénovererait l&rsquo;ancienne église là s&rsquo;il surmontait sa maladie sérieuse. Il a repris du poil de la bête, puis il a chargé <a href="https://en.wikipedia.org/wiki/Jacques-Germain_Soufflot">Soufflot</a> avec l&rsquo;architecture d&rsquo;une nouvelle église. Le Panthéon était une église, puis un lieu laïque où il n&rsquo;y avait pas de messes pendant la Revolution, puis encore une église et finalement c&rsquo;est un lieu laïque pour enterrer les gens importants. C&rsquo;est consacré à Sainte Geneviève (la bibliothèque en face du Panthéon est nommée pour elle aussi) et les murs sont peints avec des oeuvres montrant sa vie, de son enfance pieuse à sa mort. Il y a aussi une série des tableaux consacrée à Jeanne d&rsquo;Arc et quelques autres pour les autres saints.</p>
<p>Je te recommande de prendre le temps pour relever la tête et profiter du toit et sa décoration. C&rsquo;est plein de détails et tableaux. Mes préférés sont lesquels sous le dôme principal où le pendule se situe, dessus les sculptures des vertus.</p>
<p>Pour repérer le dôme du Panthéon, cherche un dôme blanc avec un deuxième coupole dessus. Seulement la couleur suffit pour l&rsquo;identifier, je pense que c&rsquo;est le seul grand dôme à Paris étant blanc.</p>
<p>Si tu cherches un croissant près du Panthéon, je te conseille d&rsquo;aller chez <a href="https://g.co/kgs/QboR7f5">La Maison d&rsquo;Isabelle</a>. Un pote me l&rsquo;a recommandée et j&rsquo;ai trouvé que ça vit vraiment aux attentes. Leurs croissants sont les plus croquants et « crackly » si c&rsquo;est le genre des croissants que tu préfères.</p>
<h2 id="hôtel-des-invalides">Hôtel des Invalides</h2>
<p>Il y a deux (ou plus) dômes dorées à Paris, mais le plus grand est lequel du Hôtel des Invalides, l&rsquo;ancien hôpital pour les invalides de l&rsquo;armée et maintenant un complèxe des musées. Napoléon I est enterré sous le dôme, dans un cerceuil avec six couches de bois, plomb, et pierre. Il y a quatre autres grands coffrets sous le dôme, et ses chapelles sont magnifiques. Le dôme est allumé en soirée et on peut le voir comme la Tour Eiffel au Jardin du Trocadéro.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/4/4e/Cath%C3%A9drale_Saint-Louis-des-Invalides%2C_140309_2.jpg"
         alt="Figure 2. Cathédrale Saint-Louis-des-Invalides (Daniel Vorndran / DXR, CC BY-SA 3.0, via Wikimedia Commons)"/><figcaption>
            <p><em>Figure 2. Cathédrale Saint-Louis-des-Invalides (Daniel Vorndran / DXR, CC BY-SA 3.0, via Wikimedia Commons)</em></p>
        </figcaption>
</figure>

<p>Dans les bâtiments environnant le dôme, il y a le Musée de l&rsquo;order de la Libération, montrant des artifaits de la Seconde Guerre Mondiale; une exposition sur Charles de Gaulle; et beaucoup d&rsquo;autres collections. Les jardins sont plûtot agréable en plus.</p>
<p>Le dôme est facile à repérer, parce que c&rsquo;est vraiment dorée. Le coupole se ressemble à une couronne et la flèche dorée est plutôt grande. C&rsquo;est un autre bon repère, comme le Panthéon.</p>
<h2 id="sorbonne-université">Sorbonne Université</h2>
<p>Ce dôme se situe dans le campus principal de la Sorbonne Université près du Panthéon. Je ne crois pas qu&rsquo;on peut normalement entrer le campus si on n&rsquo;est pas inscrit à l&rsquo;université, particulairement les week-ends, parce qu&rsquo;il y a des agents de sécurité à l&rsquo;entrée qui vérifient des cartes d&rsquo;identité d&rsquo;étudiants<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Mais autrement, la meilleure vue de ce dôme dehors du campus est à la petite place en face de l&rsquo;entrée où il y a la <a href="https://maps.app.goo.gl/w8PPHh44HTk3N8FL8">Statue August Comte</a>.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/8/81/Chapelle_Sainte-Ursule_de_la_Sorbonne%2C_Paris_001.jpg"
         alt="Figure 3. Chapelle Sainte-Ursule de la Sorbonne (Moonik, CC BY-SA 3.0, via Wikimedia Commons)"/><figcaption>
            <p><em>Figure 3. Chapelle Sainte-Ursule de la Sorbonne (Moonik, CC BY-SA 3.0, via Wikimedia Commons)</em></p>
        </figcaption>
</figure>

<p>Ce dôme est principalement bleu foncé mais il a des rayures blanches. C&rsquo;est plus petit des autres dômes. C&rsquo;est un peu difficile de le voir parce que les autres bâtiments environnants sont des hauteurs pareils.</p>
<h2 id="institut-de-france">Institut de France</h2>
<p>Le dôme d&rsquo;Institut de France est directement en face du Pont des Arts<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> et du Musée du Louvre. Il s&rsquo;abrit les grandes académies célèbres, comme l&rsquo;Académie Française qui gère la formalisation de la langue française.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/6/68/Institut_France.jpg"
         alt="Figure 4. Institut France (Benh LIEU SONG, CC BY-SA 3.0, via Wikimedia Commons)"/><figcaption>
            <p><em>Figure 4. Institut France (Benh LIEU SONG, CC BY-SA 3.0, via Wikimedia Commons)</em></p>
        </figcaption>
</figure>

<p>Dans l&rsquo;institut, il y a aussi la Bibliothèque Mazarine qui est merveilleuse. C&rsquo;est entièrement gratuit d&rsquo;entrer et l&rsquo;ambiance est vraiment sombre et academique. C&rsquo;est pas forcément « dark academia » et certainement pas « light academia » mais quelque chose agréable au milieu.</p>
<p>Le dôme est vraiment pareil que le dôme de la Sorbonne, étant gris foncé avec des rayures blanches. En revanche, le dôme de la Sorbonne a des rayures singles, mais ce dont l&rsquo;Institut de France a des rayures en paires.</p>
<h2 id="basilique-du-sacré-coeur">Basilique du Sacré-Coeur</h2>
<p>La Basilique du Sacré-Coeur se trouve à la pointe de la butte Montmartre, donnant sur la ville de Paris. Je la mentionne à la fin d&rsquo;article, parce que je trouve que c&rsquo;est amusant d&rsquo;y aller pour contrôler tout ce que j&rsquo;ai appris sur le repérage des dômes et d&rsquo;autres bâtiments. Au moins le dôme du Panthéon est visible, je crois que les autres sont un peu trop petits.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/c/c5/Le_sacre_coeur.jpg"
         alt="Figure 5. Le Sacré-Coeur (Tonchino, CC BY-SA 3.0, via Wikimedia Commons)"/><figcaption>
            <p><em>Figure 5. Le Sacré-Coeur (Tonchino, CC BY-SA 3.0, via Wikimedia Commons)</em></p>
        </figcaption>
</figure>

<p>La Basilique du Sacré-Coeur est une des basiliques mineures en France dont il y a 176 en total. C&rsquo;était construit grâce aux plaintes de Napoléon III, qui avait attribué ses défaits en guerre au « déchin moral de France ». Dans ce cas, moi, je ne dirais pas ça, mais enfin le résultat est superbe. Il y a beaucoup de vitrails qui allument vivement la basilique quand il fait beau.</p>
<p>Il y a cinq « dômes » de la basilique dont le plus grand est le dôme central. C&rsquo;est le seul endroit que j&rsquo;ai décrit qui a plusieurs dômes, alors c&rsquo;est facile de les repérer. Ils sont blancs et allongés avec des petits tours. C&rsquo;est possible de monter le dôme pour une vue spectaculaire sur Paris, moins cher qu&rsquo;une ascension à la Tour Eiffel. Je ne pense pas qu&rsquo;ils soient visible au centre-ville de Paris, alors c&rsquo;est pas un repère utile, mais ça mérite une visite quand même.</p>
<h2 id="conclusion">Conclusion</h2>
<p>J&rsquo;ai concentré sur les dômes qu&rsquo;on peut voir facilement dans le horizon de Paris, mais il y a quelques autres dômes que je n&rsquo;ai pas visité mais que j&rsquo;ai vu:</p>
<ul>
<li><a href="https://www.tribunal-de-commerce-de-paris.fr/">Le Tribunal de commerce</a> sur l&rsquo;Île de la Cité, qui se ressemble un peu ce dont la Sorbonne.</li>
<li><a href="https://www.pinaultcollection.com/fr/boursedecommerce">La Bourse du commerce</a> dans le 1e, qui est en verre et un peu plus plat que les autres.</li>
<li><a href="https://www.operadeparis.fr/">Le Palais Garnier</a> dans le 9e, qui est très plat aussi et uniquément vert.</li>
</ul>
<p>Merci d&rsquo;avoir supporté mes pensées mal structurées sur un sujet entièrement niche. C&rsquo;était un exercise utile afin de pratiquer mon écriture et de revivre mes meilleurs souvenirs de Paris. J&rsquo;espère que ça sera utile si tu te trouves n&rsquo;importe quand à Paris.</p>
<p>Enfin, je voudrais vulgariser un nouveau événement à Paris que j&rsquo;ai fondé avec mon pote <a href="https://uzpg.me/">Uzay</a>. C&rsquo;est un node de <a href="https://socratica.info/">Socratica</a> qui s&rsquo;appelle Parenthèse. C&rsquo;était toujours mon but d&rsquo;assister plus régulièrement un node Socratica, alors en voyant qu&rsquo;il n&rsquo;y avait pas de Socratica ici et que nous cherchions une communauté, on en a commencé un. Ça a lieu tous les samedis à 11h à <a href="https://www.digital-village.com/villages/paris">Digital Village Paris</a> (on est toujours à une grande table à gauche du bar). Si tu t&rsquo;y interesses, abonne-toi à notre <a href="https://lu.ma/a5q5tgxy">Luma</a>, nous serons ravis de te voir !</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Je suis plutôt heureuse que j&rsquo;ai réussi à accéder au campus — je les ai montré mon convention de stage pour l&rsquo;autre campus (Jussieu) et ils m&rsquo;ont permis d&rsquo;entrer. Peut-être le fait que je leur ai demandé en français m&rsquo;a aidé un peu (ils m&rsquo;ont démandé d&rsquo;où je viens et ils ont deviné le Japon.) Comme on dit sur tech Twitter, tu peux juste faire des choses !&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Anecdote : le Pont des Arts est le pont célèbre où tous les amoureux mettaient des « serrures d&rsquo;amour », mais c&rsquo;était trop lourd pour le Pont, alors ils étaient tous coupés et maintenant il n&rsquo;y a que du plexiglas. C&rsquo;est plûtot mignon qu&rsquo;il y avait des gens travaillant de les couper de temps en temps, c&rsquo;est un rappel qu&rsquo;il faut rester pratique même avec des questions de coeur.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>A Captive Audience</title>
      <link>https://kewbi.sh/blog/posts/250316/</link>
      <pubDate>16 Mar 2025</pubDate>
      
      <description>On free WiFi portals.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Finding free WiFi has been very ingrained into how I use the Internet. Until last summer, I didn&rsquo;t have a data package on my phone plan. Whenever I&rsquo;d be out and about off-campus, I had to rely on free WiFi. I remember scurrying around for scraps of signal on the boundaries of whatever coffee shop had guest WiFi in order to ask my friends where they were or check maps. When I open my laptop in any new library, café, or airport, the first thing I do is connect to the free WiFi. On Etsy, there are thousands of results when I search for &ldquo;free wifi sign&rdquo;, so business owners and digital artists alike must be aware that free WiFi is highly in demand.</p>
<p>I&rsquo;ve been lucky to grow up in a city and in contexts where WiFi was more or less available when needed: I put off getting data for as long as I did because I was always either at university, or at home, or on the bus between the two, all of which had free WiFi. WiFi has never felt like a commodity or resource to be carefully rationed. I&rsquo;ve always just kind of expected that it&rsquo;d be there.</p>
<p>This last year, I&rsquo;ve had the opportunity to do a lot of travelling, and that also means connecting to a lot of free WiFi while in transit and in new environments. Fun fact: if you use <a href="https://networkmanager.dev/">NetworkManager</a> on Linux, you can run <code>sudo ls /etc/NetworkManager/system-connections</code> to get a list of all of your previous connections, which by default are saved to enable autoconnection whenever the network is in range again. I&rsquo;ve accumulated a bunch of train networks: I have the <a href="https://www.upexpress.com/en">UP Express</a>, <a href="https://www.viarail.ca/en">VIA Rail</a>, and <a href="https://eurostar.com/">Eurostar</a> connections saved. I also have many a coworking space and café, as well as a sprinkling of hotels.</p>
<p>All this travelling and all this free WiFi also meant a lot of WiFi <a href="https://en.wikipedia.org/wiki/Captive_portal">captive portals</a>. Captives are the interstitial page that usually displays the company&rsquo;s information and the standard usage terms and conditions before you&rsquo;re able to meaningfully access the network. You might have to provide your email or phone number for data harvesting purposes, and in the world of airline WiFi, they&rsquo;re also used for requiring payment upfront, but I won&rsquo;t be focusing on paid WiFi here. After you submit the form, you&rsquo;re released from your Internet captivity and can begin normally using the network. They&rsquo;re a staple of free WiFi access, and I&rsquo;d suspect most folks&rsquo; brains don&rsquo;t even process the form before just trying to click through as fast as possible.</p>
<p>Despite these portals popping up on an everyday basis, have you ever wondered how they work — how they&rsquo;re triggered, usually without your interaction? In April last year, I was in Seattle for <a href="https://kewbi.sh/blog/posts/240602/">OSSNA2024</a>, and after getting back to my hotel, I was trying to log in to the guest WiFi network to check my email. I signed my phone in first, which worked without a hitch: a terms and conditions page popped up and asked for my room number before I could get access. Same goes for my parents&rsquo; devices. But on my laptop, I was only able to connect to the network — my status bar applet was showing full connection and I had an IP address assigned — but I couldn&rsquo;t figure out how to get the captive portal to show up so I could actually get access to anything. After some educated futzing around with the URLs of past free WiFi portals that were still in my browser history, I managed to open the hotel&rsquo;s WiFi portal from an old, unrelated <a href="http://www.gstatic.com/generate_204"><code>gstatic.com/generate_204</code></a> link. Since then, I&rsquo;d been wondering how this worked — why did captive portals seem to be all using this <code>gstatic</code> thing? Why did my phone always get a portal while my laptop was hit-or-miss?</p>
<p>This is a post about captive portals, HTTP hijacking, and the hardcoded URLs that tech companies use to trigger popups. I&rsquo;ll also take a brief detour into the world of Parisian libraries and how I automated one of their captive page logins. I hope this&rsquo;ll serve as a fun behind-the-scenes look at what happens when you hit up a new coffee shop and connect to their network for the first time.</p>
<h2 id="o-popup-wherefore-art-thou">O Popup, Wherefore Art Thou?</h2>
<p>When you connect to a WiFi network that uses a captive portal, the IP address assignment takes place as usual with <a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol">DHCP</a>. Your machine and the DHCP server (usually your router) perform a two round-trip exchange to offer, request, and acknowledge your assigned IP address.</p>
<p>From this point onwards, there&rsquo;s a couple ways that captive portals are implemented.</p>
<ul>
<li>For one, DHCP servers can return DNS server addresses in <a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol#Options">their responses</a>. A free WiFi network can set their firewall to only allow captive users to use the network&rsquo;s DNS server for all resolution at first, and then only return the IP address of the captive portal page for all lookups. The firewall can be configured to allow noncaptive users to use other DNS servers once they&rsquo;ve authenticated.</li>
<li>Otherwise, networks might use HTTP redirects: all web traffic is pointed first at an intermediary server that returns a redirect to the captive portal page. When your client device first connects to the network, it sends a request to a standard captive portal detection URL) and checks the status code to see if the network allows unfettered access or if it redirects to a portal page. This only works with HTTP sites, though, because with HTTPS, the router can&rsquo;t do anything with the intercepted traffic: it doesn&rsquo;t have the decryption keys, so it can&rsquo;t modify it; if it returns a different certificate with the response, the browser will show a certificate error. If a site uses <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security">HSTS</a>, any attempts to downgrade the traffic to HTTP to redirect to the captive portal will fail. HTTPS sites are therefore difficult for captive portals to intercept.</li>
<li>Besides all this hijacking, there&rsquo;s an <a href="https://datatracker.ietf.org/doc/html/rfc8910">RFC</a> to introduce a new standardized DHCP option for routers to inform clients of the captive portal enforcement. The proposed option would contain the URI of the captive portal page. For networks not using a captive portal, the RFC specifies a sentinel value to use to avoid the client having to perform captive portal detection. There&rsquo;s another <a href="https://datatracker.ietf.org/doc/rfc8908/">RFC</a> for specifying a similar HTTP-based API.</li>
</ul>
<p>The exact URLs used for captive portal detection differ per client. The <a href="http://www.gstatic.com/generate_204"><code>gstatic.com/generate_204</code></a> that I used in Seattle to trigger the captive portal redirect is controlled by Google, and <a href="https://www.chromium.org/chromium-os/chromiumos-design-docs/network-portal-detection/">Chrome has a similar link</a>. iOS tries to load <a href="http://captive.apple.com/">captive.apple.com/</a> when connecting. Both of these are HTTP links, so can be redirected or hijacked as necessary by the portal. If a captive portal is in place, the <code>204</code> status or success page won&rsquo;t load (and may replace itself with the captive portal&rsquo;s page). Another site that&rsquo;s often recommended is <a href="https://neverssl.com"><code>neverssl.com</code></a>, which exists for the sole purpose of having a reliable HTTP url to load (that won&rsquo;t be redirected by the browser to an upgraded HTTPS connection). I use this to force the captive portal page to load whenever Chrome&rsquo;s detection doesn&rsquo;t quite work.</p>
<p>I think my captive portal detection was hit-or-miss in the past because I would <em>sometimes</em> have HTTP sites open in Chrome previously, which would auto-load after starting my laptop or reconnecting to WiFi, and sometimes I&rsquo;d have tabs full of HTTPS only. The latter is more frequently the case because most sites nowadays default to HTTPS. Chrome will remember which sites do support HTTPS and automatically load the HTTPS versions, even if you type in a HTTP URL. However, Chrome has a whole <a href="https://www.chromium.org/chromium-os/chromiumos-design-docs/network-portal-detection/">page on portal detection</a>, so I&rsquo;m not sure why their solution has been so spotty in the past.</p>
<p>Linux&rsquo;s <code>NetworkManager</code> also has some configuration options to <a href="https://wiki.archlinux.org/title/NetworkManager#Captive_portals">automatically open captive portal pages</a> on desktop managers that don&rsquo;t automatically do so. You&rsquo;ll have to write a dispatcher script to start a browser instance if <code>NetworkManager</code> detects that the network&rsquo;s connectivity state is a portal. <code>NetworkManager</code>&rsquo;s portal detection uses the <a href="http://ping.archlinux.org"><code>ping.archlinux.org</code></a> URL, but this can be configured via the <a href="https://wiki.archlinux.org/title/NetworkManager#Checking_connectivity"><code>[connectivity]</code> option</a>. I haven&rsquo;t set this up, since just opening the browser and visiting a HTTP site has worked well enough for me.</p>
<p>The upshot for captive portals on the Internet is that you&rsquo;ll need some sort of web browser on any device, and I&rsquo;d bet this is part of why web browsers are so prevalent on devices like TVs where the interaction feels awkward. There&rsquo;s a lot of complaining on various electronics community forums about one&rsquo;s TV not connecting to captive networks: these browsers likely don&rsquo;t implement proper portal detection, so folks have had to come to the same conclusion of putting in the portal&rsquo;s URL directly, since sometimes even redirects don&rsquo;t work.</p>
<h2 id="sainte-geneviève-meet-networkmanager">Sainte-Geneviève, Meet NetworkManager</h2>
<p>The <a href="https://www.bsg.univ-paris3.fr/iguana/www.main.cls">Bibliothèque Sainte-Geneviève</a> is one of the main public libraries in Paris. It&rsquo;s right by the <a href="https://fr.wikipedia.org/wiki/Panth%C3%A9on_(Paris)">Panthéon</a>, which is a nice view if you get stubbornly stuck in the hours-long queue for a spot that sometimes snakes across the end of the block<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I really like working there when I&rsquo;m not in the lab — in general, high ceilings and big windows are my jam, and the BSG&rsquo;s vaguely Art Nouveau roof design and vaulted ceiling with tonnes of windows checks all my boxes.</p>
<p>What&rsquo;s more, the BSG provides both a lovely working environment <em>and</em> free WiFi for registered readers. WiFi is blocked behind a captive portal asking for your library card number and account password: by default your birthday in DDMMYYYY format. I was writing part of this post at the BSG, so out of curiosity I poked around at the portal page.</p>


<style>
/* https://github.com/lonekorean/gist-syntax-themes */
@import url('https://cdn.rawgit.com/lonekorean/gist-syntax-themes/d49b91b3/stylesheets/one-dark.css');
body .gist .gist-meta {
  color: #ffffff;
  background: var(--sub-colour); 
}
body .gist .gist-meta a {
  color: #ffffff
}

.gist ::-webkit-scrollbar {
background: #141414;
}

.gist {
--borderRadius-medium: 8px;
}

</style>
<script src="https://gist.github.com/kewbish/9f9664bd268d7a640ff6390ab700826b.js"></script>


<p>This page just <a href="https://gist.github.com/kewbish/9f9664bd268d7a640ff6390ab700826b#file-bsg-captive-portal-html-L65">fires an AJAX login request</a> based on the card number and password you provide. The <code>zoneid</code> variable is set by a separate <code>zone.js</code> script, which seems to statically set it to 0.</p>
<p>Some networks, particularly those that require a login and password, do a better job at remembering users after captive portals. However, because this captive portal came up every time I visited, I wondered if I could automate login with a simple shell script so I wouldn&rsquo;t have to fill the form in myself.</p>
<p>I learned that Linux&rsquo;s <code>NetworkManager</code> supports <a href="https://askubuntu.com/questions/13963/call-script-after-connecting-to-a-wireless-network">dispatcher scripts</a>, which are run whenever a connection changes. It passes several environment variables, including the <code>CONNECTION_ID</code> SSID, and two arguments: the interface name and event type (like &ldquo;up&rdquo;). The scripts must have <a href="https://man.archlinux.org/man/NetworkManager-dispatcher.8.en">certain permissions set</a> as well. You can reference <a href="https://man.archlinux.org/man/NetworkManager-dispatcher.8.en">the dispatcher documentation</a> for more details.</p>
<p>For my use case, a simple script wrapping a <code>curl</code> command was enough. This script will run the <code>curl</code> on every connection change to an &ldquo;up&rdquo; state on all connections with the SSID &ldquo;BSG Public&rdquo;<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># in /etc/NetworkManager/dispatcher.d/bsg.sh</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># run:</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># $ sudo chown root:root /etc/NetworkManager/dispatcher.d/bsg.sh</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># $ sudo chmod 755 /etc/NetworkManager/dispatcher.d/bsg.sh</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> <span style="color:#f92672">[</span> <span style="color:#e6db74">&#34;</span>$2<span style="color:#e6db74">&#34;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;up&#34;</span> <span style="color:#f92672">]</span> <span style="color:#f92672">&amp;&amp;</span> <span style="color:#f92672">[</span> <span style="color:#e6db74">&#34;</span>$CONNECTION_ID<span style="color:#e6db74">&#34;</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;BSG Public&#34;</span> <span style="color:#f92672">]</span>; <span style="color:#66d9ef">then</span>
</span></span><span style="display:flex;"><span>	curl -X POST <span style="color:#e6db74">&#34;http://portail.bsg.univ-paris3.fr:8000/api/captiveportal/access/logon/0/&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>		 -H <span style="color:#e6db74">&#34;Content-Type: application/json&#34;</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>		 -d <span style="color:#e6db74">&#39;{&#34;user&#34;: &#34;[USERNAME]&#34;, &#34;password&#34;: &#34;[DDMMYYYY]&#34;}&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fi</span>
</span></span><span style="display:flex;"><span>exit $?
</span></span></code></pre></div><p>And with that, I no longer had to fumble for my library card to log in every time I connected. I haven&rsquo;t tried poking into other captive WiFi network pages to see what they require behind the scenes, but I figure it&rsquo;d be easy enough to scrape pages to find the &ldquo;accept conditions&rdquo; checkbox and network request and automate logins with a similar curl command.</p>
<h2 id="conclusion">Conclusion</h2>
<p>TL;DR: whenever you connect to a new network, if you get certificate errors on all your HTTPS sites or can&rsquo;t access anything and don&rsquo;t get a captive portal page, open <a href="neverssl.com"><code>neverssl.com</code></a>, which should get you to the captive portal page.</p>
<p>I wrote this post primarily to share this <code>neverssl.com</code> tip, which would have saved me a lot of time retrying free WiFi connections with no luck and resigning myself to doing work on my phone. Whenever I encounter networking problems, I tend to chalk it up to it &ldquo;just being a Linux thing&rdquo;, but in this case, captive portal implementations are unstandardized and slightly janky on all providers. In this case, Linux and <code>NetworkManager</code> actually let you hook into network connections more easily, and as I&rsquo;ve shown, we can automate portal logins relatively easily even if the underlying portal implementation doesn&rsquo;t support it.</p>
<p>In my earlier section on captive portal implementations, I mentioned there were a couple RFCs on better standardizing captive portal interactions. While the RFCs themselves date to around five years ago, it seems like there&rsquo;s been some progress on supporting them in both <a href="https://developer.apple.com/news/?id=q78sq5rv">iOS</a> and <a href="https://developer.android.com/about/versions/11/features/captive-portal">Android</a>, but there&rsquo;s still work to be done for adding support to <a href="https://news.ycombinator.com/item?id=41922225">other major DHCP servers and router hardware</a>. Overall, though, providers seem to have converged on a set of detection and portal display techniques that work for most cases, so I don&rsquo;t know if there&rsquo;ll be much movement in this area going forward.</p>
<p>Diving into captive portals was fun — there&rsquo;s so many other similar interactions on the Web that are ubiquitous but never something that you really think about. Getting to dig to the spec and RFC level for a small, self-contained area as well as coming up with a little artifact is a nice way to get an overview of an API or area. Writing shorter technical posts is also quite refreshing after my recent run of heavier explainers: more rabbitholes (and café free WiFi connections) to come in the future!</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>As I&rsquo;m finishing this blog post, the queue is to the end of the block, so I&rsquo;ve been resigned to sitting on one of the little rock benches across the street just barely in range of the WiFi.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>If you want to limit the script to only a specific connection (and not just all networks called &ldquo;BSG Public&rdquo;), you can also look into the <code>.nmconnection</code> files in <code>/etc/NetworkManager/system-connections</code> to find its UUID and update the script to check the <code>$CONNECTION_UUID</code> variable instead. This UUID will <a href="https://unix.stackexchange.com/a/351010">differ per device</a> even on the same connection, so for the sake of making this script more universal I opted to use the <code>CONNECTION_ID</code>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>FOSDEM Follies</title>
      <link>https://kewbi.sh/blog/posts/250302/</link>
      <pubDate>02 Mar 2025</pubDate>
      
      <description>On Brussels and treasure hunts.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>A couple weeks ago, I gave a talk about <a href="https://kewbi.sh/blog/posts/250223/">Kintsugi</a> at <a href="https://fosdem.org/">FOSDEM</a>, a massive free and open-source software conference welcoming thousands of developers around the world at the <a href="https://www.ulb.be/fr/plans-et-acces/solbosch">ULB Solbosch</a> campus in Brussels. I hustled myself onto the first Eurostar to Brussels early Saturday morning and returned Sunday evening with my bag laden with goodies and a camera roll significantly fuller with incredible architecture. I&rsquo;ve never been in Brussels before and wanted to explore the city a bit despite only being there for the weekend, so I had a very packed Saturday at FOSDEM and an equally hectic trek around downtown Brussels on Sunday. But in between, I still got to run into friends, meet new folks, and have a stop at neat museums (for free!) — a very fulfilling trip.</p>
<p>The most surprising thing about FOSDEM was its sheer scale and professional organization despite being entirely free and not requiring registration. The hallways were very crowded, not to speak of the main stands rooms and larger keynotes, and there were constant flows of people everywhere. The organizers&rsquo; communication, prep, and signage was super clear, however, and there were plenty of information volunteers milling around. Everything seemed to run like a well-oiled machine (it was the 25th time they ran this, after all) and I&rsquo;m very impressed that this was all a volunteer effort with no formal governing body. The website estimates &gt;8K people attending, and even from the main train station and tram stops in Brussels it seemed like you could pick out at least one attendee wherever you were (wearing bright tech merch and a well-stickered laptop were usually dead giveaways.) It felt like throngs of people were flooding through the city to get to various meetups, beer nights, and talks. In spite of this, however, apparently even locals were unaware of the event: I had some friends from Brussels that I met at <a href="https://kewbi.sh/blog/posts/241006/">DARE</a> who had only found out because I&rsquo;d told them about my talk. Perhaps locals chalked up the surges of hoodie-clad, Android-wielding folks to a little mid-winter peak of tourism.</p>
<p>The scale of FOSDEM means that it&rsquo;s just a lot to take in, especially if it&rsquo;s your first time. I&rsquo;ll confess I went through a few survival guides before attending, such as <a href="https://petersouter.xyz/fosdem-survival-guide/">this</a>, <a href="https://marcin.juszkiewicz.com.pl/2019/10/15/how-to-survive-fosdem/">this</a>, and <a href="https://ounapuu.ee/posts/2024/02/12/fosdem-2024/">this</a> to get a sense of how things worked. Still, I&rsquo;m not sure if any survival guide (including this one) can really prepare you for it. For instance, a common thread was not being able to get into popular talks and devrooms, which makes sense, especially for popular technologies like Rust and Go and so on. I wasn&rsquo;t expecting to not be able to get into even the Security devroom — but more about this later. The advice in other survival guides was certainly helpful, particularly for day-of logistics and recommendations for side events and other attractions in Brussels. While I maybe didn&rsquo;t engage as deeply in the event as the seasoned veterans that&rsquo;ve written other guides, I wanted to share thoughts from a first-timer&rsquo;s perspective and compare it to <a href="https://events.linuxfoundation.org/open-source-summit-north-america/">OSSNA</a><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>This is a post about my FOSDEM experience and survival tips, my attempt to solve the treasure hunt that was run, and my haphazard trip planning process. I very much enjoyed the experience — major props to all the organizers, volunteers, and team members for putting together such a vibrant and well-put-together-yet-scrappy conference.</p>
<h2 id="-le-jour-j-2">« Le Jour-J »<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></h2>
<p>Between my talk getting accepted and actually speaking, I spent most of my preparation time finishing up the implementation and making sure it was in a presentable state instead of prepping for the talk itself. I&rsquo;d given a similar presentation on Kintsugi once internally at <a href="inkandswitch.com">Ink &amp; Switch</a>, so I&rsquo;d already prepared slides and was banking on reusing them mostly unedited for my FOSDEM talk. What I didn&rsquo;t account for was that this first presentation was &lt;20min in length total, whereas FOSDEM slots were 25min. You&rsquo;d be surprised how long coming up with 5min of content takes, from writing a script to making diagrams, but I ended up spending a decent chunk of the time I&rsquo;d allotted to preparing for FOSDEM on revamping the slides with some new cryptography background. As with my <a href="https://kewbi.sh/blog/posts/240609/">OSSNA talk</a>, I ended up with a slightly uncomfortable lack of time to run through the talk, but I was able to get to a decent level of fluency between talking points, and the talk went alright after all.</p>
<p>On the day-of, I was feeling very confident given the smooth trip to Brussels and no hitches on public transport. I arrived to the campus 15 minutes before the Security devroom, which I was presenting in, would start, so I figured I&rsquo;d be able to grab a seat early and check that my HDMI adapter worked. Alas, by the time I rounded the stairwell to the room, I saw the corridor packed with people and a &ldquo;This room is full!&rdquo; sign on the door. The room itself was a smaller lecture theatre, with a capacity of 50 or so. I also had the misfortune of speaking directly after the <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-4204-tightening-every-bolt/">curl maintainer</a>, which was the second talk of the devroom, so everyone had the same idea of coming early for the first talk to snag a seat for the later talks, just like all those FOSDEM guides recommended. I tried to squeeze in before the curl talk, but no one really budged, so I wasn&rsquo;t able to get in until they were calling for the speaker in the hallway for my session. Lesson learned: FOSDEM is much bigger than I&rsquo;d expected, and many more people than I&rsquo;d thought are into security. There were a couple other talks that I wanted to get to, but I ran into the same problems with a full room, so it might be worth just going to soak the atmosphere in in a single room (something like the Lightning Talks room would have been interesting with the amount of variety) and watching through other talks that you&rsquo;re most interested in content-wise afterwards online.</p>
<p>You can find a recording of my talk <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-5266-kintsugi-a-decentralized-e2ee-key-recovery-protocol/">here</a>. You can also read a blog post version with a few more notes on implementation details <a href="https://kewbi.sh/blog/posts/250223/">here</a>. I won&rsquo;t go over my talk content again, but I did want to say that all the questions and couple of email exchanges with folks afterward were very meaningful and honestly heartwarming. Someone even said my talk was their <a href="https://chaos.social/@neverpanic/113930981715315172">favourite of the day</a>, which really made my day.</p>
<p>The projector setup was fairly painless — I was very surprised that my HDMI adapter worked first-try, since it usually gives me some headaches until I apply the correct series of suspend and login incantations to get my displays to be recognized. They gave me a lapel mic and told me to stand within a certain space at the lectern to stay in the camera frame. All of the live streaming and recording was very smooth, with participants being able to chat in the Element room and view the talk in real time. I was very pleasantly surprised with how smooth the video infrastructure was, and perhaps <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-6714-fosdem-infrastructure-review/">their talk</a> might go into this in more depth? After the conference, they emailed me a link to review my video and choose the start/end crop times, which I thought was very professionally done.</p>
<p>A group of students caught me as I was leaving the room to say they liked my talk, which I really appreciated! We chatted for a bit about how I prepared for the talk: my presentation style was more practiced and script-based than the other talks that I&rsquo;d listened to. I&rsquo;ve found that writing out a script and essentially memorizing it helps counter my tendencies towards filler-words and not being very grammatically coherent. While I&rsquo;ve been warned that practicing too much would make one sound stiffer, I think this is where limited prep time actually helped: I knew the gist of the flow, and key verbs and flows of sentences, but it wasn&rsquo;t so rote that I&rsquo;d be reciting the script word-for-word, and I&rsquo;d switch up the order of points or restructure phrases each time I&rsquo;d run through the talk. This underpreparing-to-overprepare technique probably has downsides that I haven&rsquo;t come to notice yet, though, so I don&rsquo;t know if I&rsquo;d recommend this.</p>
<p>In terms of speaker experience, I&rsquo;d say it was pretty good: the recording process was very well-done with a fast turnaround and the audience was very engaged (and it was a full room!) I would have appreciated some earlier guidance on speaker prep, which I later found was published <a href="https://fosdem.org/2025/manuals/program/speaker/">here</a>, and a little more day-of information on when/where to turn up, especially as a first-timer. Major props to the volunteers manning the Security devroom, though — they were very supportive and helpful!</p>
<h2 id="around-fosdem">Around FOSDEM</h2>
<p>FOSDEM manages to have a very high-production-value structure and be incredibly well-run while retaining the right touches of cheeky, hackery culture. The treasure hunt, for example, was a nice touch, and it was hilarious to see the accessories and costumes that different companies put on (I recall an electric-blue PostgreSQL elephant suit and a sea of VLC cone hats). There was also reportedly beer and Club Maté being sold at a couple &ldquo;bars&rdquo; dotted around, and I&rsquo;ve been told this is peak hacker-core. In the hallways, everyone would good-naturedly grumble together about missing this or that talk or the endless lines, but it seemed that everyone was having a great time.</p>
<p>My first FOSDEM tip would be to spend an hour or so beforehand looking through the devroom list, mapping out where the most interesting ones are (see next point). There&rsquo;s so many talks (this year had 1104 events) that it&rsquo;s very difficult to narrow things down as you&rsquo;re wandering between buildings day-of. As I mentioned above, it might be helpful to limit yourself to just a couple devrooms even if there&rsquo;s particular talks that you really want to see, since it takes time to go between rooms and shuffle through the crowd. I think a great part of FOSDEM is just sitting and soaking up the energy, which is a bit harder to do if you&rsquo;re darting around between each talk. Devrooms also operate on different cadences (e.g. 20min talks, 15min talks) and start times, so it gets tricky to coordinate when to switch between physical locations. Come up with an ideal talk itinerary, then fill it in with other talk options. Leave time to explore the stands too, and don&rsquo;t get too attached to your schedule if something else catches your eye day-of.</p>
<p>Another tip would be to look up the campus map and familiarize yourself a bit with where the major buildings are (U, which has A/B/C/D blocks, H, etc.) ahead of time. The signage is good once you get into a building, but in the main avenue I did have to stop to look at the large signposts and pinpoint where buildings were a couple times. There&rsquo;s <a href="https://play.google.com/store/apps/details?id=be.digitalia.fosdem&amp;hl=en">FOSDEM companion apps</a> (<a href="https://apps.apple.com/us/app/fosdem-app/id1513719757">iOS</a>) that help visualize this. These apps can also help you keep track of your talk wishlist as well as figure out which other devrooms are close by should you miss your first choice or if it&rsquo;s full.</p>
<p>There&rsquo;s a few nice green spots on campus: there&rsquo;s a lawn with steps by the parking lot by the K building, facing some smaller buildings and a bit further away from the bustle of the main road. I saw lots of people picnicking here, especially with the sunny weather. The law building at the end of the campus (the one with the nice clock tower spire) also has a little green space that&rsquo;s a little less crowded. I think the buildings that host the info booth, etc. change each year, but these tend to be the biggest buildings with the most popular talks, and thus also very busy. I didn&rsquo;t explore too much beyond the main FOSDEM buildings, so I&rsquo;m sure there&rsquo;s other spots I&rsquo;m missing.</p>
<p>In terms of food, there aren&rsquo;t too many options directly on the campus besides the couple of food trucks down the main avenue. They&rsquo;re not too overpriced, given that they&rsquo;re food trucks at a conference, but it&rsquo;s mostly finger food like burgers and fries and sweets. I might be tainted by my experience of more American events, with a lot more, slightly gimmicky, options. I&rsquo;m not sure if the cafeteria on campus was running, but I saw folks with takeaway containers of pasta, which wasn&rsquo;t sold by any food trucks, so I think some of the sandwicheries and cafés might also have options. Make sure to look for the Mozilla cart giving out free cookies! It&rsquo;s good sustenance while you brave the miles-long queue for any of the trucks. Definitely bring a water bottle — I wasn&rsquo;t looking for water fountains but didn&rsquo;t immediately notice many. You could probably also do with protein bars and skip the food truck lines, but either way there&rsquo;ll be options on campus.</p>
<p>FOSDEM was only my second major conference, so my expectations for swag and boothing were on-par for the largest North American open-source conferences with hefty ticket prices and even steeper booth costs. FOSDEM&rsquo;s stands are very different — much more casual and less corporate presentation posters, and more demos and folks talking about the tech. This also means that there&rsquo;s not much free swag besides stickers, and in fact most of the shirts and bags and whatnot are at a fixed price to help support the tools. I like this approach more, since you can directly financially contribute to the projects and have a bit more of a check and balance before grabbing tons of free swag that you won&rsquo;t ever use back home. I was looking for a neat tote bag to bring back, but I instead got some <a href="https://nlnet.nl/hex/">NLNet stickers</a> and a cute 3D printed Grafana mascot. If you&rsquo;re looking for FOSDEM-specific merch, you can buy them at the information desk with the stands in building K as well as the other info desk in building H. One point where I&rsquo;d like to contradict other survival guides is that you don&rsquo;t have to rush to get merch: where other folks have suggested that you go first thing, I thought the line was absurdly long (although the volunteers kept it moving super quick) and there was plenty of stock left over at the end of the day in all sizes, from what I could see. Since there&rsquo;s only two places you can buy the official merch, it makes sense to avoid the bottlenecks and go later in the day or on Sunday.</p>
<p>I&rsquo;d also suggest seeing if any open-source communities you&rsquo;re involved with or are interested in are hosting side events — as they say, the best part of FOSDEM is the <a href="https://en.wiktionary.org/wiki/hallway_track">hallway track</a> and the fringe events. You can browse through the list of <a href="https://fosdem.org/2025/fringe/">fringe events</a> on the site for larger events, and you should ask around in your friend circles to see if anyone else&rsquo;s going. I unexpectedly bumped into a friend from UBC that was studying abroad in a different country and somehow made their way to Belgium, and I caught up with some friends that I met at a distributed systems summer school. Some communities might not have formal stands, like the <a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a>, who staked out a spot by the entrance to the K building unofficially, and there are plenty of unofficial casual gatherings as well. Historically, there&rsquo;s been a beer night at the <a href="https://www.deliriumvillage.com/bar/delirium-cafe/">Delirium Café</a> Friday/Saturday night, and a big hacker party with light displays and live music at <a href="https://bytenight.brussels/">ByteNight</a> at the Brussels hackerspace. On my part, I went to a closed GSOC mentors/students meetup at BrewDog, and was debating going to ByteNight but instead walked around at night, which was probably a much better idea since Brussels looks so different at night.</p>
<p>One last FOSDEM tip: if you&rsquo;re interested in <a href="https://volunteers.fosdem.org/">volunteering</a>, you can certainly register ahead of time, but you can also just turn up day-of and go to the information booth to ask if they need help. One of my friends came on Saturday, realized that he could volunteer (for the CV points, but still), and asked on the spot if he could volunteer on Sunday. I&rsquo;m sure it&rsquo;s more of a the-more-the-merrier situation, so you could also consider this if you find yourself bored and unable to get into any talks.</p>
<h2 id="treasure-hunt">Treasure Hunt</h2>
<p>This year, FOSDEM also ran a <a href="https://fosdem.org/2025/news/2025-02-01-update-treasure-hunt/">treasure hunt</a> on the side — I think it might have been the first year that one was run, at least from what I found online. I initially passed over the hunt, knowing I&rsquo;d only have a day at FOSDEM and wanting to make the most of it by attending talks, but my curiosity was piqued when I realized that the odd noises playing from a speaker outside Building H were part of the puzzle. I&rsquo;d initially assumed someone had set up some public art, was doing some experimentation, or had connected their speakers to the wrong wires, but I later realized it was because <a href="https://fosdem.org/2025/news/2025-02-01-update-treasure-hunt/">the original treasure hunt signs were stolen</a> and they&rsquo;d had to set up a makeshift station outside.</p>
<p>I was super into puzzling and riddles when I was younger — the <a href="https://www.ted.com/search?q=TED-ED+riddle">TED riddle series</a> was a favourite to binge-watch, and I only started playing CTFs in the pursuit of the guessiest &ldquo;crypto&rdquo; challenges that valued knowledge of obscure ciphers rather than actual math. So it&rsquo;s no surprise that I got nerdsniped, and spent my last hour on the ULB campus trying to decipher the riddles instead of listening to the talk I was sitting in for.</p>
<p>No one managed to solve the riddles during the conference, and given that the signs were made available online, the hunt&rsquo;s still going on and the prize is still up for grabs, at least as far as I know. I didn&rsquo;t manage to find anyone else to drag into this, so I wanted to leave my thoughts as a starting point for others who might still be poking into this. Again, you can see the signs <a href="https://fosdem.org/2025/news/2025-02-01-update-treasure-hunt/">here</a>.</p>
<p>For the first riddle, the little &ldquo;1&rdquo; measure and the mention of the radius made me think of counting up the radius of the concentric circles, which ended up being 15. I&rsquo;m not sure what the &ldquo;one set spins as two&rdquo; or the &ldquo;cradle of worlds&rdquo; were meant to lead to. Googling &ldquo;cradle of worlds&rdquo; brought up some notes about various historic sites, but I can&rsquo;t imagine having to pinpoint any of them in relation to the diagram. The &ldquo;set&rdquo; and &ldquo;union&rdquo; made me think of something related to finding how to split the circles up such that their rotation would reveal something, but that seems farfetched to me. It might also have something to do with the building names and where the location of the next sign in the original hunt would have been, since both S and U were buildings where FOSDEM activities were taking place, but there aren&rsquo;t any room numbers mentioned <a href="https://fosdem.org/2025/schedule/rooms/">here</a> that start with &ldquo;15&rdquo;, and I doubt the organizers would have wanted more people crowding in these rooms.</p>
<p>For the second riddle, it immediately looked like a logical-and equation. I&rsquo;m not sure what base the numbers are supposed to be interpreted as. I tried base-10: doing the chunk-wise and (e.g. <code>102 &amp; 111</code>) and converting back to an ASCII character gave me &ldquo;fped&rdquo;. I also tried octal, which gave me &ldquo;@HA@&rdquo;, and hex, which gave me &ldquo;ĀĐāĀ&rdquo;. Out of these, the base-10 looks most plausible. The question mark being upside down at the bottom of the equation made me think about flipping the results visually, which just looks like &ldquo;pedt&rdquo; and didn&rsquo;t give me any more leads. The &ldquo;speech alone could not house our dreams&rdquo; might also lead to <a href="https://en.wikipedia.org/wiki/Braille_ASCII">Braille ASCII</a>, although the 2/4 digits wouldn&rsquo;t make sense, or other non-text-related encodings.</p>
<p>For the third riddle, I didn&rsquo;t get anything promising from either the excerpt or the diagram. I thought it might have something to do with a map overlaid on top of the ULB campus, but it doesn&rsquo;t seem to match up. I did note that not all the potential intersections are marked, so if you&rsquo;d have extended the lines, there would have been more intersections, but if the treasure hunt was originally designed to be played at one single location, they probably wouldn&rsquo;t want folks to mark up the sign while solving, so I don&rsquo;t think this leads anywhere. There are also some intersections that are super close together, which made me think about processing the coordinates via some scripts, but again, the hunt was originally designed to be played in person without direct access to the graphics. I did count the intersections, of which there are 28.</p>
<p>For the fourth riddle, the audio puzzle, I awkwardly stood in front of the speaker for a few minutes to record the sample, which attracted some odd looks and curious questions. The sample&rsquo;s now available online, which saves you the effort. The ungainliness of recording the speaker was actually a silver lining though. A passersby mentioned that the initial jingle in the soundbite is the <a href="https://en.wikipedia.org/wiki/Lincolnshire_Poacher_(numbers_station)">Lincolnshire Poacher number station</a>&rsquo;s theme. A <a href="https://en.wikipedia.org/wiki/Numbers_station">numbers station</a> is a radio station containing loops of numbers that are ostensibly directed at intelligence agents working abroad to receive messages or decrypt transmissions. This matched what the audio file seemed to be quite well. The audio contains the Lincolnshire Poacher theme followed by groups of numbers, each repeated three times. The deduplicated numbers were:</p>
<pre tabindex="0"><code>10 14 11 15 13 23 6 26 7 8 5 12 19 3 2 17 20 24 16 18 21 4 9 25 22 1
</code></pre><p>It was hard to hear the recording in-person given the background noise and speaker quality, so the <a href="https://ftp.belnet.be/mirror/FOSDEM/video/2025/treasurehunt/four.ogg">OGG online</a> was very helpful. I noted that all the numbers were less than 26, which likely means that they correspond to entries in the alphabet. Applying the <a href="https://www.dcode.fr/letter-number-cipher">A1Z26 cipher</a> gives you <code>JNKOMWFZGHELSCBQTXPRUDIYVA</code>. There are also exactly 26 numbers, and no numbers are repeated, so this led me to believe it&rsquo;s some substitution cipher key, but I&rsquo;m not sure where the ciphertext is.</p>
<p>For the fifth puzzle, the text &ldquo;all threads converge&rdquo; made me think this was likely combining the results of the first three puzzles. Add 103 to the result of the first puzzle (15), take the first three characters of the second riddle&rsquo;s answer (ped, if we consider flipping), then multiply the third riddle&rsquo;s result (28) with 754. If we assume an ASCII encoding, the first character should be 118, which decodes to &ldquo;v&rdquo;, so the first part might be &ldquo;vped&rdquo;. Not sure what the third riddle&rsquo;s result was, but if it was 28 then this bit should be &ldquo;21112&rdquo;. This might have been some location-based riddle, since there <a href="https://www.ulb.be/medias/photo/plan-solbosch01-09-22_1662016341684-png?ID_FICHE=8914">was a V building on the Solbosch campus</a>, but it wasn&rsquo;t marked as part of the FOSDEM activities. In that case the &ldquo;21112&rdquo;, or whatever the number really was, might be a reference to a room number that led you to the last riddle. It&rsquo;s hard to figure out which clues were meant to lead to which physical locations and which were for the riddle at hand, but perhaps the signs&rsquo; riddles weren&rsquo;t meant to lead you to the next riddle and the locations of signs was just a general scavenger hunt?</p>
<p>For the sixth puzzle, it seems pretty obviously ASCII as hex, which gives you <code>aulnvzmhdat</code>. I&rsquo;m not sure if this is too obvious? I figure this might have to do with the substitution cipher key from the fourth riddle, but decrypting it with <code>JNKOMWFZGHELSCBQTXPRUDIYVA</code> as an alphabet gave me more gibberish. This might also depend on the fifth puzzle, since the organizers mentioned puzzles were intended to be sequential.</p>
<p>Other miscellaneous notes:</p>
<ul>
<li>The appendix names and volume numbers, in order, are &ldquo;M3B459&rdquo;</li>
<li>The reference to &ldquo;sol&rdquo; in &ldquo;the book of sol&rdquo; might be a reference to the <em>Sol</em>bosch campus, or maybe the FOSDEM logo that, if you squint, could look like a sun</li>
<li>None of the riddles should require image processing, making a copy of the signs to mark them up, or fixing extremely precise coordinates/measurements, given how the hunt was originally designed for in-person play</li>
<li>The riddles should have some sequential aspect as mentioned by the organizers, so there may be clues I&rsquo;ve missed that need to bleed into the next riddles (or maybe this just refers to the fifth riddle and how you need to solve the first three first?)</li>
<li>I can&rsquo;t make out specific references to what might be a room number or location clue versus what&rsquo;s about the final ciphertext, particularly while playing online</li>
</ul>
<p>Feel free to <a href="https://kewbi.sh/about/#contact">email me</a> if you make any more progress or solve the puzzle — I&rsquo;d love to read a writeup!</p>
<h2 id="tant-de-conseils-touristiques3">Tant de conseils touristiques<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></h2>
<p>I also wanted to say a few words about Downtown Brussels. Because the trip was so short and because I&rsquo;d been so busy moving and settling in in the preceding weeks, this was my most last-minute trip planning ever. I didn&rsquo;t buy tickets for anything ahead of time and was sitting on Google Maps the night before my train trying to piece together an itinerary. I think embracing the fact that I had very limited time and was only going to do very touristy things helped cut down on a lot of the decision fatigue, since planning then reduces to a constraint satisfaction problem of what order to visit the top 10 Brussels must-sees in and what meals/foods I wanted to try. I hadn&rsquo;t learned much about Brussels before, so I had absolutely no idea what the major monuments or foods were, and thus also no expectations for what things would be like.</p>
<p>For my itinerary, I took liberal inspiration from the <a href="https://fosdem.org/2025/sightseeing/">tours that FOSDEM organizes</a> for partners and kids who might not be interested in a tech event. I also had a few recommendations from friends, who, being from Brussels, were mildly jaded about things not being very interesting or authentic, but of course coming from a much younger city and drastically different culture I was fascinated by everything. Here&rsquo;s what I went by:</p>
<ul>
<li>the <a href="https://www.atomium.be/">Atomium</a>, a scaled-up version of an iron atom made for the &lsquo;58 expo with very neat modern art installations</li>
<li>the <a href="https://www.hallegatemuseum.be/">Porte de Halle</a>, one of the last remaining parts of Brussels&rsquo; original city walls</li>
<li>the <a href="https://www.visit.brussels/en/visitors/venue-details.Brussels-Palace-of-Justice.232780">Palais de Justice</a>, the courthouse with amazing panoramic views (and when I was there, an <a href="https://www.thebulletin.be/giant-octopus-symbolising-fantastical-brussels-enjoys-temporary-home-place-poelaert">octopus statue</a> outside)</li>
<li><a href="https://www.ot-honfleur.fr/en/Honfleur/unmissable-in-honfleur/saint-catherine-church/">Sainte Catherine Church</a> and the <a href="https://www.cathedralisbruxellensis.be/en/">Brussels Cathedral</a></li>
<li>the <a href="https://www.brussels.be/grand-place-brussels">Grand Place</a>, the town hall and trades buildings, with some very gilt detailing and the Brussels Museum — my favourite part of the trip and absolutely worth seeing both lit up at night and during the day</li>
<li>the <a href="https://en.wikipedia.org/wiki/Manneken_Pis">Manneken</a> (and Jeanneken and Zinneke) <a href="https://en.wikipedia.org/wiki/Manneken_Pis">Pis</a>, statues of a little boy/girl/dog peeing</li>
<li>the <a href="https://www.grsh.be/">Galeries Royales Saint-Hubert</a>, a covered shopping street not unlike the Parisian covered galleries</li>
<li>The quadrifecta of Bruxellois gustatory delights are waffles, « moules-frites » (mussels with fries), beer, and chocolate. I&rsquo;ll let you make your own conclusions on which places to try and if they&rsquo;re all that they&rsquo;re stacked up to be…</li>
<li>I also just walked around a lot near the Grand Place looking at neat buildings and taking it all in!</li>
</ul>
<p>The list above is generally ordered in how you could potentially approach a day in Brussels, starting from the Atomium, which is a little further out, and ending in the centre of the city by dinner with plenty of time to go on side quests in between. It&rsquo;s easy to get around by tram and bus, with plenty of convenient stops, which you can tap in/out of with your phone&rsquo;s wallet app. Google Maps is perfectly sufficient for navigation: sometimes the French/Dutch names of lines or stops will differ, but it&rsquo;s obvious by context where you are. If I remember correctly, most of the transit instructions/signs are also available in English.</p>
<p>As I mentioned above with the FOSDEM swag, my backpack space was fairly limited, so in terms of souvenirs, I wanted to get something small. I have this thing that I call strategic souvenirs: back home, I have a collection of little engraved glass skylines of cities (<a href="https://www.google.com/search?q=3d+glass+paperweight">like this</a>) and my parents are working on a Christmas ornament collection from around the world. This makes self-control much easier, since I usually only ever buy things in those two categories, and as a bonus both are small and light. I ended up getting a little Atomium keychain that we can use as an ornament, and it&rsquo;s super cute.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I&rsquo;m very grateful for the opportunity to have attended FOSDEM and to share my work to so many. The timings aligned so well this year, making travelling to attend much more feasible. This might be the only time in a while that I&rsquo;ll be able to attend given I&rsquo;m normally based in Vancouver — flying across the Atlantic for a weekend conference is a bit much, especially if it&rsquo;s open-registration and there aren&rsquo;t any travel grants. There&rsquo;re quite a few academic-focused conferences in Europe that I&rsquo;d loved to attend as a volunteer/student, like <a href="https://www.eurosys.org/">EuroSys</a>, but the times don&rsquo;t overlap as well with my current trips and again it&rsquo;s not really worth it if I&rsquo;m normally in Vancouver. Nevertheless, it was interesting to get a glimpse into the European open-source community and travel to a new country, and returning to FOSDEM is definitely on my radar if I&rsquo;m ever in Europe this time of year again.</p>
<p>Speaking of travel, I really enjoyed taking a short weekend trip like this: it feels very low-commitment and overwhelming-in-a-good-way. Europe is so small that you can cross country borders within a couple of hours by train, and it&rsquo;s even faster by flight. Compared to North American travel, where 4H can <em>maybe</em> get you between two cities in the same province (Toronto to Ottawa), transportation feels so fast and is fairly inexpensive. The differences in architecture, landmarks, languages, and local vibe change so drastically in such a small distance. Daytrips to completely different regions and one-night stays in other countries feel so tractable now, and even exploring in a single city has so much to offer. I realize this is a very North American take, since it&rsquo;s just that everything seems so shiny and possible and new since I haven&rsquo;t been exposed to much of the platonic ideal of Europe, but it&rsquo;s been fun exploring so far and I hope to do more short sojourning.</p>
<p>I plan to be back to writing shorter posts more frequently soon. My last few posts have all been on the order of 5K words, which is fun to brain-dump and write, but it leads to more investment in each post, especially if it&rsquo;s more technical and there&rsquo;s a lot of research or explanatory diagram creation required. This makes me procrastinate on writing, and my backlog of smaller ideas just keeps growing. There&rsquo;s a few (shallower) rabbitholes that I&rsquo;d like to write about here that will probably fit in more digestible chunks, so expect to see more of that in the coming months.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Like the Netflix-famous <a href="https://en.wikipedia.org/wiki/Emily_in_Paris">Emily in Paris</a>, I&rsquo;m here to provide more of <del>an American</del> a Canadian perspective.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>&ldquo;D-Day&rdquo; in French. Slightly unrelated: <a href="https://en.wikipedia.org/wiki/Languages_of_Belgium">some notes on French vs. Dutch (and German) in Belgium</a>. It&rsquo;s a fairly major political issue in Belgium, and from what I&rsquo;ve heard, there are entirely separate government systems in each language.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>&ldquo;So much tourism advice&rdquo; in French.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Kintsugi</title>
      <link>https://kewbi.sh/blog/posts/250223/</link>
      <pubDate>19 Feb 2025</pubDate>
      
      <description>On decentralized E2EE key recovery.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Last term, I wrote a couple of posts on cryptography concepts (on <a href="https://kewbi.sh/blog/posts/241020/">OPRFs</a> and on <a href="https://kewbi.sh/blog/posts/241229/">Lagrange interpolation</a>). In the conclusion of each of these posts, I&rsquo;ve alluded to a new, related project that I&rsquo;ve been working on this last term. That project is <a href="https://github.com/kewbish/kintsugi">Kintsugi</a>, and I&rsquo;ve recently had the opportunity to present it at <a href="https://fosdem.org">FOSDEM</a>, widely regarded as the biggest open-source conference around. I realized that I&rsquo;d never shared in-depth details about Kintsugi or how it works, and I thought I&rsquo;d edit and republish my talk in article format. This post is a capstone to this series of crypto explainers, highlighting how we&rsquo;ve combined ideas from both OPRFs and Lagrange interpolation to create a decentralized key recovery protocol for E2EE platforms.</p>
<p>Kintsugi&rsquo;s elevator pitch goes as follows: Using E2EE apps mean that you&rsquo;re solely responsible for keeping a copy of your keys, but what happens when you lose your device or backup files? E2EE apps like WhatsApp and Signal have recovery mechanisms, sure, but these schemes rely on one centralized provider that manages all the special hardware and servers that might be needed. Kintsugi is instead decentralized, based on a P2P network of recovery nodes. To recover your key, you use your password and communicate a threshold of your recovery nodes. Thanks to some fun crypto, though, these recovery nodes can&rsquo;t brute-force access to your data offline, and even colluding recovery nodes can&rsquo;t gain access to your account. Kintsugi doesn&rsquo;t rely on all of these nodes being reachable, just a threshold of them, so it can remain operational even if some recovery nodes go offline. Kintsugi therefore lets you use a familiar password-based authentication scheme while retaining E2EE security properties and protecting against brute-force and recovery node collusion.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p>This post will first cover some prior E2EE key recovery work, including the schemes that are used by the most popular E2EE apps today. If you&rsquo;re impatient, you can skip through to the demo <a href="#demo">here</a>. Then, I&rsquo;ll detour into the basics of a couple cryptography primitives to recap this series&rsquo; prior two posts before covering the specific communication flows between recovery nodes. I&rsquo;ll also add some of my hard-learned lessons from implementing Kintsugi in Rust with libp2p and Tauri.</p>
<p>If you&rsquo;d prefer to watch through a video, you can find the recording <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-5266-kintsugi-a-decentralized-e2ee-key-recovery-protocol/">here</a>. The slides are also available <a href="https://emilie.ma/talks/fosdem2025">here</a>. Tab back over to <a href="#implementation-details">the implementation details section</a> after you&rsquo;re done watching, since I don&rsquo;t cover the actual system architecture or the P2P app architecture in much depth in my live talk.</p>
<h2 id="background-context">Background Context</h2>
<figure><img src="/img/250223/1.png"/>
</figure>

<p>So, to contextualize the problem space a bit, let&rsquo;s consider what happens when you lose your phone but want to regain access to data on some app you&rsquo;d installed. With a non-E2EE app, you can just download the app again and log in with the same username and password. Your password can be checked against whatever the app server stores, and the server can return your data. However, if the app is E2EE, then this isn&rsquo;t possible. The app server doesn&rsquo;t store your password, recovery key, or anything to help you decrypt whatever encrypted backup data is stored on the server. There are a couple main recovery mechanisms: to name a few, you can set a recovery PIN, some apps let you designate a recovery contact, or you could store recovery codes or hard copies of recovery files.</p>
<figure><img src="/img/250223/2.png"/>
</figure>

<p>Unfortunately, these schemes each have tradeoffs. For example, Signal and WhatsApp <a href="https://signal.org/blog/secure-value-recovery/">both</a> <a href="https://faq.whatsapp.com/2183055648554771/">use</a> some sort of PIN-based system for recovery. You set your account&rsquo;s recovery PIN, a 4-to-6 digit code, from which a recovery key is derived and used to decrypt your backups. However, such a short code is easy to brute-force, so services must provide some form of rate-limiting. This usually relies on secure hardware, like <a href="https://en.wikipedia.org/wiki/Hardware_security_module">hardware security modules</a>, which will ensure that recovery attempts can only be performed once every so often. These HSMs are fairly expensive to run, though — Signal&rsquo;s preprod system, with a very limited scale, cost over $2K a month to run — and can be difficult to deploy.</p>
<p>There are also recovery contacts, where you can designate a friend or a group of contacts, to help you recover your account. <a href="https://support.apple.com/en-us/102641">Apple iCloud</a> is one such platform that lets you set up a recovery contact. The issue with social recovery schemes, though, is that you have to deeply trust your contacts. While, in some cases, you&rsquo;ll have to provide some personal information during recovery, as iCloud requires, this is often guessable. On some platforms like <a href="https://preveil.com/">PreVeil</a> that enable groups of recovery contacts, a threshold of contacts are able to collude behind your back to reconstruct your recovery key in entirety without your input or knowledge. This isn&rsquo;t good, as it essentially gives your recovery contacts all-powerful recovery access to your account (and remember that an account is only as secure as its least secure recovery option.)</p>
<p>Finally, some platforms like LastPass require you to store a set of recovery codes. Along the same lines, crypto wallets usually require you to store some seed phrase of 24 words or so, from which your private key is derived. These recovery codes are less prone to brute force concerns, since they&rsquo;re longer and higher-entropy, so you don&rsquo;t have to worry about expensive specialized hardware. On the other hand, this requires keeping a copy of the recovery codes or files around. Folks tend to misplace these, either digitally or physically, leading to total account lockout if you ever lose the files altogether. Also, because recovery codes are high-entropy and not as memorable as a password, it&rsquo;s much more difficult to commit them to memory.</p>
<figure><img src="/img/250223/3.png"/>
</figure>

<p>These recovery schemes also rely on some centralized app provider or source of trust, and this centralization comes with its own drawbacks. The model of a central authority controlling all the servers and hardware associated with an app simply doesn&rsquo;t work for some contexts. For example, apps that require metadata privacy, like <a href="https://www.torproject.org/">Tor</a>, wouldn&rsquo;t work well with an all-powerful, potentially-malicious provider. Other applications may be at risk of having their infrastructure shut down if they need to run everything on a single cloud provider, or perhaps the service lacks the concept of a responsible, central authority in the first place, as is the case with instance-based forums, for example. Infrastructure can also be cost-prohibitive, especially if the platform&rsquo;s design requires specialized hardware, like the HSMs that Signal and WhatsApp use. Running these HSMs is complex and expensive, which limits the amount of decentralization possible — you can&rsquo;t really use a volunteer-based operator model like Tor does if the hobbyist contributors can&rsquo;t afford specialized hardware. Overall, while centralized recovery mechanisms work for existing apps, we wanted to explore a new space for recovery protocols in our research, particularly exploring schemes that were completely decentralized and didn&rsquo;t require any specialized hardware.</p>
<figure><img src="/img/250223/4.png"/>
</figure>

<p>This is where Kintsugi comes in! It&rsquo;s a decentralized key recovery protocol based on a peer-to-peer network of recovery nodes. These nodes might be recovery servers run by different providers, end-user devices of social recovery contacts, like your friends, or a mix of the two. With Kintsugi, users recover their keys by providing their password and contacting some threshold <code>t+1</code> of recovery nodes. These recovery nodes each store some share of a secret that&rsquo;s needed to help the user reconstruct their key. Users can also update their recovery nodes at any time, which is something that&rsquo;s ideal in a context where we plan to apply Kintsugi to, for example, recover access to a collaborative doc where you have changing collaborators. Kintsugi defends against brute force attacks on the password, malicious, colluding recovery nodes, and can remain operational with offline nodes.</p>
<p>Before I go further into how Kintsugi works, though, I wanted to go through a quick demo just so you can get a sense of what Kintsugi can help us do.</p>
<h2 id="demo">Demo</h2>

<video src="/img/250223/demo.mp4" controls="controls" muted="muted" style="max-width:100%;border-radius: 8px;margin-bottom: .8em"></video>

<p>You can check out the implementation for this demo <a href="https://github.com/kewbish/kintsugi">here</a>. Kintsugi is implemented as a P2P app in Rust, with <a href="https://libp2p.io/">libp2p</a> for the communication layer and <a href="https://v2.tauri.app/">Tauri</a> with React for the demo app&rsquo;s UI — more about this implementation <a href="#implementation-details">later</a>. This demo just shows the UI of the &ldquo;user&rsquo;s&rdquo; node, but each Kintsugi node can serve as a recovery node for other Kintsugi nodes, and there&rsquo;s no distinction between &ldquo;users&rdquo; and &ldquo;recovery servers&rdquo;.</p>
<p>In this video here, I walk through a user registering with a service that uses Kintsugi. Let&rsquo;s say this service is an encrypted notepad service, and for simplicity, all you can do is read and write to a locally encrypted file. In this case, Kintsugi is used to protect the key used to encrypt this file.</p>
<ul>
<li>In the video, we first walk through registration. The user chooses their username and password, then configures their recovery nodes. The service can also do this opaquely in the background for the user. We&rsquo;re just using a set of bootstrap nodes that I&rsquo;m running separately in the background here.</li>
<li>Then, we write to the encrypted notepad.</li>
<li>Next, we delete the local login file to simulate device loss. This file holds the key that was used to encrypt the notepad, and is used for local login. So now, we no longer have a local copy of the key we need to decrypt the notepad.</li>
<li>We then initiate recovery from our recovery node peers. The mapping from username to recovery nodes is stored in a <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">distributed hash table</a> that can be queried globally without knowing any particular recovery data. We then initiate a recovery request with our username and password, which starts communicating with our recovery nodes behind the scenes.</li>
<li>Now, we can see that the keypair was successfully recovered and that we&rsquo;re logged back in. As well, the notepad can now be decrypted, and we can read back what we wrote earlier. Finally, local login works again, since we&rsquo;ve persisted our key locally again.</li>
<li>We can also change the set of recovery nodes or the threshold for recovery and repeat the same recovery process. This is Kintsugi&rsquo;s recovery node refresh flow.</li>
</ul>
<h2 id="background-context-bis">Background Context, bis</h2>
<p>(This section will duplicate content from the previous blog posts about OPRFs and Lagrange interpolation, but I&rsquo;m keeping it in here because someone mentioned that the diagrams very clearly explained the math, and to be honest I&rsquo;m still riding the high from the acknowledgement!)</p>
<figure><img src="/img/250223/5.png"/>
</figure>

<p>I&rsquo;ll keep the crypto light to keep things accessible, but I wanted to briefly cover the basic concepts behind the main building blocks of Kintsugi here. For one, the cryptographic primitive we use to preserve E2EE properties and ensure that the recovery nodes can&rsquo;t find out anything about the user&rsquo;s password or final recovery key was via an <em>Oblivious Pseudo-Random Function</em>, or an OPRF.</p>
<p>An OPRF is a type of function where a user inputs a secret value, which we can call <code>U</code>, and their server inputs their own secret value, which we can call <code>S</code>. Evaluating an OPRF requires both the user and server to provide their secret values. However, only the user learns the function&rsquo;s output, <code>F(U, S)</code>, whereas the recovery nodes that participated don&rsquo;t learn anything at all: specifically, not the output of the function. Neither party learns anything about the other&rsquo;s secret value.</p>
<p>How does this work? The key is in what we call <em>blinding</em>. You can think of this as wrapping a secret present, like a top hat, in some wrapping paper. The user first blinds their secret value <code>U</code> before sending it to the server, so the server can&rsquo;t actually see what <code>U</code> is. Then, the server operates on this blinded value — maybe think of this as some magic machine that transmutes the secret present into pure gold and gives it back to you. Then, you get to unwrap your present — unblind your output — and enjoy the end result. The server doesn&rsquo;t see what your secret was, but you also don&rsquo;t know metaphorically how the server turned your secret present into gold: by analogy, you don&rsquo;t learn the server&rsquo;s secret <code>S</code> during this evaluation either.</p>
<figure><img src="/img/250223/6.png"/>
</figure>

<p>The other main concept used in Kintsugi is <em>secret sharing</em>. This is how we&rsquo;re able to decentralize the key recovery and distribute trust across multiple recovery nodes. If you&rsquo;ve heard of it before, we used an extension of the ideas in <a href="https://en.wikipedia.org/wiki/Shamir%27s_secret_sharing">Shamir Secret Sharing</a> (SSS). Forgive me if your eyes are glazing over at the sight of a polynomial on the slide, but I promise this is intuitive.</p>
<p>With SSS, there&rsquo;s some secret <code>S</code> we want to split up into shares, and we want to make sure we require at least <code>t+1</code> shares to reconstruct <code>S</code>.</p>
<p>Consider some function with a constant term of <code>S</code>. We can define some polynomial as the SSS polynomial as long as it passes through <code>S</code> at <code>x = 0</code>, so we&rsquo;re able to choose these coefficients at random. We can then take points on the polynomial at different x values, which will be the secret shares. With a technique called <a href="https://en.wikipedia.org/wiki/Lagrange_polynomial">Lagrange interpolation</a> and given enough shares, you can &ldquo;connect the dots&rdquo; given by each of the points and eventually find the unique polynomial that passes through all of the shares. Then you can compute the function at <code>x = 0</code> again, which gives you <code>S</code>. If a polynomial has <code>t</code> of these extra coefficient terms, then you have <code>t</code> variables, represented by a, b, and z, and so on, that you need to find the values of, and taking into consideration the extra <code>S</code> variable you need to also find, you need <code>t+1</code> points in order to solve for these <code>t+1</code> variables. The core TL;DR is that you take your secret <code>S</code>, draw some squiggly polynomial that goes through <code>S</code>, then take points on the curve that you can then connect back later to find your secret <code>S</code> again.</p>
<figure><img src="/img/250223/7.png"/>
</figure>

<p>We used extensions of both OPRFs and Shamir Secret Sharing to actually build Kintsugi. In Kintsugi, we use threshold OPRFs, which are just like an OPRF, except that you have multiple servers, each with their own secret share. You send blinded requests to each of these servers, and you need to get a blinded execution back from t+1 of them to combine together before you unblind things to get your actual encryption key. This concept is explained in more detail in the <a href="https://eprint.iacr.org/2017/363">TOPPSS paper</a> by Jarecki et al.</p>
<p>As well, instead of Shamir Secret Sharing, we use a variant called dynamic, proactive secret sharing, where each recovery nodes&rsquo; secret values can be refreshed while keeping the overall shared secret <code>S</code> the same. This can be thought of as changing the points in the graph in the earlier slide, while keeping the overall value of <code>S</code> the same. We use dynamic, proactive secret sharing so the user can change their recovery nodes at any time — for example, if one becomes untrustworthy or goes permanently offline. Users can then make sure that old recovery nodes can&rsquo;t participate in any new reconstruction efforts, while keeping the shared secret, later used to derive their recovery key, the same. This is described in the <a href="https://eprint.iacr.org/2022/971">Long Live the Honey Badger paper</a> by Das et al.</p>
<h2 id="registration">Registration</h2>
<p>Now, let&rsquo;s finally get into the three main flows you saw in the demo video: registration, recovery, and updating the recovery nodes.</p>
<figure><img src="/img/250223/8.png"/>
</figure>

<p>The first flow we saw in the demo is registration: users start with their password, which they blind. Recall that blinding is an operation that&rsquo;s easy for the user to perform and undo but that the server can&rsquo;t break, which prevents the recovery nodes from finding out the user&rsquo;s password. Users send this blinded password (represented by the yellow present) to their recovery nodes. Users need to get responses from at least <code>t+1</code> recovery nodes, where this <code>t</code> is a threshold that the user can choose during registration. Each of these <code>t+1</code> recovery nodes hold a share of a recovery secret. Note that you don&rsquo;t have to reach out to all of your recovery nodes during this process, so if some of them are down during registration that&rsquo;s fine.</p>
<p>The user takes the blinded password and combines it with the node&rsquo;s secret share via a threshold OPRF, represented by the blue present. Remember how I mentioned with threshold OPRFs, the other parties don&rsquo;t learn anything about the user&rsquo;s password or the final output, which only the user sees? In this case, the user takes the final output, unblinds it, and uses the OPRF evaluation result as another key. This OPRF result key is used to encrypt their recovery key and any recovery data they want to save. The blinding and the threshold-based communication here prevent the recovery nodes from mounting an offline brute-force attack. We call this encrypted backup the encrypted envelope, which is sent to the recovery nodes to be persisted.</p>
<h2 id="recovery">Recovery</h2>
<figure><img src="/img/250223/9.png"/>
</figure>

<p>During recovery, the user performs a similar exchange: they blind their password and send it to the recovery nodes. Again, you don&rsquo;t have to reach all of your recovery nodes, just a threshold, so if some nodes are offline you can still proceed with recovery. The recovery nodes each combine the blinded password with their respective shares and return their blind OPRF evaluations to the user along with the encrypted envelope that they&rsquo;ve stored. The user reconstructs their encryption key via the returned OPRF evaluations and with Lagrange interpolation, and decrypts the encrypted envelope to get their recovery key back.</p>
<figure><img src="/img/250223/10.png"/>
</figure>

<p>These nodes also perform rate-limiting as an additional layer of brute-force protection without requiring any secure hardware. Because you need to wait for a threshold of nodes to return results before you can attempt to reconstruct the key, you&rsquo;re limited by the slowest recovery node. As long as one recovery node correctly implements a recovery attempt rate limit (which we assume in our threat model), the attempts will be rate-limited overall as well. This gets you some nice decentralized rate limiting as a result.</p>
<p>Also, because no single recovery node has the whole recovery secret, you&rsquo;ll need a whole threshold of at least <code>t+1</code> nodes to collude in order to get access to the shared recovery secret. Even then, these colluding nodes must still perform a brute-force attack, since the user&rsquo;s password was blinded, so they can&rsquo;t directly decrypt the encrypted envelope that they&rsquo;ve persisted. This provides protection against colluding recovery nodes.</p>
<h2 id="refreshing-update-nodes">Refreshing Update Nodes</h2>
<figure><img src="/img/250223/11.png"/>
</figure>

<p>If the user wishes to update their recovery nodes, they send a notification to the old recovery nodes. A threshold of the old recovery nodes then use dynamic, proactive secret sharing to refresh their shares, communicating second-order shares of shares to the new recovery nodes (represented by the pink robots). These new recovery nodes might overlap with the old recovery nodes significantly, or indeed be the same set of nodes, or be completely different. The new recovery nodes reconstruct their new shares with Lagrange interpolation, which are then used from this point onwards.</p>
<p>Intuitively, consider that the original secret is split into shares once at each of the original, blue recovery nodes. Each of those shares is split up again in the second step in passing on shares to the new recovery nodes (pink robots). This broadcast just changes which pink robots hold which sub-shares of the original secret, but the underlying shared recovery secret remains the same. If you&rsquo;re interested, I wrote a <a href="https://kewbi.sh/blog/posts/241229/">blog post</a> that explains dynamic proactive secret sharing more, but let&rsquo;s wrap up all this math and take a look at the concrete implementation instead.</p>
<h2 id="implementation-details">Implementation Details</h2>
<p>Kintsugi is written in Rust, and the GitHub repository is available <a href="https://github.com/kewbish/kintsugi">here under the MIT License</a>. The P2P communication builds on the <a href="https://libp2p.io/">libp2p</a> framework, primarily based on the <a href="https://docs.rs/libp2p-request-response/latest/libp2p_request_response/"><code>request-response</code></a> module. libp2p is used <a href="https://docs.libp2p.io/concepts/introduction/users/">by the likes of</a> Ethereum, IPFS, and Filecoin, to name a few. You can read more about its basic model <a href="https://docs.libp2p.io/concepts/fundamentals/overview/">here</a> and see the Rust tutorial <a href="https://docs.rs/libp2p/latest/libp2p/tutorials/ping/index.html">here</a>. The gist of libp2p is that it&rsquo;s structured as an event-based loop, with everything from peer discovery to actual protocol messages implemented as so-called <a href="https://docs.rs/libp2p/latest/libp2p/tutorials/ping/index.html#network-behaviour"><code>NetworkBehaviour</code>s</a> that can define event handlers.</p>
<p>The client UI was developed with the <a href="https://v2.tauri.app/">Tauri</a> framework, using React as a frontend framework for familiarity&rsquo;s sake. Tauri lets you invoke commands, which are defined in Rust, from JS, and likewise emit events, which are handled in JS, from Rust. Tauri requires you to restructure your Rust and web frontend a little: for example, it needed to hold all the mutable state, and it needed to get the right same async runtime plugged in. There were few resources with using it with another async library like libp2p — I found <a href="https://rfdonnelly.github.io/posts/tauri-async-rust-process/">this blog post</a> very helpful for figuring out how to wire libp2p and Tauri together.</p>
<p>The event loop has to be written as a separate future to be managed by the Tauri app handle, and Tauri and libp2p have to be connected via a separate <a href="https://doc.rust-lang.org/std/sync/mpsc/fn.channel.html"><code>mpsc::channel</code></a>. Here&rsquo;s the general architecture:</p>
<figure><img src="/img/250223/architecture-diagram.png"/>
</figure>

<p>You can see this event loop <a href="https://github.com/kewbish/kintsugi/blob/master/src/main.rs#L334">here</a>. For UI events, the commands that are invoked by the Tauri JS side forward extra messages through the <code>mpsc::channel</code> to initiate libp2p requests. There&rsquo;s a receiver <a href="https://github.com/kewbish/kintsugi/blob/master/src/main.rs#L337">here</a> in the event loop that takes in messages from this channel. You need to forward messages via this channel due to how Tauri is managing node state and where the libp2p communication objects are available, scope-wise. Specifically, the <code>#[tauri::command]</code> commands have to take in all parameters from the UI on the JS side, so it doesn&rsquo;t have access to libp2p components. All these commands are responsible for is sending a message to . These libp2p messages are processed <a href="https://github.com/kewbish/kintsugi/blob/master/src/main.rs#L107">here</a> and <a href="https://github.com/kewbish/kintsugi/blob/master/src/main.rs#L146">here</a>, sending responses back or kicking off yet more requests.</p>
<p>We initially started building Kintsugi with the <a href="https://docs.rs/libp2p-gossipsub/latest/libp2p_gossipsub/">gossipsub module</a>, but there were some issues with <a href="https://github.com/libp2p/rust-libp2p/discussions/5696">gossipsub reporting <code>InsufficientPeers</code></a> even when there were multiple recovery nodes subscribed to a topic as well as problems with <a href="https://github.com/libp2p/rust-libp2p/discussions/5731">topic re-creation</a> that blocked development. Someone mentioned in the comments that it might have just been an issue with the <a href="https://github.com/libp2p/rust-libp2p/discussions/5696#discussioncomment-11786456">crate tagging</a>, but I didn&rsquo;t verify if this was the fix since I&rsquo;d already begrudgingly ported everything to the request-response module already anyways. The request-response model worked better with our final design anyways, since the user individually blinds their password for each recovery node and since the recovery nodes only want to communicate directly with the user instead of broadcasting message information around willy-nilly.</p>
<p>Peer discovery is handled by the <a href="https://docs.rs/libp2p/latest/libp2p/mdns/">mDNS module</a>, and for now only takes place on the local network. For distributing global information like the user to recovery node mapping, we use the built-in <a href="https://docs.rs/libp2p/0.55.0/libp2p/kad/index.html">Kademlia DHT module</a>. We had to add some record verification to check signatures and the well-formedness of messages (<a href="https://github.com/kewbish/kintsugi/blob/master/src/kad_interactions.rs#L91">here</a>), but the Kademlia module&rsquo;s event-based structure led to some very annoying callback hell and required a lot of state to be passed around (<a href="https://github.com/kewbish/kintsugi/blob/master/src/kad_interactions.rs#L88">example</a>). If you want to enable message filtering, for message verification, for instance, you have to write event listeners both for the first attempted write to the DHT as well as the filtering request that has to perform the actual write. This complicated event structure was one of my main frustrations with libp2p. It&rsquo;s likely because I don&rsquo;t come from an event-driven programming background, but I found the model to lead to convoluted code that was hard to visualize without drawing out an explicit data flow graph.</p>
<p>There were also limited examples for what I needed references for (e.g. a very stripped down Kademlia basic example without peer discovery), although the docs and <a href="https://github.com/libp2p/rust-libp2p/tree/master/examples">existing example apps</a> were mostly enough to piece things together. I also hadn&rsquo;t gotten much experience with async Rust beforehand, so there was an extra learning curve on top of the framework details, even after going through the <a href="https://rust-lang.github.io/async-book/">Async Rust handbook</a>.</p>
<p>One very nice thing about libp2p was that the network communication (at least over a local network, I didn&rsquo;t mess with any NAT hole-punching) worked flawlessly. As I was explaining my libp2p woes to someone one day, they mentioned that with P2P networks, it&rsquo;s usually always the network that causes issues. I&rsquo;m happy to report this wasn&rsquo;t the case at all. This was fairly surprising, since I was developing on <a href="https://en.wikipedia.org/wiki/Eduroam">eduroam</a> for most of the project, and I&rsquo;d expect there&rsquo;s plenty of firewalling and broadcast limitations implemented.</p>
<p>Some other implementation notes:</p>
<ul>
<li>I wouldn&rsquo;t recommend integrating Tauri with all the libp2p events in one fell swoop. Instead, I&rsquo;d suggest starting from a smaller example and adding on only when the basic communication is working, since this limits the amount of refactoring you need to do if something all goes wrong (e.g. if you need to switch <code>NetworkBehaviour</code>s). This sounds very intuitive, but it&rsquo;s very tempting to build out all the libp2p communication, then just slap Tauri on top, but it took ages to debug.</li>
<li>Sometimes when libp2p messages don&rsquo;t seem to be getting sent properly, check if you have a mutex deadlock somewhere, particularly if you&rsquo;re also letting Tauri manage your shared node state with an <code>Arc&lt;Mutex&lt;T&gt;&gt;</code> or something similar.</li>
<li>It was easy to overlook in the docs for <a href="https://v2.tauri.app/develop/state-management/#async-commands">async commands</a>, but make sure the Tauri app handler has its async runtime set properly (<a href="https://github.com/kewbish/kintsugi/blob/master/src/main.rs#L312">here</a>).</li>
<li>Migrating to Tauri&rsquo;s minor idiosyncrasies with all the annotations, and the event-based loop that libp2p required, gave the project a natural tendency towards putting all the code in one file so various callbacks would be in one place and there wouldn&rsquo;t be any scoping or visibility issues. At one point, my <code>main.rs</code> was some &gt;2K LoC, which was still tenable but unsustainable for explaining the project to anyone. It was more straightforward to refactor than expected, but again I&rsquo;d advise starting with a more logically separated crate structure from the get-go.</li>
</ul>
<p>Overall, libp2p took some time to get used to, particularly when integrating it with Tauri, but the event-loop-based approach is starting to grow on me as I&rsquo;m becoming more comfortable debugging issues. If I were to reimplement Kintsugi, I&rsquo;d be happy going with this stack again.</p>
<h2 id="conclusion">Conclusion</h2>
<p>So that&rsquo;s been a whirlwind walkthrough of Kintsugi: I&rsquo;ve walked through some of the reasons why existing E2EE key recovery methods are lacking, gone through some fun intros to crypto, and finally touched on how Kintsugi works. With Kintsugi, our main improvement over existing recovery methods is our focus on decentralization. We also don&rsquo;t require any expensive hardware, can tolerate device loss, provide brute-force resistance, and protect against colluding recovery nodes. Here&rsquo;s the &ldquo;money slide&rdquo; conclusion from the talk:</p>
<figure><img src="/img/250223/12.png"/>
</figure>

<p>Kintsugi is currently perhaps on a bit of a pause. I&rsquo;ve finished the protocol demo that you can see on <a href="https://github.com/kewbish/kintsugi">GitHub</a>, after much libp2p wrangling and a frantic grind towards getting the demo fully functional for FOSDEM. After I wrapped up the MVP demo, I ended up needing to focus on moving to my next internship and prepping for the FOSDEM talk, and have since not had much time to make progress. There&rsquo;s still plenty to look forward to in the future though: I should really continue polishing up the implementation, as there&rsquo;s plenty of (noncritical) loose ends like Byzantine value agreeemtn that I haven&rsquo;t fully implemented yet. There&rsquo;ve also been some vague discussions of integration with the Ink &amp; Switch decentralized access control project <a href="https://www.inkandswitch.com/beehive/notebook/">Beehive</a>, and I&rsquo;ve gotten some other messages from and chatted with folks interested in potentially using Kintsugi&rsquo;s theory in their own E2E platforms.</p>
<p>Speaking of getting questions and emails, I&rsquo;m reminded of something my UBC supervisor said the last time I gave a talk, about how it&rsquo;s nice to take academic research to industry conferences, both since it encourages you to ensure your work can be repackaged and massaged into something that&rsquo;s immediately impactful to real developers, and for reaching a new audience beyond at-times stuffy academia with different considerations and goals. Getting to think through these questions is a nice side effect of the opportunity and a very-much-appreciated affirmation that my work matters in some small way. It&rsquo;s also unique feedback that helps you better think through and articulate the project in the future. For example, I got a couple reoccurring questions about what happens if some recovery nodes are down, or if not all the initial recovery nodes are reachable upon registration, so I&rsquo;ve tried to do a better job in this blog post to reiterate that only a threshold of nodes need to be reached.</p>
<p>I&rsquo;ll be presenting Kintsugi again at the International Workshop on Security Protocols in March, and the proceedings should be available not long after then. I&rsquo;ve set a reminder to update this post with a link to the paper once it&rsquo;s out, as it explains some of the finer-grained details with more nuance and clearer caveats. Leaving this as a placeholder here until I&rsquo;ve put it up — you can also feel free to subscribe to notifications on <a href="https://github.com/kewbish/kintsugi/issues/1">this GitHub issue</a>, as I&rsquo;ve also set a reminder to comment there once I can upload a version of the paper to the repo.</p>
<p>That&rsquo;s about it from Kintsugi for now, but I&rsquo;m also writing up my FOSDEM experience in a separate post. I only attended for the first day, but I&rsquo;ll still be touching on some of the other talks I attended and some &ldquo;survival tips&rdquo; in the vein of <a href="https://petersouter.xyz/fosdem-survival-guide/">these</a> <a href="https://ounapuu.ee/posts/2024/02/12/fosdem-2024/">posts</a>. If you&rsquo;re less concerned with cryptography and more interested in treasure hunts, tangents about trip planning, and survival guides, look forward to that being out next week!</p>


<style>
figure {
margin-bottom: .8em;
}
</style>


<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Elevator rides are &lt;2min, which converts to around ~260 words at an average speaking rate. This explainer was ~160 words, so maybe you&rsquo;d even have a chance to brandish a <a href="https://kewbi.sh/blog/posts/240811/">NFC ring</a> to exchange contact information to take further questions…&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Snakes and Lagrangian Ladders</title>
      <link>https://kewbi.sh/blog/posts/241229/</link>
      <pubDate>29 Dec 2024</pubDate>
      
      <description>On secret sharing and interpolation.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I recently had the pleasure of reading a dense crypto paper, emailing the corresponding author in frustration to ask questions, then double emailing two hours later to say I&rsquo;d figured it out. The paper in question was Yurek et al.&rsquo;s <a href="https://eprint.iacr.org/2022/971">&ldquo;Long Live The Honey Badger: Robust Asynchronous DPSS and its Applications&rdquo;</a>: it describes how to split up a secret into shares that can be distributed among a set of people and how to change the set of people and refresh shares while keeping the original secret intact. Secret sharing is important for sensitive but critical information: information that no single party should be able to read on their own, but that we can&rsquo;t afford to lose — think nuclear launch codes and encryption keys.</p>
<p>The problem I was emailing with was me not being able to understand the refresh process. Algorithm 3 in the paper opaquely says a few times to &ldquo;interpolate&rdquo; the desired new secrets. I&rsquo;m sure seasoned cryptographers can recalculate secrets from shares in their sleep, but detangling these three lines took more time than reading the entire rest of the paper. Typical secret sharing via <a href="https://en.wikipedia.org/wiki/Shamir%27s_secret_sharing">Shamir secret sharing</a> is very cleverly constructed already, and as I mentioned in <a href="https://kewbi.sh/blog/posts/241020/">my previous post</a>, crypto papers generally don&rsquo;t do a good job of explaining the basics in favour of just laying down novel material. This is great for brevity and conciseness in academia, but not so great for beginners to the field.</p>
<p>Once I&rsquo;d gotten more background on the very finicky math, the actual interpolation and refreshing wasn&rsquo;t hard to understand and implement. Still, I wish they&rsquo;d linked to a layman&rsquo;s explainer, although from a few cursory searches, none quite seems to exist. This post is the explainer I wish I&rsquo;d had before tackling this paper. I&rsquo;ll cover the very basics of Shamir secret sharing before summarizing the Honey Badger protocol&rsquo;s use of interpolation, explaining the key three lines of Algorithm 3 in the scheme, so you can hopefully save yourself the three hours of puzzling.</p>
<h2 id="eating-the-frog">Eating the Frog</h2>
<p>In my opinion, the hardest part of Shamir Secret Sharing is the Lagrange interpolation, so I&rsquo;m going to put it up front here while your brains are still fresh. Lagrange interpolation is a way of estimating the value of a polynomial at some input, given some points on the polynomial. Let&rsquo;s consider a bog-standard function: <code>f(x) = x^2 + 2</code>.</p>
<figure><img src="/img/241229/interpolation-1.png"
         alt="Figure 1. f(x) = x² &#43; 2."/><figcaption>
            <p><em>Figure 1. f(x) = x² + 2</em></p>
        </figcaption>
</figure>

<p>If we have no knowledge of the polynomial, we&rsquo;ll need three points to estimate the value of <code>f(x)</code> for any <code>x</code> back. This is because <code>f(x)</code> is a polynomial of degree two (highest power term is <code>x^2</code>). There&rsquo;s no <code>x</code> term in the function as I&rsquo;ve written it, but we can also write it as <code>f(x) = 1 * x^2 + 0 * x + 2</code>.</p>
<p>In order to recover <code>f(x)</code>, we need to solve for the coefficients of the terms — the 1, 0, and 2. If we know the values <code>y_i = f(x_i)</code> taken at few different points <code>x_i</code>, then we&rsquo;ll get something like the below:</p>
<pre tabindex="0"><code>y_1 = a * x_1^2 + b * x_1 + c
y_2 = a * x_2^2 + b * x_2 + c
y_3 = a * x_3^2 + b * x_3 + c
</code></pre><p>In this case, we know three values of <code>x</code>, and their associated <code>y</code> values, and we&rsquo;re solving for <code>a</code>, <code>b</code>, and <code>c</code>. Because we have three unknown coefficients, we&rsquo;ll need a system of three equations, based on three evaluated points. In general, for a polynomial of degree <code>t</code>, you&rsquo;ll need <code>t+1</code> points to solve for the polynomial — the extra <code>+1</code> comes from the unknown value of the constant term itself.</p>
<p>To figure out how to reconstruct the polynomial, let&rsquo;s start with a slightly easier function, <code>f(x) = 2x</code>. Let&rsquo;s say we know that <code>f(1) = 2</code> and <code>f(3) = 6</code>.</p>
<figure><img src="/img/241229/interpolation-2.png"
         alt="Figure 2. f(x) = 2x."/><figcaption>
            <p><em>Figure 2. f(x) = 2x</em></p>
        </figcaption>
</figure>

<p>We want to derive a polynomial that takes on the value 2 at <code>x = 1</code> and 6 at <code>x = 3</code>. This is one such polynomial:</p>
<pre tabindex="0"><code>y = (x - 3)/(1 - 3) * 2 + (x - 1)/(3 - 1) * 6
</code></pre><p>Note that when <code>x = 1</code>, the first fraction cancels out to 1 and the second fraction evaluates to 0, so <code>y = 1 * 2 + 0 * 6 = 2</code>, as expected. Similarly, when <code>x = 3</code>, the first fraction evaluates to 0 and the second fraction to 1, making <code>y = 0 * 2 + 1 * 6 = 6</code>. Also note that when we rearrange the terms:</p>
<pre tabindex="0"><code>y = (x - 3)/(-2) * 2 + (x - 1)/(2) * 6
  = -(x - 3) + 3(x - 1)
  = -x + 3 + 3x - 3
  = 2x
</code></pre><p>So we can recover our original function! As another example, let&rsquo;s take our original function <code>f(x) = x^2 + 2</code>. Because this polynomial is of degree 2, we&rsquo;ll need 3 points to reconstruct it. Let&rsquo;s take <code>f(1) = 3</code>, <code>f(2) = 6</code>, and <code>f(3) = 11</code>.</p>
<p>Let&rsquo;s look at the form of our fractional coefficients. We want each fraction to evaluate to 1 at the associated x-value, so the overall term evaluates to the right y-value. We also want the fraction to evaluate to 0 anywhere else. The general form of such a term (let&rsquo;s say, for the point <code>(x_i, y_i)</code>) is to have the numerator of the fraction be a product of <code>(x - x_m)</code>, and the denominator be <code>(x_i - x_n)</code>, for all of the other <code>x_m</code>. We exclude the <code>(x - x_i)/(x_i - x_i)</code> fraction, because when this is evaluated at <code>x_i</code>, we&rsquo;d get <code>0/0</code>, which is undefined. When we evaluate this fraction at <code>x_i</code>, the terms in the numerator all cancel with the terms in the denominator, so we get 1, as desired. When we evaluate this fraction at any of the other input x-values, however, one of the numerator terms <code>(x - x_m)</code> will be 0, preventing this particular y-value from affecting the overall polynomial&rsquo;s value. This fractional coefficient is also called the <a href="https://en.wikipedia.org/wiki/Lagrange_polynomial#Definition">Lagrange basis polynomial</a>, and we&rsquo;ll denote it <code>λ_i(x)</code>. Each y-value is multiplied by a different Lagrange basis polynomial, since the x-value changes, so the <code>i</code> in the basis polynomial also has to change.</p>
<figure><img src="/img/241229/interpolation-3.png"
         alt="Figure 3. Form of the Lagrange basis polynomial."/><figcaption>
            <p><em>Figure 3. Form of the Lagrange basis polynomial.</em></p>
        </figcaption>
</figure>

<p>For our example, our polynomial is thus:</p>
<pre tabindex="0"><code>y = (x - 2)(x - 3)/(1 - 2)(1 - 3) * 3 +
    (x - 1)(x - 3)/(2 - 1)(2 - 3) * 6 +
	(x - 1)(x - 2)/(3 - 1)(3 - 2) * 11
</code></pre><p>If we plug in <code>x = 4</code>, for example, we&rsquo;d expect to get <code>4^2 + 2 = 18</code>. Indeed, we get:</p>
<pre tabindex="0"><code>y = (4 - 2)(4 - 3)/(1 - 2)(1 - 3) * 3 +
    (4 - 1)(4 - 3)/(2 - 1)(2 - 3) * 6 +
	(4 - 1)(4 - 2)/(3 - 1)(3 - 2) * 11
  = 1 * 3 - 3 * 6 + 3 * 11
  = 3 - 18 + 33 = 18
</code></pre><p>Feel free to skip this expansion, but if you&rsquo;re interested, this is what we get when we rearrange the terms:</p>
<pre tabindex="0"><code>y = (x^2 - 5x + 6) * 3/2 +
    (x^2 - 4x + 3) * -6 +
    (x^2 - 3x + 2) * 11/2
  = (3/2 - 6 + 11/2) * x^2 +
    (-15/2 x + 24 x + - 33/2 x) +
	(9 - 18 + 11)
  = x^2 + 0x + 2 = x^2 + 2
</code></pre><p>Even when evaluating this interpolated polynomial at an x-value that wasn&rsquo;t originally provided, like <code>x = 4</code>, for example, we were still able to get the correct result. We can use the same interpolated polynomial to evaluate the y-value at <code>x = 2.5</code>, for example. Using the Lagrange interpolation to recover the y-value at an x-value not included in the list of input points is critical to how Shamir secret sharing works, as I&rsquo;ll describe in the next section.</p>
<h2 id="here-there-be-snakes-sss">Here There Be Snakes (SSS)</h2>
<p>Shamir Secret Sharing starts with the secret <code>s</code> that you want to be able to reconstruct. This might be something like a recovery key or private message. For the sake of explanation, assume this secret is a number. In more realistic scenarios, the secret is likely some series of bytes which need to be transcoded into, or at least interpreted as, large integers, but this is outside of the scope of the SSS algorithm.</p>
<p>We then define a polynomial <code>SSS(x) = s + a * x + b * x^2 + ... + z * x^t</code>. The degree of the polynomial (the choice of <code>t</code>) determines how many shares you&rsquo;ll need to reconstruct the secret <code>s</code>. The coefficients <code>a, b, ...</code> are all randomly chosen numbers. Note that the constant term is the secret <code>s</code> that we&rsquo;re trying to split into shares, and that <code>SSS(0) = s</code>. The SSS shares of the secret are now simply the point <code>(i, SSS(i))</code> for some index <code>i</code> — we need to keep track of the actual index from which a SSS share was calculated for the reconstruction later on. Many such shares can then be calculated and distributed to the other parties who want to be able to help reconstruct the secret.</p>
<p>To recover the secret, at least <code>t+1</code> parties must submit their shares. Using Lagrange interpolation, we can then recover the original <code>SSS</code> polynomial, or in particular, evaluate it at index 0. This gives us the value of <code>s</code> back.</p>
<p>As you might have guessed, SSS&rsquo;s primary application is data recovery. For example, <a href="https://www.preveil.com/">PreVeil</a> is an E2EE platform focusing on email and file collaboration. It <a href="https://www.preveil.com/wp-content/uploads/2024/06/PreVeil_Security_Whitepaper-v1.6.pdf">supports the notion of Approval Groups</a>, a recovery scheme that makes use of SSS, requiring some threshold of designated contacts to recover the user&rsquo;s encryption key. Trezor, the hardware cryptocurrency wallet, <a href="https://trezor.io/learn/a/what-is-shamir-backup?srsltid=AfmBOoq2BNTogcvxxynrx-o49LEF0cLjtxPRuM2F0kTxkLVIu5ZwNry_">makes use of SSS</a> to back up the user&rsquo;s recovery key. The HN- and GitHub-famous <a href="https://github.com/jesseduffield/horcrux">Horcrux</a> tool is one of my favourite SSS applications, just because it&rsquo;s such a fun concept: Horcrux lets you split up a file into encrypted shares, much like Voldemort did with his soul. I mentioned above that the SSS secret is usually some series of bytes interpreted as a large integer — here, Horcrux splits up the file into chunks of bytes to avoid integer overflow and repeats the SSS once per chunk, collecting the i-th shares of each chunk into the overall i-th share.</p>
<p>With SSS, you can choose both your recovery threshold, <code>t</code>, and your total number of shares, <code>n</code>. Having a large <code>n</code> is appealing, since you have more options for who can help reconstruct your secret — in the case where you&rsquo;re trying to recover a key from unreliable P2P nodes, for example, the higher availability from a large <code>n</code> might be desirable. On the other hand, an adversary also has more options for who to compromise in order to learn <code>s</code>. Having <code>n</code> be much larger than <code>t</code> can be problematic in this case.</p>
<p>One key caveat of SSS is that when these applications directly recover data (e.g. split up a recovery key directly into shares), they&rsquo;re vulnerable to malicious parties colluding to recover your data. SSS is usually applied in E2EE contexts as an alternative to the platform servers storing the user&rsquo;s key, so it&rsquo;s problematic if adversaries can compromise a threshold of nodes and directly recover your key. In the case when these parties are social recovery contacts (read: real people), social engineering is also a risk, since there&rsquo;s no easy way to authenticate reconstruction requests, so your contacts might accidentally send their share to a malicious impersonator and leak your recovery data. PreVeil&rsquo;s whitepaper doesn&rsquo;t mention any protections against this, and neither does Trezor. I think the collusion and social engineering concerns are fundamental to vanilla SSS without any additional security considerations.</p>
<p>One solution to these issues is the approach I took in my recent research project, <a href="https://github.com/kewbish/kintsugi">Kintsugi</a>, which involves adding an <a href="https://kewbi.sh/blog/posts/241020/">Oblivious Pseudo-Random Function exchange</a> that protects against the risk of collusion by requiring an additional brute-force step, and against social engineering by not requiring recovery request authentication. The math is quite neat, and this project is what made me look at dynamic proactive secret sharing in the first place. Speaking of, let&rsquo;s get into the Honey Badger protocol now that we have the background on the base SSS protocol.</p>
<h2 id="resharing-is-caring">(Re)sharing is Caring</h2>
<p><a href="https://eprint.iacr.org/2022/971">Honey Badger</a> is the dynamic, proactive secret sharing (DPSS) protocol proposed by Yurek et al. in their 2022 paper &ldquo;Long Live The Honey Badger: Robust Asynchronous DPSS and its Applications&rdquo;. DPSS is used to refresh the secret shares that SSS outputs while keeping the same overall secret <code>s</code>. DPSS both allows users to update the set of parties that possess shares, and invalidates former secret shares, preventing them from being used to reconstruct the secret <code>s</code>.</p>
<p>Recall that the SSS polynomial has the form <code>SSS(x) = s + a * x + b * x^2 + ... + z * x^t</code>. I&rsquo;ll use the term &ldquo;party&rdquo; to refer to the party that holds a secret share, be that a service provider, server, or friend. The core idea of Honey Badger is for each party at index <code>i</code> that has the old SSS secret share <code>s_i = SSS(i)</code> to generate a new SSS polynomial:</p>
<pre tabindex="0"><code>SSS&#39;_i(x) = s_i + a&#39; * x + b&#39; * x^2 ... + z&#39; * x^t&#39;
</code></pre><p>The constant term of this new polynomial is the former SSS secret share. The coefficients <code>a', b', ... z'</code> are new random coefficients, and the degree of the polynomial can change to a new threshold <code>t'</code>. The new secret share that results from the DPSS process will be different than <code>s_i</code>, and if they differ, a threshold of <code>t'</code> will be required to reconstruct <code>s</code> instead of a threshold of <code>t</code>. (The Honey Badger paper uses the notation <code>χ_i(x)</code> instead of <code>SSS'_i(x)</code>, <code>[s]^i_d</code> instead of <code>s_i</code>, and <code>d</code> instead of <code>t</code>.)</p>
<p>The party at index <code>i</code> then sends an evaluation to each other party at their respective index, <code>SSS'_i(j)</code>. which allows the party at index <code>j</code> to interpolate their new share <code>s_j'</code> (line 208 in Algorithm 3 of the paper). These new party shares can be further interpolated to recover the original secret <code>s</code>. Recall that each original <code>s_i = SSS(i)</code> and <code>s = s_0 = SSS(0)</code>. Similarly, each party&rsquo;s new share <code>s'_i</code> is interpolated as <code>SSS'_0(i)</code>, or alternative shares of <code>s_0 = s</code>. Once the party at index <code>i</code> has collected a threshold of shares of the form <code>SSS'_1(i)</code>, <code>SSS'_2(i)</code> and so on, they can interpolate :</p>
<pre tabindex="0"><code>s&#39;_i = λ_1(0) * SSS&#39;_1(i) + λ_2(0) * SSS&#39;_2(i) + ... + λ_{t&#39;}(0) * SSS&#39;_{t&#39;}(i)
    = SSS&#39;_0(i)
</code></pre><p>Thus, when these <code>s'_i</code> are interpolated again (during a normal SSS recovery operation, for example), the original <code>s</code> is recovered.</p>
<pre tabindex="0"><code>  λ_1(0) * s&#39;_1 + λ_2(0) * s&#39;_2 + ... + λ_{t&#39;}(0) * s&#39;_{t&#39;}
= λ_1(0) * SSS&#39;_0(1) + λ_2(0) * SSS&#39;_0(2) + ... + λ_{t&#39;}(0) * SSS&#39;_0(t&#39;)
= SSS&#39;_0(0)
= s_0 = s
</code></pre><p>Intuitively, consider that the original secret <code>s</code> is split into shares once, with each of those party shares being split up again. This broadcast changes which parties hold which sub-shares of the original secret, although the underlying shared data remains the same. <code>SSS'_i(x)</code> can have a different degree, and therefore a different reconstruction threshold <code>t'</code>, than <code>SSS(x)</code>, allowing users to add or remove recovery parties. This secret refresh can also be configured to run at some desired interval (e.g. once per day) to protect against recovery parties&rsquo; shares being leaked over time.</p>
<p>Alternatively, the paper describes this interpolation process more formally by framing the new <code>SSS'_i(x)</code> as a bivariate polynomial, or a polynomial with two variables, denoted as <code>SSS'(i, x)</code> (the paper uses <code>B(x, y)</code>, see line 207 of Algorithm 3 in the paper). This bivariate polynomial still has the form <code>SSS'(i, x) = s_i + a' * x + b' * x^2 ... + z' * x^t'</code>. Note that <code>SSS'(0, 0) = s_0 = s</code>. The idea of resharing is then to interpolate in one variable first, <code>i</code>, over the evaluations at <code>x = i</code> (this is the tricky part!) to get the various <code>SSS'(0, i) = s'_i</code> shares. Then, to reconstruct the original secret, you can interpolate in the other variable, <code>x</code>, to recover <code>SSS'(0, 0) = s</code>. If looking at concrete code makes this easier to understand, feel free to also take a look at <a href="https://github.com/kewbish/kintsugi/blob/master/src/polynomial.rs#L77">my Rust implementation</a> and its <a href="https://github.com/kewbish/kintsugi/blob/master/src/polynomial_tests.rs#L44">tests</a>.</p>
<h2 id="commitment-issues">Commitment Issues</h2>
<p>The above section focused on how the core resharing of Honey Badger worked. However, you might have noticed that the actual paper also mentions checking <a href="https://en.wikipedia.org/wiki/Commitment_scheme"><em>commitments</em></a>. Commitments hide an actual value and later prove, upon revealing the value, that you haven&rsquo;t changed it in the meantime. In Honey Badger, the commitments serve to prove that the nodes are resharing correct secret shares <code>s'_i</code> to the new set of parties.</p>
<p>Honey Badger uses <a href="https://www.rareskills.io/post/pedersen-commitment">Pedersen commitments</a>, of the form <code>s_i * G + ŝ_i * H</code> (see <a href="https://kewbi.sh/blog/posts/241020/#background-elliptic-curves">my other post</a> if you&rsquo;re less familiar with elliptic curves.) Here, <code>s_i</code> is the secret you&rsquo;re committing to, <code>G</code> is the generator point of the elliptic curve, <code>ŝ_i</code> is a random blinding factor used to keep <code>s_i</code> secret even in the case of brute-force attacks, and <code>H</code> is similarly a random elliptic curve point. Points <code>G</code> and <code>H</code> are public to both the old and new resharing parties. During refresh operations, <code>ŝ_i</code> is also calculated the same way <code>s_i</code> is reshared, with a new <code>SSS'_i(x)</code> polynomial with <code>ŝ_i</code> as its secret constant.</p>
<p>In Honey Badger, parties broadcast their new shares alongside a new commitment, which is then verified at various points (lines 205 of Algorithm 1, 303 of Algorithm 2, and 202 of Algorithm 3). Nodes must also keep track of other parties&rsquo; commitments, though, so they have something to verify new shares against: note that in Algorithm 1, the commitments of all shares are broadcast and stored by all parties. This means that the resharing process requires an additional step to interpolate the new commitments (line 209 of Algorithm 3). This isn&rsquo;t trivial (in contrast to the paper&rsquo;s rather flip suggestion to simply &lsquo;interpolate&rsquo;), because we don&rsquo;t know the other parties&rsquo; new secret shares <code>s'_i</code> or their blinding factors <code>ŝ'_i</code>, so we need to somehow interpolate their <em>new</em> commitments only based on public information.</p>
<p>Let&rsquo;s say that the party <code>j</code> wants to interpolate these new commitments. To set the scene, we start out by knowing <code>c_i = s_i * G + ŝ_i * H</code> for all of the other parties (without knowing their <code>s_i</code> or <code>ŝ_i</code>, or any of the new shares or blinding factors), as well as our new share <code>s'_j</code> and new blinding factor <code>ŝ'_j</code>. We want to figure out <code>c'_i = s'_i * G + ŝ'_i * H</code>.</p>
<p>The key here is to recall how <code>s'_i</code> is calculated with Lagrange interpolation, which we can also apply on the commitments themselves to interpolate the new <code>c'_i</code>. Recall that the Lagrange basis polynomial, <code>λ_i(x_i)</code>, is used as a coefficient for the point at index <code>i</code> to interpolate for the value of the polynomial at <code>x = x_i</code>. Now, instead of interpolating for <code>s_0</code> at <code>x = 0</code>, we want to interpolate for the commitment at index <code>i</code>. This can be written as:</p>
<pre tabindex="0"><code>  λ_1(i) * c_1 + λ_2(i) * c_2 + ... + λ_{t+1}(i) * c_{t+1}
</code></pre><p>We can then expand the form of the commitments <code>c_1</code>, <code>c_2</code>, etc.:</p>
<pre tabindex="0"><code>= λ_1(i)     * (s_1 * G     + ŝ_1 * H) +
  λ_2(i)     * (s_2 * G     + ŝ_2 * H) + ...
  λ_{t+1}(i) * (s_{t+1} * G + ŝ_{t+1} * H)
</code></pre><p>Then, multiply out the Lagrange basis polynomials and collect like terms to move <code>G</code> and <code>H</code> outside. You can then notice that the coefficients of <code>G</code> and <code>H</code> are then exactly the forms of the reshared <code>s'_i</code> and <code>ŝ'_i</code><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<pre tabindex="0"><code>= (λ_1(i) * s_1 * G + λ_2(i) * s_2 * G + ... + λ_{t+1} * s_{t+1} * G) +
  (λ_1(i) * ŝ_1 * H + λ_2(i) * ŝ_2 * H + ... + λ_{t+1} * ŝ_{t+1} * H)
= (λ_1(i) * s_1 + λ_2(i) * s_2 + ... + λ_{t+1} * s_{t+1}) * G +
  (λ_1(i) * ŝ_1 + λ_2(i) * ŝ_2 + ... + λ_{t+1} * ŝ_{t+1}) * H
= s&#39;_i * G + ŝ&#39;_i * H
= c&#39;_i
</code></pre><p>This lets us determine the value of <code>c'_i</code> from the other received commitments without actually needing to learn the secret shares of other parties. You can see this commitment interpolation in code <a href="https://github.com/kewbish/kintsugi/blob/master/src/dpss.rs#L82">here</a>, with tests <a href="https://github.com/kewbish/kintsugi/blob/master/src/dpss_tests.rs#L64">here</a>.</p>
<p>I&rsquo;ll admit I couldn&rsquo;t have figured out how to interpolate these commitments without leaning on ChatGPT — I was barely familiar with single-variable Lagrange interpolation and couldn&rsquo;t fathom how I could manage both the secret sharing and the blinding factor. This term was the first where I bothered to try using it as a learning tool, and I was pleasantly surprised by how decent it was for crypto in particular. Sometimes, it&rsquo;d get the explanation itself wrong, but while walking through it, I&rsquo;d manage to get a key insight that let me fill in the rest correctly. Its errors were fairly easy to spot, especially when translating its output into code: things like mixing up scalar and point addition that an additional reprompt was often enough to fix.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I hope this explainer has highlighted that the crypto isn&rsquo;t as scary as it sounds, and that the primitives of a paper aren&rsquo;t so hard to understand either. I think it&rsquo;d be neat if we required authors to submit a &ldquo;from the basics&rdquo; guide alongside their work, even if just to call out what commonly-understood terms like &ldquo;interpolate&rdquo; mean and where to look for further information<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>This isn&rsquo;t intended at all as a dig to the paper, which was otherwise very thorough and well-written. It was easy to read, and I appreciated the various comparison tables and practical benchmarking sections. The paper was a fundamental building block to my recent research work, and I&rsquo;d definitely recommend <a href="https://eprint.iacr.org/2022/971.pdf">giving it a read</a>. There&rsquo;s plenty more aspects of the paper that I haven&rsquo;t covered here, including how high-threshold secret sharing is handled and how they optimize resharing by amortizing batched operations. I wanted to focus this blog post on the main interpolation mechanisms in Algorithm 3, but here&rsquo;s a few more less-fleshed-out notes about Honey Badger:</p>
<div class="grid-element" style="margin-bottom: 0.5em">
  <details>
    <summary>More pointers on Honey Badger&#39;s properties</summary>
    <hr />
    <p>In the resharing section, we learned how we can recover the original secret <code>s</code>, but we still need to distribute the shares to the various parties. The paper outlines two options: one is to assume the presence of some trusted dealer, with full (albeit perhaps temporary) knowledge of the secret, and the other is to use a <em>distributed key generation</em> function (DKG), which can be used for a trustless setup. If we want to go the DKG route, however, the hitch is that Honey Badger is <em>asynchronous</em>, meaning that it&rsquo;ll continue to operate in face of arbitrary network delays. This therefore means that the DKG we choose also needs to be asynchronous. This is tricky, since you&rsquo;d usually expect DKGs to require some element of synchronization and consensus over which nodes to &rsquo;listen to&rsquo; during key generation. Honey Badger calls out <a href="https://eprint.iacr.org/2021/1591">Das et al.&rsquo;s asynchronous DKG</a> in particular — if you&rsquo;re interested in detangling this, I&rsquo;d recommend watching <a href="https://www.youtube.com/watch?v=A-3ZhG-7SI0">their conference presentation</a> for the same paper first.</p>
<p>Besides asynchrony guarantees, Honey Badger is also Byzantine-fault tolerant up to a third of nodes. This means that even if up to a third of nodes go rogue and actively try to submit incorrect shares for resharing or otherwise misbehave, Honey Badger can still continue with its resharing and refreshing operations. This is thanks to the multi-valued validated Byzantine agreement (MVBA) protocols used to agree on which nodes have emitted correct shares. I&rsquo;ll discuss this more in the next section on polynomial commitments. You can find their example implementations <a href="https://github.com/tyurek/dpss/blob/main/dpss/broadcast/tylerba2.py">here</a> — I didn&rsquo;t fully get my MVBA prototype working in time.</p>
<p>One last note I&rsquo;ll make is a distinction between the types of failures that Honey Badger can tolerate. One failure, as I&rsquo;ve just mentioned, is a Byzantine-fault failure, with actively malicious nodes. Honey Badger can handle up to a third of total nodes being Byzantine. On the other hand, it can only tolerate <code>t</code> honest-but-curious nodes that follow the protocol correctly (e.g. don&rsquo;t submit false <code>s_i</code>) but collude. Any more, and they&rsquo;ll be able to reconstruct <code>s</code> due to how SSS works. Otherwise, the SSS can instead tolerate having <code>n - t - 1</code> nodes being offline, since only <code>t+1</code> nodes are required to successfully recover <code>s</code>. I ran into these differences while trying to describe the overall fault-tolerance of a protocol I was developing that made use of Honey Badger, so I think it&rsquo;s worth considering here.</p>

  </details>
</div>

<p>If you&rsquo;re interested in other types of secret sharing, there are so, so many extra offshoots built off the same primitives that you can explore:</p>
<ul>
<li><em>Proactive</em> secret sharing, as mentioned above, is secret sharing where the shares are refreshed while keeping the secret itself the same. <a href="https://link.springer.com/chapter/10.1007/3-540-44750-4_27">Here&rsquo;s one of the seminal papers on this topic.</a></li>
<li><em>Dynamic</em> secret sharing, as mentioned above, lets the set of parties holding shares to change. Usually, this requires proactive secret sharing — otherwise, former shareholders could collude to reconstruct the secret. This is sometimes also called <em>mobile</em> secret sharing. <a href="https://dl.acm.org/doi/10.1145/1880022.1880028">Here&rsquo;s another paper on this.</a></li>
<li><em>Computationally secure</em> secret sharing limits the computational resources required to store shares. Secret sharing can require a lot of storage — growing linearly in the number of shares created. <a href="https://www.cs.cornell.edu/courses/cs754/2001fa/secretshort.pdf">This approach allows for more efficient sharing.</a></li>
<li>Similarly, <em>batched</em> secret sharing makes sharing multiple secrets more space-efficient. The Honey Badger paper includes a batch-amortized variant, and <a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025510004536?via%3Dihub">here&rsquo;s another paper on the topic.</a></li>
<li><em>Verifiable</em> secret sharing allows parties to validate the correctness of a share. <a href="https://eprint.iacr.org/2023/1196.pdf">Here&rsquo;s one paper on this.</a></li>
<li><em>Threshold signatures</em> are slightly different than threshold secret sharing, but there are <a href="https://eprint.iacr.org/2022/1656">interesting papers on this as well</a>.</li>
</ul>
<p>I&rsquo;m sure there are plenty more variants I&rsquo;ve missed above — it became a bit of a game during my initial literature review to figure out which magic keyword combination I needed to find relevant papers.</p>
<p>In other news, my workshop paper on decentralized E2EE key recovery was accepted! It builds on the concepts I&rsquo;ve mentioned in this post and <a href="https://kewbi.sh/blog/posts/241020/">my previous one on OPAQUE</a>. The project is called <a href="https://en.wikipedia.org/wiki/Kintsugi">Kintsugi</a>, a play on how the protocol mends together encryption key backups from distributed shares. The demo implementation is <a href="https://github.com/kewbish/kintsugi">on GitHub</a>, and I&rsquo;ll update with a copy of the paper when that&rsquo;s available. I&rsquo;m pretty proud of the fact I was able to go from knowing very little about cryptography to defining an interesting research direction to implementing and writing a whole paper in less than ten weeks. I&rsquo;m happy that the project had a solid implementation portion and a focus on applied work, since historically I haven&rsquo;t sat well with theory-only projects. Nonetheless, I appreciated the stretch to dive into the technical bits of cryptography, as opposed to glossing over it and reaching for existing libraries. There&rsquo;s still plenty of design considerations to be finalized and details to be polished on the demo, which I&rsquo;ll be working through next, but this project has been an extremely fun and challenging exercise in cryptography and protocol design.</p>
<p>There are still a few papers that I&rsquo;ve waded through and think could be explained much better, so I might make this type of cryptography/systems paper explanation a running series here. Wrestling with papers more deeply more often has been a goal of mine for a while, and distilling it into explainers <a href="https://muratbuffalo.blogspot.com/">à la Murat</a> is helpful for keeping you accountable for carefully reading all the details. I have my eye on a few <a href="https://eprint.iacr.org/2024/887">systems</a> <a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">implementations</a> <a href="https://www.usenix.org/conference/osdi20/presentation/dauterman-safetypin">papers</a>, or perhaps a more theoretical look at a <a href="https://eprint.iacr.org/2021/1591">distributed key generation</a> protocol, so we&rsquo;ll see what I come up with.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>The keen-eyed reader might notice that we&rsquo;ve been mixing <em>scalar</em> and <em>point</em> addition for the interpolation process. This has been termed doing the interpolation <a href="https://eprint.iacr.org/2017/363">&lsquo;in the exponent&rsquo;</a> — although the elliptic curve notation used here implies group multiplication, the result is equivalent to as if we&rsquo;d done the commitment interpolation in field arithmetic via exponentiation, then multiplied by the appropriate points.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>It&rsquo;s occurring to me that this might just be what appendices are commonly used for, but ideally this explainer should be in more casual language! We don&rsquo;t need thirty pages of proofs and all these Greek symbols to understand how to connect the dots to find a polynomial.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Making OPAQUE Clear</title>
      <link>https://kewbi.sh/blog/posts/241020/</link>
      <pubDate>20 Oct 2024</pubDate>
      
      <description>On becoming less oblivious to OPRFs.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I am not a cryptographer. I&rsquo;ve participated in enough CTFs to have had the refrain &ldquo;never roll your own crypto&rdquo; drilled into my head. Leave the group-modulo-n wrangling to the professionals, as the undertone went. While I won&rsquo;t encourage you to do so, today I&rsquo;ll give you enough of the basics to implement your own key exchange protocol. I&rsquo;ll leave the deploying it to prod to you.</p>
<p>To build up some backstory: I recently met someone, who, when I asked to exchange contacts, told me to add them on Signal, instead of Discord or Whatsapp. This was new. A few years earlier, I&rsquo;d had the same reaction when I needed to join some group chats that were hosted on Telegram<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I&rsquo;ve just finished <a href="https://mitpress.mit.edu/9780262548182/tor/">a book about Tor</a> for a reading group, and attended a couple talks about <a href="https://en.wikipedia.org/wiki/Mix_network">mixnets</a>. While it might have something to do with the fact that my office is in the <a href="https://www.cambridgecybercrime.uk/">Cybercrime Centre</a>, recent news like the <a href="https://en.wikipedia.org/wiki/Pavel_Durov#2024_arrest_and_indictment">arrest of the Telegram founder</a> and the <a href="https://docs.google.com/document/d/1iWCqmaOUKhKjcKSktIwC3NNANoFP7vPsRvcbOIup_BA/edit?tab=t.0">viral AR I-XRAY glasses</a> have been bringing up topics around privacy and security.</p>
<p>To me, a core thread running through these concerns is the question of who we can trust with our data. There are growing movements to <a href="https://en.wikipedia.org/wiki/DeGoogle">abandon big-tech platforms</a> and use dumb phones without internet. Folks hop between the secure messaging platforms de jour, or at least onto the incumbent, which appears to be Signal. Signal, Protonmail, even something as familiar as Whatsapp: they&rsquo;re all end-to-end encrypted. This means the servers that run these platforms only store encrypted copies of your data, and the only people who can read your funnier-in-your-head texts are you and the intended recipient. This encryption usually uses big random numbers instead of passwords, since passwords are lower-entropy. These platforms also (usually) won&rsquo;t store your keys for you, since that&rsquo;d undermine the whole point of end-to-end encryption. You&rsquo;re therefore the only person in the world who can correctly decrypt any messages that are sent — nice and safe. But what happens when you lose your phone? Sure, the app prompted you to save a recovery file, store a twelve-word recovery phrase, or back up your keys somewhere before proceeding, but like most folks, you&rsquo;d probably just skipped past that step.</p>
<p>Let&rsquo;s use passwords, you say — folks know how to use them, they generally do a better job at recording them somewhere, and there are password manager tools readily available so it&rsquo;s rare you&rsquo;ll forget them. However, even besides the myriad misconceptions about strong passwords and the dangers of people reusing passwords, there&rsquo;s the fundamental problem that the platform&rsquo;s server will have to store your password. Nowadays, it&rsquo;s usually stored hashed, so that&rsquo;s mostly fine — should someone break into the service&rsquo;s database, their only choice is to brute-force or <a href="https://en.wikipedia.org/wiki/Rainbow_table">rainbow-table</a> their way to steal your original password.</p>
<p>Now consider what happens in between you hitting &lsquo;Log in&rsquo; on the auth page and the server processing your password — or more precisely, how the bytes of your password are transmitted. Yes, hopefully in this day and age it goes through TLS, so no one should be able to read it. But the core problem is that <em>it&rsquo;s still in plaintext</em>. Once the server receives your password via HTTP, it still needs to read and process it into a hash, to compare against the stored hash. And how is this processing done? In plaintext. That puts a lot of trust on the server to behave honestly. Even if the server behaves as expected, the hardware it runs on might be vulnerable to attacks: because the password is transmitted in plaintext, it&rsquo;s also in the RAM and cache in plain text. When I was at Cloudflare, I learned about some of the ways the team architected the Workers platform explicitly for better isolation on all levels, guarding against <a href="https://developers.cloudflare.com/workers/reference/security-model/">speculative execution bugs</a>, for example. If the server&rsquo;s using plain passwords, it&rsquo;s vulnerable to SPECTRE and other lower-level attacks like it.</p>
<p>It seems, then, that there&rsquo;s no safe option. Either you have better security at the risk of fallible users losing access to their data, or you get a more familiar user experience at the expense of many layers of security concerns. However, there&rsquo;s a way to augment passwords with some neat cryptography so that you can effectively get the best of both worlds. Enter OPAQUE: a password-based key exchange protocol that lets the end user input a password and save their keys on the server, while not allowing the server any access to the password. It retains the server-has-zero-knowledge properties that we&rsquo;d expect in an E2E setting and requires both user and server to participate in any login attempts, reducing the feasibility of brute-force attacks. OPAQUE was selected for standardization by the IETF over several other similar password-based protocols, including the other top contender <a href="https://en.wikipedia.org/wiki/Secure_Remote_Password_protocol">SRP-6a</a>, because of this defense against brute-force attacks. It&rsquo;s also been implemented by several companies, including <a href="https://blog.cloudflare.com/opaque-oblivious-passwords/">Cloudflare</a> and <a href="https://github.com/facebook/opaque-ke">Facebook</a>.</p>
<p>In my current research internship, I&rsquo;ve been working with variants of OPAQUE as applied to key recovery for E2E services. We&rsquo;re figuring out how to adapt OPAQUE to store and retrieve a user&rsquo;s private key via a password: for example, in cases where they&rsquo;ve lost access to their old devices. We needed OPAQUE&rsquo;s properties: we don&rsquo;t want the server to be able to reconstruct the password and read the user&rsquo;s keys, nor do we want the user to keep the only copy of keys locally and end up susceptible to brute-force if any encrypted info leaks. We&rsquo;re adding some other goodies on top, too, but I had to implement a vanilla version first. When I was doing so, I had to trawl through tens of pages of dense crypto papers and cross reference the <a href="https://www.ietf.org/archive/id/draft-irtf-cfrg-opaque-17.html">OPAQUE spec</a> with the myriad <a href="https://github.com/search?q=opaque+protocol&amp;type=repositories">example repos</a>, but I think the core ideas boil down much more intuitively.</p>
<p>Protocols like OPAQUE shouldn&rsquo;t be secure-by-obscurity, and certainly not secure-by-lack-of-good-high-level-public-explanations. This post aims to give you the walkthrough of OPAQUE I wish I had when I embarked on this project. I&rsquo;ll assume some general CS knowledge, but otherwise I&rsquo;ll provide the context you need if you&rsquo;re starting from scratch. I&rsquo;ve chosen to gloss over some of the related crypto concepts to focus on just what&rsquo;s needed to understand the OPAQUE exchange, but I&rsquo;ve included links and mentioned other keywords if you&rsquo;d like to dive deeper.</p>
<p>I hope this post will serve to make OPAQUE clear and you less wary about crypto — reams of LaTeX can be scary, but I promise this won&rsquo;t be.</p>
<h2 id="background-elliptic-curves">Background: Elliptic Curves</h2>
<p>One of the concepts I&rsquo;ll assume some background in is <a href="https://en.wikipedia.org/wiki/Public-key_cryptography">public-key cryptography</a>. The basic idea is that you store two keys: one public and one private. You share your public key with others, and keep your private key to yourself, as the names may suggest. To encrypt something, you take your private key and the public key of the intended recipient together and do some operations on it, which ensures that only the recipient can decrypt your message, since only they have the private key associated with their public key. The idea is that public keys are derived from private keys using some hard-to-reverse operation, and that you can easily derive the public key from the private key, but not vice versa. For example, multiplying numbers is easy, but factoring numbers is hard, so part of what underlies the <a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)">RSA cryptosystem</a> is that you can&rsquo;t easily factor numbers to derive the secrets that are used to create the private key<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Elliptic-curve cryptography works on the same principle. The hard-to-reverse operation here is multiplying a point on the curve with a number. Let&rsquo;s build up to multiplying with points on the curve by first adding a point to itself, which we can then repeat <em>n</em> times to get multiplication by <em>n</em>.</p>
<p>We first have to start with the given point on the curve. The formula of this curve will change depending on the particular curve you use (and there are plenty), so I won&rsquo;t go into detail about it now. Pick a point <code>P</code>. To add the point to itself, you&rsquo;ll need to draw the tangent line to the curve at <code>P</code> — this is the line that follows the shape of the curve at point <code>P</code>. Extend the tangent line far enough, and you&rsquo;ll find that it intersects exactly one point on the curve. Call this point the tangent line intersection.</p>
<figure><img src="/img/241020/adding-points-1.png"
         alt="Figure 1. Drawing the tangent line to P."/><figcaption>
            <p><em>Figure 1. Drawing the tangent line to P.</em></p>
        </figcaption>
</figure>

<p>This tangent line intersection point is then reflected in the x-axis to get the doubled point, <code>2P</code>.</p>
<figure><img src="/img/241020/adding-points-2.png"
         alt="Figure 2. Reflecting across the x-axis to get 2P."/><figcaption>
            <p><em>Figure 2. Reflecting across the x-axis to get 2P.</em></p>
        </figcaption>
</figure>

<p>We can then repeat this again, with the tangent line for the point <code>2P</code>, to get <code>3P</code>, and so on. There are several optimizations to do this multiplication faster, including the <a href="https://en.wikipedia.org/wiki/Elliptic_curve_point_multiplication#Double-and-add">double-and-add</a> algorithm.</p>
<figure><img src="/img/241020/adding-points-3.png"
         alt="Figure 3. Repeating to find 3P."/><figcaption>
            <p><em>Figure 3. Repeating to find 3P.</em></p>
        </figcaption>
</figure>

<p>The private key in elliptic curve cryptography is the choice of a number <code>n</code>, and the public key is the curve&rsquo;s basepoint multiplied by <em>n</em>. The curve&rsquo;s basepoint is a point that&rsquo;s defined along with the curve (technically, the generator of the group we&rsquo;ll be operating in) — just consider it as a constant that&rsquo;s handed to you together with the definition of the curve. It&rsquo;s easy to compute the public key given the private key, since the multiplications aren&rsquo;t hard. However, if you want to recover the private key given just the resulting public key point, you&rsquo;ll have to try every single possible value of <code>n</code>, which is assumed to be infeasible. This multiplication is called the <a href="https://en.wikipedia.org/wiki/Discrete_logarithm_records#Elliptic_curves">elliptic curve discrete log problem</a>, as an analogy to the discrete log problem of finding the number <code>x</code> such that <code>g^x = y</code> for some public number <code>y</code>.</p>
<p>One thing to note is that if you know the number <em>n</em> that you multiplied by, it&rsquo;s easy to &lsquo;undo&rsquo; a multiplication as well. You can multiply by its inverse — think of it like doing <code>n * P * 1/n</code> — to recover just your original point. You might wonder why we can&rsquo;t do something similar to recover the number <code>n</code> from our public point, since the curve&rsquo;s basepoint is a public parameter. However, you can&rsquo;t analogously &lsquo;invert&rsquo; a point, so you&rsquo;ll still have to end up trying all the possible values of <code>n</code>. The core takeaway of all this is that division by a number is easy, and division by a point to get the number back is hard.</p>
<h2 id="metam-oprf-asis">Metam-OPRF-asis</h2>
<p>Let&rsquo;s put that elliptic curve theory to work, starting with the main building block of OPAQUE: the oblivious pseudo-random function (OPRF). We can build up what an OPRF is step by step:</p>
<ul>
<li>A function is a mapping from a domain of inputs to a range of outputs.</li>
<li>A <a href="https://en.wikipedia.org/wiki/Pseudorandom_function_family#Motivations_from_random_functions">random function</a> is an entirely random mapping from inputs to outputs. This means the random outputs should be <a href="https://en.wikipedia.org/wiki/Randomness_test">uniformly distributed</a>, which means there&rsquo;s no obvious bias in the outputs.</li>
<li>A pseudo-random function <em>looks</em> like it&rsquo;s an entirely random mapping, but is actually deterministically mapping inputs to outputs. It&rsquo;s very important that it <em>looks</em> like a random function, so it also needs to have a uniform distribution of outputs.</li>
<li>An oblivious pseudo-random function is a random function that requires two people to evaluate, where neither person learns what the other put in — they&rsquo;re <em>oblivious</em> to the other party&rsquo;s input.</li>
</ul>
<p>More concretely, let&rsquo;s describe the two people as a client and a server and define an OPRF as a function <code>F(server_input, client_input)</code> such that the client never learns the server input, and the server never learns the client input nor even the final result of the function. I think <a href="https://en.wikipedia.org/wiki/Oblivious_pseudorandom_function">Wikipedia</a> and other resources do a terrible job of explaining how this is possible, because intuitively, it isn&rsquo;t. How can the server, who&rsquo;s evaluating the function, not know its own output? How can the server also not know the client&rsquo;s input, if it was required as part of the function&rsquo;s inputs in the first place?</p>
<p>The answer lies in the elliptic-curve operations I touched on before. Here&rsquo;s how the OPRF actually works:</p>
<figure><img src="/img/241020/oprf-exchange.png"
         alt="Figure 4. The full OPRF exchange."/><figcaption>
            <p><em>Figure 4. The full OPRF exchange.</em></p>
        </figcaption>
</figure>

<ul>
<li>The client has <code>x</code>, which is a number it wants to keep secret. It multiplies this point by the curve&rsquo;s basepoint, so now we have a point. Let&rsquo;s call this point <em>x_point</em>.</li>
<li>To keep it secret, the client generates a random number <code>r</code>, which is called the <a href="https://en.wikipedia.org/wiki/Oblivious_pseudorandom_function#EC_and_conventional_Diffie%E2%80%93Hellman"><em>blinding factor</em></a>. The client calculates <code>r * x_point</code> and sends that to the server as <code>client_input</code>. The server doesn&rsquo;t know <code>r</code>, so it can&rsquo;t get the original <code>x_point</code> back. This protects the server from learning what the client inputted, but it&rsquo;s easy for the client to undo this later.</li>
<li>The server receives <code>client_input</code>, and multiplies it by its own secret number, <code>server_input</code>. (In the diagram, I called this secret number <code>key</code> to save space.) This makes the output <code>= client_input * server_input = r * x_point * server_input</code>. The server can&rsquo;t learn the actual execution output without the blinding factor <code>x_point * server_input</code> nor the <code>x_point</code> itself, because that pesky <code>r</code> is there.</li>
<li>The client receives <code>output</code>, and multiplies it by <code>1/r</code>. This lets it recover <code>server_input * x_point</code> — remember that division by a number is easy. However, the client still can&rsquo;t learn <code>server_input</code> either — remember that division by a point (<code>x_point</code>) is hard.</li>
</ul>
<p>To summarize:</p>
<ul>
<li>We want to end up with the client&rsquo;s input multiplied by the server&rsquo;s input, without either party knowing the other&rsquo;s value.</li>
<li>The property that dividing by points is hard prevents the server from learning the client&rsquo;s blinding factor or secret point and similarly prevents the client from learning the server&rsquo;s secret.</li>
<li>The property that dividing by numbers is easy enables the client to unblind the result to get the required <code>client_input * server_input</code>.</li>
</ul>
<h2 id="registration">Registration</h2>
<p>That&rsquo;s actually all the hard crypto out of the way! Let&rsquo;s now cover the three main phases of OPAQUE: the registration, login, and key exchange. The first phase is registration, where the user will use their password (a string) in an OPRF exchange to get an encryption key that only they know that they then can use to encrypt their keypair data.</p>
<p>The registration revolves around an OPRF exchange.</p>
<figure><img src="/img/241020/opaque-registration.png"
         alt="Figure 5. OPAQUE registration."/><figcaption>
            <p><em>Figure 5. OPAQUE registration.</em></p>
        </figcaption>
</figure>

<ul>
<li>The client transforms their password into a point on the curve. This is done via <a href="https://datatracker.ietf.org/doc/rfc9380/">&lsquo;hash-to-curve&rsquo; functions</a> that allow you to take arbitrary inputs to points on the curve. This is the <code>x_point</code> in the OPRF explanation above. The client then blinds their password point with some random blinding factor, <code>r</code>.</li>
<li>The server receives this <code>client_input</code>. The server generates a user-specific keypair that&rsquo;ll just be used for this user. This user-specific private key will be the <code>server_input</code> in the OPRF explanation above. It multiplies the <code>client_input</code> with its <code>server_input</code> and returns this value to the client, along with the server&rsquo;s public key.</li>
<li>The client receives this <code>output</code> and unblinds it. The client now has <code>x_point * server_input</code>. Let&rsquo;s call this unblinded output <code>rwd</code> — it&rsquo;ll be used as the key to (symmetrically) encrypt what we call the <em>envelope</em>.</li>
<li>The client generates an <em>envelope</em>, which includes a new keypair that the client will use in communications with this server. It also puts the server&rsquo;s public key into this envelope. The client then encrypts all of this with the <code>rwd</code> and sends the encrypted envelope to the server.</li>
<li>The server saves the encrypted envelope so the user can access it again later. It can&rsquo;t decrypt this envelope, since it has no way of unblinding its output to recover the <code>rwd</code>.</li>
</ul>
<p>Note that in every step of this process, the server will never learn the password nor the <code>rwd</code> used to encrypt the envelope, so the client can safely trust the server to store its information. This is critical for end-to-end encryption systems.</p>


<div class="grid-element" style="margin-bottom: 0.5em">
<details>
<summary>
A fun challenge: given the protocol as specified above, can you find the DOS attack vector?
</summary>
<hr>
<p>
It's possible for a malicious user masquerading as the client to intercept the server's output and unblind it with some random number, making the `rwd` that the malicious user calculates meaningless. This doesn't matter, though, because it can then encrypt jibberish with the `rwd` or just directly send junk to the server, which will happily store it under the original user's identifier. When the original user tries to log in, they won't be able to decrypt the envelope they retrieve from the server, which effectively DOSes their account for any future use. This means there needs to be some way of checking that the original user is the same one who provides the blinded input and the encrypted envelope.
</p>
<p>
My supervisor pointed this out in my initial implementation of OPAQUE, and I was pretty confused when I saw that none of the other implementations on GitHub handled this in any way. I ended up asking <a href="https://github.com/expede">Brooke Zelenka</a> about it, and she pointed me to <a href="https://www.ietf.org/archive/id/draft-irtf-cfrg-opaque-17.html#name-registration">this section of the OPAQUE spec</a>, which states that registration requires some other method of the server authenticating the client to ensure that it's talking to the right one. I think you can get past this if you assume enough things about the communication channel on which messages are exchanged, but I just slapped some signatures onto the messages to ensure authenticity and called it a day.
</p>
</details>
</div>


<h2 id="logging-in">Logging in</h2>
<p>Logging in also relies on a similar OPRF exchange. This time, the user needs to recover <code>rwd</code> so it can decrypt the encrypted envelope that the server returns.</p>
<figure><img src="/img/241020/opaque-login.png"
         alt="Figure 6. OPAQUE login."/><figcaption>
            <p><em>Figure 6. OPAQUE login.</em></p>
        </figcaption>
</figure>

<ul>
<li>The client transforms their password into the same point on the curve, and chooses a new random blinding factor <code>r</code>. The client blinds their password point and sends it over.</li>
<li>The server receives this <code>client_input</code> and multiplies it with the same <code>server_input</code> secret that it used during registration. The server sends this <code>output</code> along with the stored encrypted envelope to the client.</li>
<li>The client receives this <code>output</code> and their envelope. It unblinds the <code>output</code> to recover the <code>rwd</code> and uses the <code>rwd</code> to decrypt the envelope. The user has now recovered their service-specific keypair and can move onto a key exchange or further communications with the server, since the decrypted envelope will include the server&rsquo;s public key.</li>
</ul>
<p>The two main benefits of OPAQUE were that it prevents the client and server from learning anything about what the other party&rsquo;d stored or used to compute the function and that it avoids offline brute-force attacks. We&rsquo;ve previously discussed how the OPRF provides this first property via the blinding factors and elliptic-curve cryptography, but let&rsquo;s also briefly touch on the brute-force attack part. Without the OPRF, you might just encrypt the envelope with your password directly and send that to the server to store. This is both less secure than using a key, which is likely longer and has more entropy, but also allows any malicious parties, including a dishonest server, to intercept your encrypted envelope and mount an offline brute-force attack. In theory, the cryptography should ensure this takes a very long time, but the OPRF gives you the additional guarantee that any attacker must interact with the server to get their password guess multiplied by the <code>server_input</code>. This means the server is able to detect and rate-limit password attempts, making brute-force much slower than it would be otherwise.</p>
<h2 id="the-ke-rry-on-top">The KE-rry On Top</h2>
<p>The final piece of OPAQUE is the key exchange that needs to follow in order to derive a shared secret with which to encrypt all following communication. I focused less on this part of the protocol, since for my project we were only interested in the recovery of the client&rsquo;s keypair from the envelope. As well, once you&rsquo;re done with the OPRF exchanges, you&rsquo;re in some sense &lsquo;back in safe territory&rsquo; — there are plenty of key exchange protocols proposed, and you could probably plausibly choose any one of them. <a href="https://eprint.iacr.org/2005/176.pdf">HMQV</a>, a Diffie-Hellman variant, was chosen in the original <a href="https://eprint.iacr.org/2018/163.pdf">OPAQUE paper</a> for its performance. However, <a href="https://blog.cloudflare.com/opaque-oblivious-passwords/">Cloudflare&rsquo;s OPAQUE explainer</a> leverages TLS as an AKE, and the <a href="https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-opaque-01">specification</a> mentions another variant using a <a href="https://www.iacr.org/cryptodb/archive/2003/CRYPTO/1495/1495.pdf">SIGMA-I</a> Diffie-Hellman variant.</p>
<p>For the sake of completeness, I&rsquo;ll briefly cover the HMQV calculation used in the original OPAQUE paper. We want to derive a shared secret that both the client and server can calculate, and use this as a key going forward.</p>
<ul>
<li>As part of the login (or in a separate round-trip message), the client chooses a random number <code>c</code>. It multiplies the curve&rsquo;s basepoint with this to get a public point <code>C</code>. This is sent to the server.</li>
<li>Likewise, the server chooses a random number <code>s</code> and multiplies it with the curve&rsquo;s basepoint to get <code>S</code>.</li>
<li>Both client and server then compute a couple of hashes (remember that these are effectively numbers, not points.) First, the client computes <code>blinded_session_identity = H(client_identity, server_identity, r)</code> with its blinding factor. Then, let <code>e_u = H(C, server_identity, blinded_session_identity)</code> and <code>e_s = H(s, server_identity, blinded_session_identity)</code>. The exact details of this are less important to the overall protocol — this just ensures you&rsquo;re talking to the right person.</li>
<li>Then, the client computes its shared secret as <code>H((S + e_s * server_public_key) * (c + e_c * client_private_key))</code> and the server computes <code>H((C + e_c * client_public_key) * (s + e_s * server_private_key))</code>. The first parenthesis of each expression contains the public parameters that are known from the other party, and evaluates to a point; the second parenthesis contains the private parameters from the party computing the hash and evaluates to a number.</li>
</ul>
<p>If we expand both sides, we&rsquo;ll see that what&rsquo;s being hashed is the same. Feel free to skip the proof if you&rsquo;re happy to just trust that the above are equal, but it&rsquo;s neat looking at variants of Diffie-Hellman to prove how both client and server derive the same secret. I&rsquo;d encourage you to give it a go — it&rsquo;s very satisfying to see everything fall into place and the base math isn&rsquo;t challenging, though keeping all the variables in line and recognizing when to factor terms in and out can be a nice puzzle. Let <code>G</code> be the curve basepoint:</p>
<pre tabindex="0"><code>  (S + e_s * server_public_key) * (c + e_c * client_private_key) // what the client hashes
= (s * G + e_s * server_public_key) * (c + e_c * client_private_key)
= (s * G) * (c + e_c * client_private_key) + (e_s * server_public_key) * (c + e_c * client_private_key) // distribute the multiplication
= (s * G * c) + (s * G * e_c * client_private_key) + (e_s * server_public_key) * (c + e_c * client_private_key)
= (s * G * c) + (s * G * e_c * client_private_key) + (e_s * server_private_key * G) * (c + e_c * client_private_key)
= (s * G * c) + (s * G * e_c * client_private_key) + (e_s * server_private_key * G * c) + (e_s * server_private_key * G * e_c * client_private_key)
= (s * G * c) + (e_s * server_private_key * G * c) + (s * G * e_c * client_private_key) + (e_s * server_private_key * G * e_c * client_private_key) // rearranged terms
= (s * G + e_s * server_private_key * G) * c + (s * G + e_s * server_private_key * G) * e_c * client_private_key // factor out c and e_c * client_private_key
= (s + e_s * server_private_key) * c * G + (s + e_s * server_private_key) * e_c * client_private_key * G // factor out G
= (s + e_s * server_private_key) * (c * G + e_c * client_private_key * G) // factor out first term
= (s + e_s * server_private_key) * (C + e_c * client_public_key)
= (C + e_c * client_public_key) * (s + e_s * server_private_key) // what the server hashes
</code></pre><p>This completes the authenticated key exchange, and in turn, the OPAQUE protocol!</p>
<h2 id="conclusion">Conclusion</h2>
<p>When I was first looking into implementing OPAQUE, my supervisor sent me the original paper as some helpful reading, but after seeing the PDF was 61 pages long, I bailed out to go read through the <a href="https://blog.cloudflare.com/opaque-oblivious-passwords/">Cloudflare explainer</a> instead. The original paper only has the full protocol laid out on page 47! The rest of the paper, and even the protocol description itself, is very dense — I suppose it&rsquo;s nicely concise for those who have been in the field for long enough that they can parse the math at first glance, but trudging through all of that isn&rsquo;t fun for a first-timer. I found the crypto explainers in general to also be at weird levels of abstraction that didn&rsquo;t immediately make it clear how primitives built together, particularly for topics like elliptic-curve cryptography or OPRFs.</p>
<p>In general, I&rsquo;ve noticed that theoretical crypto papers always start with a sea of security games where they prove the correctness and security of their protocol, but not actually explain the protocol until later, as if the protocol is an afterthought that derives naturally from the security games. Again, this probably makes sense for the cryptographers who are focusing on the security, but you&rsquo;d think you&rsquo;d put your major contribution up front in the paper. Another thing I&rsquo;ve noted about crypto papers is how little discussion they usually have. Unless it&rsquo;s an applied crypto paper where the system has been fully implemented and benchmarked, there&rsquo;s usually at most a page or so of discussion, which mostly consists of re-explaining that they protocol is better than the others that currently exist. The conclusion is also usually on the order of a paragraph or two, which is a far cry from the systems/HCI papers that I&rsquo;d read. As well, one thing that&rsquo;s nice is that the modern crypto papers in major journals are mostly all available freely via the <a href="https://iacr.org/publications/">IACR</a>. Having almost all my references centralized on the IACR archives and the IACR having a sequential numbering scheme have had the side effect of me memorizing the numbers of the key papers I&rsquo;ve been referencing over and over again, to the point that I can type in the first digit out of the three or four digit ID and have Chrome autofill the rest as the first search result. Such is crypto research.</p>
<p>I came into this project not really having much crypto background besides understanding the basics of public key cryptography and what an elliptic curve was. The main resources I used to hack my way through were Wikipedia entries, which were usually less notation-heavy than papers, Cloudflare explainers published via their blog, and, in an unusual-for-me turn, ChatGPT. It&rsquo;s surprisingly decent at explaining crypto and math topics — I was very wary of it getting things wrong, but it turns out even if it&rsquo;s messing up some of the details, it&rsquo;s good enough at imparting the intuition that lets you get a skeleton of an implementation done, enough to check it against the expected outputs from Wikipedia or the actual paper. I did write the code myself, since it wasn&rsquo;t quite understanding the libraries I needed to use, but it did a fair job of pointing me in the right direction or mentioning keywords (even if they were explained in the wrong contexts) that I could check against other resources. I&rsquo;m decidedly less anxious about using ChatGPT as an assistant now, and I expect it to keep giving me enough nudges to make my way to the end of my project.</p>
<p>Anyways, I hope this explainer has been clearer than the usual seas of math notation that never tell you how things fit together or how the intuition works. I&rsquo;m thinking of doing the same sort of explainer for some other cryptography topics that I&rsquo;ve had to wrestle with for my project recently, like Shamir secret sharing. As my supervisor said, warning people not to roll their own crypto is a bit patronizing when you think of it: it discourages folks from really understanding the protocols they&rsquo;re relying on and creates this out-group of folks who think they&rsquo;re not good enough to do crypto. It emphasizes this mindset where people aren&rsquo;t trusted to understand any crypto well enough to not mess it up. While this was probably trying to prevent people from writing their own very easily breakable ciphers and things of that more trivial nature, I think it&rsquo;s a bit of a gatekeep-y refrain. Go forth and implement your own OPAQUE — hopefully this explainer has made you a little less oblivious to OPRFs and OPAQUE and how to build them!</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Admittedly, not generally known for being truly secure, particularly against malicious Telegram employees, but it marketed itself as something different to the conventional chat platforms I&rsquo;d used before then.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>When I say &lsquo;hard&rsquo; in this post, I generally mean &lsquo;currently no one thinks it&rsquo;s possible&rsquo;, but that doesn&rsquo;t roll off the tongue quite so well. If it makes you happier, replace &lsquo;hard&rsquo; with &lsquo;requires exponential-time brute-force&rsquo;, and &rsquo;easy&rsquo; with &lsquo;polynomial-time or less&rsquo;.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Truth or DARE</title>
      <link>https://kewbi.sh/blog/posts/241006/</link>
      <pubDate>06 Oct 2024</pubDate>
      
      <description>On Darmstadt and distributed systems.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I think distributed systems are neat, but I also don&rsquo;t think I understand them well enough to warrant my level of interest in them. I&rsquo;ve never taken a distributed systems course, have only stumbled my way through the <a href="https://fly.io/dist-sys/">Fly.io distributed systems challenges</a>, and have never wrestled with more complicated design constraints while architecting something from the ground up. Whenever folks ask me about what particular subfield I&rsquo;m interested in, I don&rsquo;t have a concrete answer. Sure, I&rsquo;ve read <a href="https://books.google.co.uk/books/about/Designing_Data_Intensive_Applications.html?id=zFheDgAAQBAJ"><em>Designing Data-intensive Applications</em></a> and have covered the concepts behind different consistency models at least three times, but I still tended to butcher their distinctions when explaining them. If distributed systems was a band, I&rsquo;d definitely be labelled as a fake fan. I&rsquo;ve wanted to do something about this for a while — I&rsquo;ve wanted to finally <em>understand</em> distributed systems and be a <em>real</em> distsys engineer. So when a great opportunity cropped up, I shipped myself off to Germany to spend a week among brutalist buildings, looming castles, and most importantly, a cohort of grad students and eminent researchers, to see if I could make some progress.</p>
<p>The <a href="https://dare-summer.github.io/">Second ACM Europe Summer School on Distributed and Replicated Environments</a> is not only a bit of a mouthful — it&rsquo;s also a summer program that invites grad students interested in distributed systems together to participate in lectures and labs taught by leading professors in the area. Last year, it took place in Brussels, Belgium, and this year, we were hosted in Darmstadt, Germany, at the <a href="https://www.tu-darmstadt.de/index.en.jsp">Technische Universität Darmstadt</a>. Each day of the program consisted of several chunks of either lectures, which were more formal presentations about some new research, or labs, which were structured like a programming assignment and set us free to tackle some extension problem related to the lecture. A list of the speakers is available <a href="https://web.archive.org/web/20240929083858/https://dare-summer.github.io/speakers/">here</a>, and the program for this year is <a href="https://web.archive.org/web/20240929083842/https://dare-summer.github.io/program/">here</a>.</p>
<p>I&rsquo;m currently an undergrad, so I would normally be ineligible. However, Professor Kleppmann (author of aforementioned <em>Designing Data-intensive Applications</em>) was supervising me for my current research internship and also speaking at DARE, so he encouraged me to apply. I&rsquo;m very grateful that I was invited to apply, and immensely surprised that my prior research experience and quickly-put-together motivation letter sufficed to make up for my lack of a degree.</p>
<p>My previous experience in distributed systems work was primarily through a <a href="https://www.cs.ubc.ca/students/undergrad/courses/specialty">CPSC448 directed studies</a> that touched on formal verification, though I didn&rsquo;t do any actual proving. As well, my work at Cloudflare and at Stripe were fairly relevant: while I wasn&rsquo;t directly working on quote-unquote distributed systems, I was doing infrastructure work that was appropriately flavoured as such. My motivation letter listed these, as well as name-dropping an <a href="https://kewbi.sh/blog/posts/240526/">unrelated paper</a> I&rsquo;d worked on in the software engineering space. I don&rsquo;t think the applications were particularly selective, since the <a href="https://tuda-dare24.hotcrp.com/">HotCRP</a> listed 32/36 submissions accepted, and I&rsquo;d assume at least a couple of those were test submissions. I was still very nicely surprised when I&rsquo;d heard back about my acceptance, though, and I&rsquo;m again very thankful I was granted the opportunity.</p>
<p>I&rsquo;d taken notes during each lecture and wanted to revisit them, so this is a post summarizing my main takeaways from the talks and from the program overall. Each of the subsections here could be a blog post in itself — this will be the longest post on my blog to date, but it&rsquo;s also because it&rsquo;s covering a packed week of dense lecture material. I&rsquo;ve written up my notes in the same order as the lectures occurred, so you&rsquo;ll get to relive the learning at DARE as it happened. Professors and other students: I might&rsquo;ve made some mistakes or simplifications in the below — please forgive me!</p>
<h2 id="martin-kleppmann--bft-decentralized-access-control-lists">Martin Kleppmann — BFT Decentralized Access Control Lists</h2>
<p>Professor Kleppmann&rsquo;s lecture turned out to be very closely aligned to what I&rsquo;ll be working on this term with him, and it was nice getting the high-level summary lecture at DARE before diving into extension work. His talk revolved around a decentralized access control list protocol, where members can be added and removed from a group chat. This seems simple, but there are tricky edge cases when concurrency gets involved: if two people concurrently remove each other, what happens? What happens if a user who is removed by another user concurrently adds their own guest user? The protocol also needs to be Byzantine-fault tolerant, meaning that the system must continue to provide a consistent access control model despite having nodes that don&rsquo;t correctly follow the protocol. All in all, not as easy as it seems.</p>
<p>We started by covering some of background — how can you implement a BFT system. One approach is a version vector, where every replica keeps track of its idea of the state of the other replicas. However, they aren&rsquo;t safe in a Byzantine context, since a malicious replica can send different updates to different nodes with a version vector crafted to confuse the two nodes into thinking they&rsquo;re in sync when they&rsquo;ve actually diverged.</p>
<p>You can solve this, though, by using a hash graph, like in Git. Each &lsquo;commit&rsquo; or operation contains the hash of the previous one, which implicitly will transitively include the hash of the predecessor&rsquo;s predecessor, and so on. If the hashes of the most recently received operation are the same, you can assume that two nodes are in sync, relying on the property that cryptographic hash collisions are hard to find. Otherwise, you can keep moving backwards in the graph until the two nodes converge on a common point, then exchange all updates after that point. This is good for a Byzantine context, but is inefficient in the number of roundtrip exchanges, since both nodes will have to continuously communicate as they &lsquo;move backwards&rsquo; in the hash graph. It&rsquo;d be nice if we could figure out the set of updates to share more efficiently.</p>
<p>Generally, you can speed up set membership checks by using <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a> to approximate things. <a href="https://martin.kleppmann.com/2020/12/02/bloom-filter-hash-graph-sync.html">A paper</a> he worked on applied that exact idea, which seems like such an obvious idea once you think about it. Both nodes can send a Bloom filter of the operations they currently know about and walks backward to check if operations were in the other side&rsquo;s Bloom filter, and if not, sends them over. This repeats until the nodes are in sync again — no more redundant updates. Someone once told me that the best research is the intuitively obvious stuff, and I think this paper is no different. Applying a relatively basic CS concept to a new problem space in exactly the way the concept should be used makes the work both easier to understand and to defend. I hope that I&rsquo;ll be able to hone my &lsquo;finding obvious directions&rsquo; skills more to take advantage of this.</p>
<p>Returning to the hash graph, Professor Kleppmann also went a bit into detail about blockchains. They&rsquo;re overall similar to hash graphs, but instead have a total ordering of blocks, which requires Byzantine-fault tolerant consensus. This is needed in blockchain settings to prevent double-spending of currency, but in this decentralized ACL group application we don&rsquo;t need there to be only one ordering of operations — we just need some sort of convergence. This taught me about the difference between consensus and collaboration: in consensus, nodes decide on one alternative; in colaboration, we can keep all alternatives and need to figure out how to put them together.</p>
<p>With all this background, we then worked through some design decisions around how to handle the ACL group edge cases mentioned above (spoiler alert: handling them is still active research). Some alternative systems were brought up, like Matrix&rsquo;s <a href="https://matrix.org/docs/older/moderation/#:~:text=better%20to%20redact.-,Power%20levels,-The%20next%20line">power levels</a> or some sort of seniority-based system. We ruled out user voting, since that&rsquo;s susceptible to Sybil attacks, where malicious nodes control a coordinated group of users, and social engineering. For our lab, we were given some starter code implementing one such ACL CRDT and were given freedom to explore implementing some of these ideas.</p>
<h2 id="elisa-gonzalez-boix--crdt-fundamentals-and-ambienttalk">Elisa Gonzalez Boix — CRDT Fundamentals and AmbientTalk</h2>
<p>Professor Gonzalez Boix presented their work on AmbientTalk, an actor-based programming language that supports communication across peers without any explicit infrastructure. In particular, it supports volatile connections that might drop any time.</p>
<p>The language is service-based, with events for when services are discovered and when messages are received or sent. You can define custom services in these languages and use the asynchronous messaging and lease primatives to communicate between them. The <a href="https://soft.vub.ac.be/amop/at/introduction">intro page</a> has more examples, but here&rsquo;s an overview of what it looks like:</p>
<pre tabindex="0"><code>whenever: Service
discovered: {
	|ref| // far reference
	when: message_type@FutureMessage()
	becomes: {
		|ref|
		...rest
	}
}

def service := object: {
    def message() {
	...
	return value
	}
}

export: service as: Service;
</code></pre><p>The language has a concept of <a href="https://soft.vub.ac.be/amop/at/tutorial/actors#actors_and_far_references">far references</a>, which as far as I can tell originated in <a href="https://en.wikipedia.org/wiki/E_(programming_language)">E</a>. These far references are like pointers across machine boundaries that work asynchronously. Messages that are sent to far references when connectivity drops are buffered in a queue and will be resent eventually later. Objects are passed between actors as far references, but primitive data is shared via isolates, working in a pass-by-copy fashion.</p>
<p>Most of the talk was about some CRDT fundamentals, which I won&rsquo;t go into here, as well as AmbientTalk&rsquo;s unique features, but I also wanted to mention the fun lab we had working in it. We were playing around with an interactive shopping list example app based on a CRDT that was handling its network communication via AmbientTalk&rsquo;s runtime. It was nice not having to code any of that and seeing things &lsquo;just work&rsquo;. The idea was that the shopping list app was collaborative, so if you specified the same <code>Service</code> name, you&rsquo;d be able to dynamically discover peers on the same network and listen to their messages. This ran into a slight challenge, because there were thirty of us in a small room all competing for the same messages, but we worked around this by all declaring services with slightly different names. Some of us managed to get collaboration to work across devices, but something to do with my firewall or the eduroam network we were on wasn&rsquo;t letting me try that particular feature out. This was still one of my favourite labs of the program, though.</p>
<h2 id="antonio-fernandez-anta--amecos">Antonio Fernandez Anta — AMECOS</h2>
<p>One of Professor Anta&rsquo;s students actually presented a poster about his lecture&rsquo;s research project at our poster session on the first day, so I had seen a bit of the background before the talk, although I&rsquo;ll admit I still didn&rsquo;t fully follow. The work presented was called AMECOS: A Modular Event-based framework for Concurrent Object Specification, In a similar vein to Professor Kaki&rsquo;s talk below, they noted that currently, concurrent objects are generally specified sequentially and assume some way to keep track of the object&rsquo;s state.</p>
<p>They define events as &lsquo;opex&rsquo;es, or &lsquo;operation executions&rsquo;, then define the various consistency models around the properties that these opexes would hold. For example:</p>
<ul>
<li>Linearizability implies a &lsquo;realtime&rsquo; ability to globally read a value written anywhere else immediately after the write finishes, so there can&rsquo;t be simultaneous opexes and any reads will return the latest write opex&rsquo;s value.</li>
<li>For sequential consistency, the process order must be respected, but the action doesn&rsquo;t necessarily have to take effect instantaneously between its invocation and its response.</li>
<li>For causal consistency, we also require process order to be respected, but each process can have its own order of the other read/write opexes as long as it respects causal order between order events. This allows opexes to be executed locally without requiring communication or agreement with other processes.</li>
</ul>
<p>It&rsquo;d be difficult to specify these consistency models sequentially, so they specify the system modularly as an execution. An execution is correct if there&rsquo;s an opex ordering that satisfies the consistency property required. The advantages of this approach are that they don&rsquo;t assume some omniscient power knowing the total arbitration order, that the object&rsquo;s state doesn&rsquo;t need to be tracked, that the object is described only via its interface, and that the object&rsquo;s specification can then be separated from the consistency definitions it needs.</p>
<h2 id="gowtham-kaki--novel-consensus-proof-techniques">Gowtham Kaki — Novel Consensus Proof Techniques</h2>
<p>Professor Kaki&rsquo;s talk centred around novel ideas for proving distributed systems, particularly for modelling consensus via convergence and monotonicity. The current standard approach to modelling distributed systems is via asynchronous message passing, but it&rsquo;s hard to, say, specify a safety invariant for a leader election with message passing. A first attempt might look like checking &lsquo;if A has elected B as its leader and C has elected D as its leader, then B = D&rsquo;, but induction doesn&rsquo;t work for this. This invariant also allows some invalid state transitions.</p>
<p>The key takeaway I had from his talk was his point that strengthening invariants is a valid proof strategy that can unlock the final proof. Counterintuitively, you now need to prove more properties, but you can also assume more starting points in the inductive step. The final inductive invariant in the leader election might include all of the following properties:</p>
<ul>
<li>if a leader has been assigned to a node, a quorum of votes should exist for that leader</li>
<li>if a leader message exists, a quorum of votes should exist for that node</li>
<li>a node can only vote for one node</li>
<li>if a node has voted for some node and a vote message exists, the message and the leader should be the same</li>
<li>if two voting messages came from the same node, they should be the same</li>
<li>if a voting message exists, the node should have voted</li>
</ul>
<p>We can also avoid using an induction approach for the proof and instead rely on the convergence of leadership — the fact that it doesn&rsquo;t matter in what order the voting messages are processed so long as they vote for the same leader — and monotonicity of leadership — you can either vote for no one or the same leader, which you can model via a lattice. This monotonicity and convergence gives you consensus.</p>
<p>You can then model consensus with some way of replicating state, and place these two invariants on it. They found that while this replicated state approach required more messages than the async message passing approach, it instead performed better in terms of throughput. They&rsquo;re still working on this, as they&rsquo;ve mentioned they haven&rsquo;t implemented garbage collection or crash recovery in the evaluation system, but I think the gist is that this is a viable alternative to the typical message passing implementations for consensus.</p>
<p>I had a bit of trouble following these two specification/verification talks, mostly because of the formality of the details introduced, but I&rsquo;ll come back to revisit the material should they come in handy.</p>
<h2 id="carlos-baquero--state-based-crdt-performance">Carlos Baquero — State-based CRDT Performance</h2>
<p>One of the other lectures (I don&rsquo;t recall who) cited the <a href="https://inria.hal.science/inria-00609399v1/document">2011 CRDT paper</a> that Marc Shapiro wrote. I&rsquo;ve read the paper for my past research internship around formal verification, and I know the paper&rsquo;s a foundational one. I didn&rsquo;t realize, though, that Professor Baquero was also a co-author on the paper — I only put two and two together when the speaker was listing out the authors and gestured towards him. A very small world.</p>
<p>Professor Baquero&rsquo;s talk was on CRDTs and an optimization that can be applied to reduce the size of state you need to send back and forth. The general idea is that state-based CRDTs can be inefficient. For example, take an <a href="https://crdt.tech/glossary#:~:text=Add%2Dwins%20set%20(AWSet)%3A">add-wins set</a>: it keeps track of a set of tombstones for removed elements to guard against cases where an element&rsquo;s &lsquo;remove&rsquo; operation is processed before its &lsquo;add&rsquo;. As well, removed elements are typically also kept in the main set, duplicating the storage needed.</p>
<p>This talk had some background about <a href="https://en.wikipedia.org/wiki/Semilattice">join semi-lattices</a> and partially-ordered logs. A join semi-lattice is a type of structure that defines a join operation that you can apply to two states to get the joint state: the join is a bit like a set union with extra spice. Intuitively, the &rsquo;lattice&rsquo; part of the name connects to the fact that when you draw up all the possible joins and states, you end up with a lattice-like shape, with an empty state at the bottom and a final state at the top. This final state is the result of joining all the possible inputs together — there&rsquo;s some maths calling it the &rsquo;least upper bound&rsquo;, but you can think of it like &rsquo;the state that contains all of these other states joined together&rsquo;. Very frequently, this looks like a union if you squint. These states can be defined by applying this join operation based on the operations in a partially-ordered log, or a polog, for short. If you model state for a <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type#G-Counter_(Grow-only_Counter)">grow-only counter</a> in the polog like <code>{A(1), B(2)}</code>, for example, then you could define your join operation to take two states and do a member-wise max. If we had <code>{A(1), B(2)}</code> and <code>{A(3), B(1)}</code> to join, we would then get <code>{A(3), B(2)}</code>, then sum across all members to get the final grow-only counter value of of 5. Each replica keeps a local view of this polog to derive its state.</p>
<p>This state ends up getting pretty big, however, when you consider <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type#2P-Set_(Two-Phase_Set)">tombstone sets</a> and more complicated CRDTs. Instead of sending over the whole state, the approach presented therefore relies on deltas and mutations. For example, if you get an update from replica A that it&rsquo;s been incremented twice, just send that as a delta mutation instead of sending over all the extra state for replicas B, C, and D. You can fragment your state into so-called <em>irredundant join decompositions of state</em>, turning something like <code>{A(1), B(2)}</code> into <code>{A(1)}, {B(2)}</code> and send the deltas based on these smaller bits instead.</p>
<p>One of his students&rsquo; PhD thesis builds this out more, explaining how you can decompose a state, hash the members to assign their values to buckets, then calculate what buckets to send over to each replica to limit sending duplicated state. You can also apply bloom filters to efficiently test what needs to be sent over. However, there are some issues with false positives in Bloom filters, so both bucket and bloom filters need to be combined for a robust system. There&rsquo;s a whole four-round system of sending bloom filters, their differences, and buckets across that you can read more about <a href="https://vitorenes.org/publication/enes-efficient-synchronization/enes-efficient-synchronization.pdf">here</a>.</p>
<p>Aside from the content of the talk, there were two sort of offhand points about communication times that&rsquo;ve instead really stuck. One was that the whole world can be connected at a latency supporting FPS games and other real-time applications just because the Earth&rsquo;s diameter is small. It&rsquo;s neat to think about: if the Earth was larger, there could&rsquo;ve been whole classes of apps that would&rsquo;ve never been invented. The other is that communication round-trips to space colonies (e.g. Mars) will dramatically increase from what we&rsquo;re used to on Earth, and could be up to a 20 minute RTT. It was very thought-provoking to consider space tech as a field where CRDTs will likely become necessary — when you have such long response times and occassional periods where communication isn&rsquo;t possible, you can&rsquo;t really lean too heavily on the classic client-server model. I want to learn more about the state of space tech in the future, especially since a fellow Rise Global Winner has just gotten into YC with their <a href="https://bifrostorbital.com/">satellite startup</a>. I think there&rsquo;s a lot of interesting potential with critical systems that&rsquo;ll need certain consistency and consensus guarantees.</p>
<h2 id="mira-mezini--algebraic-rdts">Mira Mezini — Algebraic RDTs</h2>
<p>Professor Mezini talked about replicated data types, particularly the concept of an ARDT, or an Algebraic Replicated Data Type. Her talk presented how ARDTs can be used for decentralized state management, can be used reactively for propagating changes, and can be used for coordination with various consistency and availability guarantees.</p>
<p>An interesting point she brought up was that Brewer, the inventor of the <a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP theorem</a>, now states that the CAP theorem&rsquo;s application should be relaxed in modern systems to fit with the specific system&rsquo;s requirements. Sometimes, we can relax consistency a little bit to allow for more availability, and vice versa. It doesn&rsquo;t have to be an all-or-nothing choice given today&rsquo;s technologies. I liked this take, particularly because I could see it in the previous internship work I&rsquo;ve done — we used <a href="https://en.wikipedia.org/wiki/Isolation_(database_systems)#Serializable">serializable</a> transactions just for this part for high consistency, but for better performance left everything else in <a href="https://en.wikipedia.org/wiki/Isolation_(database_systems)#Read_uncommitted">read-uncommited transactions</a>.</p>
<p>ARDTs were presented as a standard library of composable, primitive data-type RDTs that you could really customize but still have working together. They differ from CRDTs because off-the-shelf CRDTs have fixed design decisions baked into them, like assumptions about various network models, and causes a bit of an impedance mismatch when trying to actually program with data. Using ARDTs allows you to decouple the state of data from its dissemination, so that the communication and network becomes irrelevant to the actual application logic. They felt a bit like Jacky&rsquo;s <a href="https://jzhao.xyz/posts/bft-json-crdt">BFT JSON CRDT library</a>, and to be honest I can&rsquo;t quite articulate the difference between ARDTs and &lsquo;customizable CRDTs&rsquo; better than this.</p>
<p>She presented a subset of ARDTs called reactive ARDTs that would avoid callback hell as well as having to track data dependencies across systems. Right now, it&rsquo;s difficult to model and manage updates in data being propagated correctly to other places given a system with diverse nodes — I think the final chapter of DDIA covers this a little as well. They designed a language, <a href="https://dl.acm.org/doi/10.1145/3191697.3214337">REScala</a>, that operates with these reactive ARDTs and their dependency effect chains as first-class citizens in the runtime. This way, it&rsquo;s easier to understand, since events are modelled as happening instantaneously, but also lets the runtime handle making the effect chains strictly serializable and more consistent.</p>
<p>There was also some work on coordination ARDTs mentioned along this vein, to enforce application level invariants that are difficult to otherwise manage via consensus. They achieved this via adding a verifying compiler, <a href="https://dl.acm.org/doi/10.1145/3633769">LoRe</a>, to REScala. Their coordination works by making use of locking without requiring offline nodes to agree. The system models interactions between systems as having certain pre/post-conditions and actions, so the compiler can check that the overall invariants hold at each step.</p>
<p>Fun note about her slides is that I noticed one of the images she used on a slide about decentralized collaborative applications looked really familiar. Halfway through, it hit me that it was actually the title image from the Ink and Switch <a href="https://www.inkandswitch.com/crosscut/">Crosscut</a> article, which ironically is explicitly a &lsquo;personal thinking space&rsquo; and not a collaborative tool. Say you will about me being able to recognize the Ink and Switch blog post images on sight.</p>
<h2 id="annette-bieniusa--formalizing-broadcast-tla-and-erla">Annette Bieniusa — Formalizing Broadcast, TLA+, and Erla+</h2>
<p>Professor Bieniusa&rsquo;s talk was listed on the program as something to do with reactive datatypes and Elixir, which I was looking forward to finally learning a bit more about, but she actually spoke on specifying different broadcast models in TLA+! TLA+ is a specification language used in formal verification, and it&rsquo;s been used in the industry to verify and model many critical systems, notably including AWS&rsquo;s S3. I&rsquo;ve worked a little with TLA+ in my previous research internship on an extension to the <a href="https://distcompiler.github.io/">PGo</a> project, a compiler that translated Modular PlusCal (which itself compiles to TLA+) directly into production-ready Go systems.</p>
<p>So imagine my surprise when the project Professor Bieniusa talks about is about a project, Erla+, that&rsquo;s almost exactly that, just with Go replaced with Erlang! However, their work compiles from a subset of PlusCal directly into TLA+ and Erlang, whereas PGo requires the use of our custom Modular PlusCal extension language first, so they&rsquo;ve cut out the need to learn new syntax. Also, their compiler produces actor-based systems, which I don&rsquo;t know much about but seem to map quite naturally to having multiple distributed nodes that one needs to coordinate. It was neat to see how much the two projects naturally mirrored each other.</p>
<p>The bulk of her talk was primarily about broadcast, though. We talked through several variations, including best-effort broadcast, reliable broadcast, and uniform reliable broadcast. Best-effort broadcast is just a broadcast where you try your best to deliver messages with no retries or other guarantees. For a reliable broadcast, you force each node to forward its messages, and for a uniform reliable broadcast, you need to ensure all messages are also <em>delivered</em>, or received. Unfortunately, uniform reliable broadcast can&rsquo;t exist if the majority of nodes fail, for obvious reasons. We also defined a few properties that we used in these definitions:</p>
<ul>
<li>FIFO property → if you broadcast <code>m</code> from <code>p</code> then <code>m'</code>, then <code>m</code> is delivered before <code>m'</code></li>
<li>causal property → if you broadcast <code>m</code> from <code>p</code> then <code>m'</code> from <code>q</code>, then <code>m</code> is delivered before <code>m'</code></li>
<li>total order property → if <code>m</code> is broadcast from <code>p</code> before <code>m'</code>, then <code>m</code> is broadcast from <code>q</code> before <code>m'</code></li>
</ul>
<p>We then spent some time learning TLA+ syntax and primitives to formally model these properties. I learned that TLA+ uses something called linear-time logic, which gives you a set of executions that are considered correct. You can then define linear-time properties, like safety and liveness properties. A safety property requires that if any execution is incorrect, then there was a prefix of that execution where the remainder of the execution did not fulfill the property — intuitively, it requires that if something went wrong, there was a particular &rsquo;turning point&rsquo; where things went south. Safety can only be satisfied given infinite time, but can be violated in finite time.</p>
<p>On the other hand, a liveness property requires that for any prefix of an execution, there is a set of following executions for which the property is also satisfied — intuitively, that the execution &lsquo;keeps running&rsquo;. Liveness can conversely only be violated in infinite time and is satisfied in finite time.</p>
<p>To model these in TLA+, you need a couple operators: <code>[]F</code> denotes that <code>F</code> is always true, and <code>&lt;&gt;F</code> that <code>F</code> is eventually true. You can also combine these, so <code>[]&lt;&gt;F</code> states that at all times, <code>F</code> is either true or will be true, so intuitively this expresses that some progress will be made towards getting to <code>F</code> eventually. The reverse, <code>&lt;&gt;[]F</code>, expresses that eventually, <code>F</code> will always hold. Intuitively, this denotes stability.</p>
<p>The final concept I&rsquo;ll cover is how we apply these to express &lsquo;fairness&rsquo;. It&rsquo;s a property that states that if something happens &lsquo;often enough&rsquo;, it should eventually happen. There&rsquo;s variations: weak fairness can be expressed as <code>&lt;&gt;[]F → []&lt;&gt;F</code> and says that a step towards <code>F</code> must eventually occur. The implication reads that if <code>F</code> is eventually continually true, then it must eventually occur. Strong fairness, on the other hand, can be expressed as <code>[]&lt;&gt;F → []&lt;&gt;F</code>, which says that a step must eventually occur even if something is not eventually continually true. For more intuition about the difference between weak and strong fairness, think of a traffic light. If the traffic light is strongly fair, the car will eventually have to go, because it&rsquo;ll eventually be green before switching back to red. However, if the traffic light is weakly fair, then the car might never go, because the traffic light will eventually switch back to red and never has a point where it will continue to always be green. This was really mind-bending to wrap my head around, and I think the concepts of eventual-ness and the timing logic here is fun to dig into.</p>
<p>Another coincidence: I also learned that Professor Bieniusa will be collaborating with my supervisor for my research internship next term, so we might get to connect again soon!</p>
<h2 id="german-efficiency">German Efficiency</h2>
<p>In addition to the cold, hard, technical details, I also learned about the finer details of European education systems (the Belgian and German ones, in particular) and about Darmstadt and Germany as a whole. I speak no German, so I had to rely on the locals speaking English. I was a little self-conscious about being the classic clueless North American tourist who romps about Europe and is generally a nuisance. Granted, I don&rsquo;t think I bothered anyone, but I really felt like I was very uncultured and not well-informed before learning about any of this. I&rsquo;m starting to get why people recommend exchange programs and travelling so much — you learn so much by osmosis and vibes, even from a quick stay where you&rsquo;re not interacting much with the locals.</p>
<p>Some quick-fire notes:</p>
<ul>
<li>The Frankfurt airport seemed very empty, even though I was arriving on a weekend afternoon, when I&rsquo;d have expected it to be bustling. Maybe I was in a quieter terminal.</li>
<li>On the other hand, the smoking lounges seemed very full. I was mildly shocked to see a smoking lounge right out the gate, especially indoors. It was also odd to see people smoking right outside doors, young people smoking, and other indoor smoking areas. In Vancouver, it tends to be fairly rare and is almost always an older person huddled in an alleyway, not a well-dressed twenty-something strutting by with friends.</li>
<li>Darmstadt is literally translated as &ldquo;colon/intestines-city&rdquo;. Something about how if Germany was anthropomorphized into a human, Darmstadt would be smack where the bowels were. Apologies if you were enjoying a nice meal at this point in reading.</li>
<li>Trains seem to be consistently late. We took a train a bit closer to Frankfurt to hike, and our train there was almost ten minutes late, and our train back was closer to fifteen late. I was told that German efficiency only applies to cars.</li>
<li>Germans are pretty intense about their hiking. We went up a &lsquo;small hike&rsquo; to <a href="https://www.schloesser-hessen.de/en/schloss-auerbach">Auerbach Castle</a>, which was the better part of an hour up a fairly steep hill. I&rsquo;d assumed since they didn&rsquo;t ask about accessibility restrictions that the &lsquo;hike&rsquo; meant a flat walk, but no, this was really a hike. At some point we saw people <em>biking</em> down the very steep, narrow path, and at the top I was told that most Germans would not consider our trek anything near a hike.</li>
<li>Everything initially seems more expensive than Canada — for example, ramen might run you 14 euros. I was told that this was relatively cheaper than other parts of Europe, but the converted equivalent of ~$21 CAD seemed a little steep. Something closer to $12-15 CAD is what I&rsquo;m used to. However, when you factor in the lack of tip and the already-included tax, it&rsquo;s not far off from Vancouver prices. It was nice that most prices were round numbers too, which helped with sorting out change.</li>
<li>It rains a lot, and people are used to it. One of the highlights of the program was a walking tour around the city on our first day, during which it started thunderstorming and pouring. The lightning and thunder were just a few seconds apart, and we were huddling, trying to recall the conversion for time between lightning and thunder to how close the storm was to figure out screwed we might be. Our guide, completely unfazed, led us around into the main city centre castle and continued peppering us with facts.</li>
<li>Darmstadt has their own 9/11 story, albeit in 1944. The city was <a href="https://en.wikipedia.org/wiki/Bombing_of_Darmstadt_in_World_War_II">heavily bombed by the RAF</a> during WWII, destroying half the town&rsquo;s homes overnight. We were actually in town for the 80th anniversary memorial event, and all through Wednesday we heard the bells tolling across town.</li>
<li>The cafeteria food at TU Darmstadt is quite good. It felt a bit like Ikea standing in the cafeteria line and grabbing lunch, but there was solid variety. I will warn folks that when they translate something as dumplings, though, they mean American/Western-style dumplings — I was not expecting a dense dough ball.
<ul>
<li>The group I was with was very interested in having Asian food for our free meals, seeing as we had a German-cuisine dinner already scheduled. The <a href="https://www.moschmosch.com/">two</a> <a href="https://g.co/kgs/qaPbk23">places</a> we tried were great. It was very fun teaching them to use chopsticks and see them tank Szechuan peppercorns for the first time.</li>
<li>I feel obligated to also especially shout out <a href="https://g.co/kgs/3Fgcghn">this hole-in-the-wall Tibetan dumpling</a> takeaway place, which I tried on my last night. The staff offered me a free sample of mango lassi and were very sweet in explaining everything in English.</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Besides all the distributed systems and multicultural learning, I also met many lovely people (who are probably reading this post — I can still see my blog analytics getting a suspicious number of views from Belgium). It was great making some new friends, since I think I was one of the only people who wasn&rsquo;t with a contingent from their home university and perhaps the only North American. I did my share of cultural exchange too: other than being the de-facto Asian-culture expert, I also taught folks some Canadian and American slang<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> and explained how university works here.</p>
<p>I&rsquo;m very happy that I was able to attend and feel very fulfilled in the new fields I&rsquo;ve gotten a tour of during DARE. I&rsquo;m proud to say that this was the longest continuous period in my life where I felt like I fully grasped the difference between strict, sequential, and causal consistency, and I can still mostly reason about the details now. Being exposed to different areas of research that I had no real background in was a challenge — once the LaTeX started flowing in a talk, I admit things generally started going over my head — but was also great to be able to build an idea of the different subareas within distributed systems. DARE was a shortcut in getting to the frontier of research in a short week, and I&rsquo;m excited to be able to continue thinking about some of these problems in my current and upcoming research internships.</p>
<p>The other students who took this program for ECTS credits were required to do another two-week research project following DARE, building on one of these lectures. They&rsquo;ll be doing a presentation soon in a few weeks, and I&rsquo;m really looking forward to seeing what they&rsquo;ve come up with. I didn&rsquo;t have to do one since the transfer credits aren&rsquo;t going to meaningfully affect my courseload next year, but in a way my current internship work is one big extension of Professor Kleppmann&rsquo;s talk and work, so I&rsquo;ll say it counts.</p>
<p>I&rsquo;d very much recommend the program to anyone even tangentially interested in distributed systems. I believe the talks will be different year-to-year, and I&rsquo;ve heard the next iteration is planned in Porto, Portugal. There&rsquo;s funding available for European students via the Erasmus program and no fee for the program itself otherwise. Stay on the lookout for DARE 2025 — I&rsquo;d strongly encourage other students to go for it!</p>


<style>
ul {
margin-bottom: 0.5em;
}
</style>


<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I will never forget when we were standing in a circle with someone else from Portugal explaining Skibidi Toilet to the others and chatting about brainrot, when Professor Baquero joined the group and said something along the lines of, &ldquo;ah yes, &lsquo;brainrot&rsquo;, that must be what my daughter has&rdquo; and taking a look at a Skibidi Toilet episode. Oh, how I love the Internet.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Magic! at the Mall</title>
      <link>https://kewbi.sh/blog/posts/240825/</link>
      <pubDate>25 Aug 2024</pubDate>
      
      <description>On new phones and new paradigms.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I got my first phone sometime around 2018<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I got my second last month.</p>
<p>My first phone was a silver iPhone 7. I remember my friends with iPhones had iPhone SEs or 6s back then, and having a 7 was a subtle step up. I was the one who’d take photos because I had the “best” camera. I rarely used it when I got it — our school had a phone-free policy, so I’d have to dump my phone into this wicker basket of phones at the start of the day. I’d rescue it at the end of the day, then not really do anything with it after I got home. I didn’t even get a phone plan until I started high school, and til then I didn’t use my phone for much besides Google Hangouts and the occasional FaceTime.</p>
<p>There was one classmate who had an iPhone 8, and I recall thinking the X was so excessive. What were the new features, besides a slightly bigger screen and no home button? Big deal. Fast forward a few years, and I’d think people who got the then brand-new iPhone 13 were on the bleeding edge, perhaps a little extravagantly so.</p>
<p>But it’s 2024, and the dynamic island and USB-C charger and three cameras of the iPhone 15 are all the rage. I’d still stubbornly stuck to my iPhone 7. All of a sudden, I was the only friend with a home button. I’d stopped getting updates a few years ago, but I didn’t really miss any of the new features. My 7 served me well — besides, well, Uber Eats not working with anything under iOS 16 and FaceTime and Discord calls starting to stutter out. I still didn’t really feel a need to upgrade, and having an old phone felt almost like a point of pride for me at this point: I’d taken such good care of my phone that here it was, six years later, with no scratches, a two day battery life, and working like a charm.</p>
<p>Unfortunately, the day came last month: I’m headed to Cambridge (UK) for the fall, and I’ll need both my Canadian SIM, to receive SMS verification codes and such, and a local SIM for calling. My iPhone 7 doesn’t support an eSIM, so I won’t be able to dual-SIM. With a heavy heart, I made my way to my local Apple Store.</p>
<p>There, I got an iPhone 14 (doubling my model number!). While I was there, a lot of casual magic happened. I’d never bought a phone in person before, or really spent significant time in an Apple Store, so I was pleasantly surprised by some of the little touches I noticed. This was also my first time switching phones, so I got to experience the sheer wizardry that is Quick Start. And while I was booking my pickup slot, I also noticed Apple Vision Pro demos available, and I impulsively booked a demo. The AVP isn’t something that I’ve really thought about, besides seeing a few tweets and video thumbnails, or considered for actual use, but I found the demo fairly enchanting.</p>
<p>I think there are a few aspects that <em>make magic</em>.</p>
<ul>
<li>Magic inverts expectations while building on them. It makes the hard things unexpectedly easy and the impossible things possible, but it has to do so in an incredibly intuitive way. There shouldn’t be a &lsquo;why does this work?&rsquo; — there can only be an ‘of course’.</li>
<li>Magic is embedded and composable, not standalone and sandboxed. It’s adaptable to whatever you need in the moment, and comprehensive in covering everything you might think about.</li>
<li>Magic is predictive but forgiving. It figures out the word on the tip of your tongue and the recurring patterns that make up your day. When you get something wrong, it gently nudges you to ask if that’s what you really want.</li>
<li>Magic can disappear. With more magic comes more responsibility. The more magical an experience, the more tiny flaws can quickly break the suspension of disbelief.</li>
</ul>
<p>The Quick Start and AVP demo experiences both captured these traits — I think that afternoon in the Apple store was the highest density of casual magic I’ve experienced this summer. This is a post about those moments of magic at the mall and what makes a computing experience compelling. I’ve always been jokingly disdainful about Apple fans, but in those few hours in the store, I started to see what they’re so enthusiastic about.</p>
<h2 id="dont-quick-start-now">Don&rsquo;t (Quick) Start Now</h2>
<p>Picking up my phone was a very straightforward 5-minute errand. Unfortunately, when I got home and was admiring my edge-to-edge screen, I noticed the phone had a scratch. I wasn&rsquo;t about to spend that much money and take a defective phone, so I had to go back and exchange it<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. I didn&rsquo;t want to risk taking another trip again if there was another visual defect or some software problem, so I decided to do my setup in-store (and also because the only AVP demos were at the end of the day, so I had some time.)</p>
<p>I don&rsquo;t think I had to worry much about the migration though, since Quick Start was seamless. <a href="https://support.apple.com/en-ca/102659">Quick Start</a> is a way to wirelessly transfer all your apps, app data, messages, and preferences over to a new device. You can do Quick Start via an iCloud backup, or you can run one directly from the device. One really nice touch was that I didn&rsquo;t even have to log into or search for the Apple store WiFi, and even over the public WiFi, which I didn&rsquo;t expect to be very fast, the setup was done in less than five minutes. I don&rsquo;t have a lot of photos or data backed up on my phone, but nonetheless I was impressed. This speed underscores something about magic: it works fast. Magic doesn&rsquo;t need endless loading bars and doesn&rsquo;t get stuck downloading something.</p>
<p>There are plenty of small touches that transferred over: my texts and contacts were just as I&rsquo;d left them, I was already logged into most apps, my wallpaper and lock screen was identical, the years of settings I&rsquo;d carefully curated were in place, my pirated textbook PDFs were set up perfectly with Apple Books. My muscle memory for everything still worked, without any of the tedious setup and comparing things between either phone. It was like having an exact, scaled-up replica of my old phone.</p>
<p>I don&rsquo;t think I&rsquo;ve ever been so pleasantly surprised with a migration process. When I bought my phone, I was dreading the hours I&rsquo;d expected of downloading everything and setting up logins and preferences again. Taking all that away with such attention to detail was a very good investment on Apple’s part. I used to be distrustful of cloud syncs and signing into browser/device services<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, but they’re so helpful for applications where they’re (somewhat) strictly necessary. I think background processes like syncs and preprocessing do a lot of the heavy lifting for magic. I have no insight into how Apple’s photos systems works, for example, but I’d bet they’re creating their recap albums with an off-device queueing service and they’re running their people detection online when a new photo’s uploaded to iCloud Photos. This ties into my previous point about magic working to match your speed — because the processing happens before you’re looking to access something, it seems more magical when you go to look something up and it’s already there.</p>
<p>This background processing is also a lot easier when your endpoints are all centralized, because this provides consistency in how data is stored/read. This is how you can make your service feel omniscient and predictive, since you have all the data to figure out all the patterns. You can certainly engineer a way to connect more disparate data sources: I keep coming back to reference <a href="https://www.inkandswitch.com/cambria/">Cambria lenses</a>, and I was introduced to the <a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">Resource Description Framework</a> model in one of the first few chapters of <em>Designing Data-Intensive Applications</em>. I just finished the book, and one of the primary focuses of the last chapter is on data integration via derived state, batch processing, and federated/unbundled databases, which I expect would be the key components for bringing something like this to generic devices. To this end, Samsung’s Smart Switch seems to be able to bring iOS data to Android devices as well as from other Android devices to a Samsung, and I’d be interested in learning more about how it all works.</p>
<p>I think Quick Start’s adaptability and coverage were key to making it feel like magic. I wouldn’t have expected Apple Books, for example, to get ported over so seamlessly, though now that I think about it, it probably does back up to iCloud. Even apps outside of the Apple ecosystem, like Discord and FitBit had me already authenticated and all my app-specific settings were translated over. Magic works over everything – it’s not meant to let on that it’s forgotten something and can’t be even slightly inconsistent with the ecosystem’s ‘magic system’, and Quick Start does so expertly. Maybe this is all because I haven’t done iOS development before and this is all thanks to some slick data access API requirements, but I’m so awed by how flexible the setup feels.</p>
<p>I think two things that could be improved, perhaps, are the Apple Wallet transfers for credit cards (although I guess there&rsquo;s good regulatory and privacy reasons for this) as well as SIM-card / phone-number based apps like Whatsapp or Signal. But even off the top of my head, I can think of some technical limitations with each, so there&rsquo;s probably a reason they&rsquo;ve not been implemented.</p>
<h2 id="interlude-i-miss-my-home-button">Interlude: I Miss My Home Button</h2>
<p>With my new phone itself, there are a few key things I’ve noticed. The first is fairly obvious: the camera quality is certainly a step up (and in tandem, the quality of the screen to view the photos I take has definitely improved). I was recently at a work dinner with my fellow interns, and I took out my phone to take a quick photo for my parents. The second I opened the camera app, I blurted out that the camera quality was so much better than my old phone. Doubling my model number also seemed to double the warmth, depth of colour, and sharpness of even casual pics. When I was on a trip to the UK earlier this month, I took a few nighttime photos of the very classic architecture – lots of fine details and masonry. Despite the dim lighting, the photos were still able to capture things quite well with minimal grain. I’m very impressed with this camera, and I can’t imagine the further upgrades that the newest models are supposed to deliver.</p>
<p>Another thing I’ve appreciated is finally having good NFC support! I wrote another blog post about <a href="https://kewbi.sh/blog/posts/240811/">building a webring that interacts with a physical NFC ring</a>, something that wasn’t possible to test with my old phone. I’ve been a little obsessed with NFC tags and having little physical checkpoints that interact with my digital world (for example, <a href="https://x.com/spencerc99/status/1818721711858368890">this do-not-disturb phone pillow</a>, or its more consumer counterpart <a href="https://getbrick.app/">Brick</a>). I&rsquo;ve played around a little with NFC and the Shortcuts app, and I’m also happy with how much Shortcuts has levelled up since iOS 15.</p>
<p>Finally, I’ve realized how nice it is that apps and features are able to pick up on patterns of usage. One example is the wallet app – I was travelling abroad and was using a credit card that I don’t normally use. Within a few days, Apple Wallet knew to bring that card up as my default when I double-pressed the power button. This is a nice tidbit of magic — Apple Wallet was smart enough to pick up on my intents without explicit configuration, but it’s easy to override and pick a different card if I needed to.</p>
<p>There’s much more, like being able to customise my home screen more with different icons and widgets and fonts, but I’d like to move on to another major magic experience.</p>
<h2 id="14-pounds">1.4 Pounds</h2>
<p>I impulsively booked an AVP demo since I’d be there at the store anyways, having not really seriously thought about the device or read up about its features beyond the ‘first look’ demo that was all over my feed. When I got there, the first thing the Specialist said was that the AVP was not a VR headset: it was a spatial computer. I still don’t really buy the rebranding — it feels a tad pedantic — but I will say it’s unlike anything I’d ever tried before.</p>
<p>My headset experience is limited to a ten-minute stint playing Fruit Ninja on an Oculus Quest during a summer camp, so maybe that&rsquo;s why I was so intrigued. First off, I was not expecting to have my face scanned and a custom-fit headset delivered to the demo station. I think I have a fairly normal set of face shape/head size/vision requirements, so maybe it was all a bit of theatre to make the demo feel more personalised.</p>
<p>Tailoring the demo is the major thing I felt like was lacking. The experience starts with learning how to browse photos, view live photos immersively, and navigate around apps, culminating in a very well-shot immersive video. This really highlighted the gestures and new interactions that were possible with the AVP and certainly provided the most wow-factor. I wish I&rsquo;d have gotten more walkthroughs through more productivity and everyday work demos, though. The AVP was constantly touted as a portable way to make the world your workspace for anything, but we never got to actually see what doing work was like. Going through a spreadsheets program, editing a video, or doing some debugging might have made the demo more compelling for people looking for a more serious, professional use-case for the AVP. It would have been annoying to set up and pair a MacBook for every demo, but surely there&rsquo;s a way to streamline this (make more magic, y&rsquo;all!) It would have been extra amazing if the demo could pull from iCloud data – there must be something they can copy-paste from Quick Start. I would have loved to learn how to read my EPUBs from Apple Books or how to use Shortcuts with the AVP, especially any cross-device capabilities. If anything, the current demo sells the AVP as a (heavier), more immersive version of the VR headsets already available, focusing on entertainment and casual usage: exactly what Apple was trying to avoid.</p>
<p>Controlling the AVP was a bit like how I imagine Harry Potter et al. felt at Hogwarts — harnessing magic is tricky. The calibration helped serve as a tutorial to pick up the mouse mechanics, and I liked the slight gamification. Once you got used to having to look exactly where you wanted the cursor and do the pinch-clicking, the tutorial went by fast. Pointing with my eyes didn&rsquo;t feel very accurate at first, though, unless I really focused on a point, or if I shifted my focus, then looked back. Doing gestures without a button also felt a little unusual due to the lack of tactile feedback, but by the end of the demo I was well-adjusted. I was still relying on instructions for when to use the crown and for what, but I&rsquo;m sure with more time it&rsquo;d have gotten ingrained into muscle memory.</p>
<p>One of my favourite parts of the demo was that cinematic video I mentioned before — it tied together the best of the audio/video capabilities. There are a bunch of safari and immersive walk-with-the-animals-type clips, and I&rsquo;d swear that the elephants were right by me. There was a scene with a tightrope walker, and I felt my heart drop when they also fell off. There was also an NBA scene where the player throws the ball right at your face — I visibly flinched, and the Specialist said she uses it as a marker of how far people are into the video when they recoil.</p>
<p>I loved the depth of field of the AVP, and I think it really helped with the suspension of disbelief and the resulting magic. Had the videos felt flatter or the layers more compressed, it wouldn&rsquo;t have gotten the feeling just right. Because most of the demo was so flawlessly executed, I think it made it obvious when and highlighted when things didn&rsquo;t go quite so well (e.g. the visual pointing). That&rsquo;s another aspect of magic: if you&rsquo;re going to build an immersive and comprehensive experience, it&rsquo;s crucial you take care of the smallest details too.</p>
<h2 id="conclusion">Conclusion</h2>
<p>A few days ago, before I started writing this post, I was trying to check my phone when it froze. I’d opened the Clock app to set an alarm, but all I saw were a row of icons at the bottom with a grey screen. I locked my phone and swiped up to open it — it faded out the clock font but wouldn’t open the app. It was much too late to go out to the Apple Store, and I was dreading making the trek the next day. The illusion of magic? Gone<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p>But I’ll forgive Apple on this one, since the whole experience of getting the phone itself was enough magic for a good bit. Between Quick Start, old new features, and the Apple Vision Pro, I’ve both been able to be enchanted and think a little more about what made each so charming. All of the encounters captured some of the core aspects of magic: Quick Start flipped the script on tedious phone migrations and did so in an incredibly intuitive, embedded, and comprehensive way. My new phone made me appreciate the power of good predictions, and how those little touches can seem so obvious in hindsight. On the other hand, the Apple Vision Pro underscored the responsibility that comes with this power — its immersion felt magical, which especially underscored the handful of papercuts along the way.</p>
<p>Overall, I think what really makes or breaks magic is how well it fits into an existing worldview and how intuitive it is. I was comparing magic in software to classic fantasy book series like Harry Potter, which have very composable, expansive, and consistent magic systems. Tech is how we’ll make hard things easy and make the impossible possible, but we’ll have to do so carefully to really capture the magic. Radically different offerings, like the AVP, bring a lot of opportunities for moments for casual magic, but I can appreciate the challenges that must have come up in order to make it feel so spellbinding.</p>
<p>I thought I’d have hated getting a new phone, but I both appreciate the phone itself and the fascinating few hours I had at the Apple store because of it. I plan on holding on to this phone for a long time again. I went from an iPhone 7 to an iPhone 14, so the logical next step is to wait for the next multiple of seven. When I drop by to pick up my iPhone 21, I’ll see what demos, features, and crazy, magical moments are possible then.</p>
<hr>
<p>P.S. If you&rsquo;re looking for posters or art, you should check out the <a href="https://www.etsy.com/ca/listing/1762613124/6-minimalist-computer-patent-prints">Toronto Island Patent Press</a> on Etsy! A friend and I made a set of posters based on retro schematics and patents for classic computing companies, like IBM, Nortel, and DeskMaster. They&rsquo;re available as digital downloads in a wide variety of very aesthetic colourways — perfect for the sort of people who geek out over the first monitors and blueprint drawings.</p>
<figure><img src="/img/240825/promo-pic.png"
         alt="Figure 1. Example posters and colourways."/><figcaption>
            <p><em>Figure 1. Example posters and colourways.</em></p>
        </figcaption>
</figure>

<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>This is a lie – my parents had gotten me my own phone for my birthday the year before IIRC, but I told them to return it since I didn’t really need it for anything. I think you can draw many conclusions about my personality from this.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>This was also an ordeal in and of itself — if you ever get a friend to buy you a phone with a friends-and-family discount, try to avoid having to exchange it since you&rsquo;ll have to get them to refund, then re-buy the phone with the discount. A bit of a hassle if your friend isn&rsquo;t local and doesn’t come with you.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>When I got my first computer, I not only refused to use Chrome logged in, but I used Chrome only in an incognito window. No history, no way to keep my tabs between sessions. I’d only put my laptop into Sleep instead of ever shutting it down, and I’d try to put off Chrome updates as long as possible. Whenever I was forced to re-open Chrome, I made a trigger list of sites to have to log back into again, and I’d need to go through and login to each and every one of them. Like footnote 1, I think you can see how this fits into my personal lore.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>If you run into the same issue, press and release volume up, then volume down, then hold the power button til after the Apple logo comes up.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Webring²</title>
      <link>https://kewbi.sh/blog/posts/240811/</link>
      <pubDate>11 Aug 2024</pubDate>
      
      <description>On ring fingers and finger prints.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Earlier in April, I was preparing for <a href="https://kewbi.sh/blog/posts/240602/">my first conference talk</a>. Not quite knowing what to expect, I thought there&rsquo;d be plenty of networking and job opportunities and swag. I was right on only one of these counts (spoiler: it was the merch)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>But when I&rsquo;d just been accepted, I thought I&rsquo;d be hitting up recruiters left and right on the showcase floor. I printed ten paper copies of my resume, and if that wasn&rsquo;t enough, I also ordered a NFC ring to flash my personal website onto. This way, when people wanted to learn more, they&rsquo;d be able to tap their phone against the ring to bring up my site, and I wouldn&rsquo;t have to fumble around typing my LinkedIn URL or pulling crumpled paper resumes out. I thought it&rsquo;d be a memorable way to leave a first impression: look, this candidate not only knows about web and distributed systems, but is making their resume available to me in a way I&rsquo;ve never seen before! I chose a slick double-sided titanium ring off <a href="https://store.nfcring.com/products/signature?variant=602072773">nfcring.com</a> and giddily wrote my site URL onto both chips.</p>
<p>Suffice it to say that no one scanned my ring during the conference. However, I still had the ring, and I wasn&rsquo;t about to wear it every day in the deranged hope I&rsquo;d be able to organically sneak it into conversation one day. I wanted to make a little project out of the ring, and after some very Emilie-core wordplay brainstorming, I happened upon the idea of a webring ring. You&rsquo;d be able to scan it, just like when I flashed my site URL onto it, but it&rsquo;d lead to a <a href="https://en.wikipedia.org/wiki/Webring">webring</a> of me and my friends&rsquo; blogs, and you&rsquo;d be able to navigate between sites on the ring by scanning it multiple times.</p>
<p>It didn&rsquo;t take long at all to build — a weekend and a Cloudflare Pages deep dive later, my webring ring was ready. I&rsquo;m calling it Webring², because it&rsquo;s a <code>web(ring)(ring) = web(ring)²</code>. Here&rsquo;s a demo video:</p>


<div style="display: flex; justify-content: center; margin-bottom: 1em">
	<video src="https://github.com/user-attachments/assets/0d54fa1d-c8c1-447f-80c4-9fa6e20035cd" autoplay loop>
</div>


<p>The source is available <a href="https://github.com/kewbish/webringsquared">here</a>. In this blog post, I&rsquo;ll go through the three main components of the project: the webring site itself, the mechanism to open different pages each time you scanned it, and the physical NFC ring. Along the way, I&rsquo;ll cover the history of early web search engines, some niche behaviour of WebRTC, and odd body modifications.</p>
<h2 id="if-you-searched-it-then-you-shouldve-put-a-ring-on-it">If you searched it, then you should&rsquo;ve put a ring on it</h2>
<p><a href="https://en.wikipedia.org/wiki/Webring">Webrings</a> are a collection of sites that link to each other in a cycle. Each site has &rsquo;next&rsquo; and &lsquo;previous&rsquo; links, which are wired together so by the time you&rsquo;ve hit the last site, its &rsquo;next&rsquo; link takes you back to the first site, and vice versa. The links were usually included in a commonly styled footer that everyone in the ring included on their site, and sometimes there&rsquo;d be a central directory listing to make sure that if someone&rsquo;s website went down, the ring didn&rsquo;t turn into an abbreviated line instead. There was typically a &ldquo;ringmaster&rdquo; who&rsquo;d manage the ring structure, moderating new applications to join or detangling awry linking loops.</p>
<p>Before search engines like Google or DDG, the early web subsisted on web directories. You couldn&rsquo;t just search across the whole web: you needed to have an explicit entrypoint to some site. (Before DNS, people even had to share IP addresses, not domain names!) Web directories bridged this gap by providing a central catalog of sites, neatly categorized for your perusal. <a href="https://en.wikipedia.org/wiki/DMOZ">DMOZ</a> was one such web directory, owned by AOL but managed by volunteers. Yahoo! also started as a <a href="https://en.wikipedia.org/wiki/Yahoo!_Directory">hand-curated directory</a> before pivoting to a more modern crawler approach.</p>
<p>Webrings were sort of like a branching-off point and alternative to directories, like a human-curated &lsquo;Recommended videos&rsquo; at the bottom of each site. Once you&rsquo;d found a page via a directory, it&rsquo;d be very convenient to be able to find other similar sites without going through the directory again. It&rsquo;s natural, then, that webrings were also used to boost SEO rankings, especially for early search engines in the era of PageRank, since they provide a guaranteed few links to/from relevant content. <a href="https://en.wikipedia.org/wiki/Backlink">Backlinks</a> were crucial then, because more backlinks from quality sites would boost your search result rankings. In some ways, webrings were a less-commercialized version of the linkfarms and SEO drivel that&rsquo;s pervasive on the front page of the web today.</p>
<p>Nowadays, it seems that webrings are seen as a cute nod to the web of the past. The major webring providers have shut down, and search engines have replaced much of the discovery functionality of webrings. The primary webring site, WebRing.com, was summarily end-of-lifed by Yahoo! fairly early on, in 2001, but other providers stuck around til through the 2010s. There are still modern webrings running, like <a href="https://webring.xxiivv.com/">this one by Devine Lu Linvega</a>, and every so often, <a href="https://news.ycombinator.com/item?id=38268706">a post</a> <a href="https://news.ycombinator.com/item?id=38177128">comes up</a> on Hacker News lamenting their relative demise. While poking through Hacker News, I also found this site <a href="https://webri.ng/">webri.ng</a> that lets you manage webrings by generating you the footer HTML to insert (bonus for a cool domain!). I&rsquo;m sure there are plenty of webrings still running, particularly personal ones like the one I started, hosted by a group of friends or colleagues. In my head, they&rsquo;re in the same semantic space as the cozy web, as little relics of delight that you might stumble upon from a quirky site.</p>
<p>Speaking of my webring, let&rsquo;s look into its HTML structure. The NFC ring has a URL record written on it, so when you scan it, all it does is open a website. I&rsquo;ll discuss why we have to use a single website in the next section, but for now, let&rsquo;s take a look at the site itself. The ring links to <a href="https://webring.kewbi.sh">webring.kewbi.sh</a>, which is a static Cloudflare pages site. It displays a single <code>&lt;iframe&gt;</code> with the current webring page, and the footer links navigate to the previous and next sites in the ring. The source is <a href="https://github.com/kewbish/webringsquared/blob/master/src/index.html">here</a> — the markup is very simple, simple enough to have been mostly generated by ChatGPT.</p>
<p>One of the more unique bits about this webring is its architecture. Webring² is a centralized display, linking to sites that are separately controlled by each of my friends. Using an <code>&lt;iframe&gt;</code> to dynamically link to their content and keeping a central navigation header retains the core experience of exploring a webring, but guarantees no broken links or downtime. Even if one of my friends&rsquo; pages goes down, their site won&rsquo;t load, but the navigation will still allow you to go to the next and previous sites. This lessens maintenance burden, since I won&rsquo;t have to run around asking the owners of the pages that link to the broken site to change their links. This also makes it easier to join and leave webrings: all the links are managed centrally on my link service, so I can localize changes just to that configuration file instead of requiring multiple people to update their links. Because this site is just a static HTML file, it&rsquo;s easy to rehost on another provider, providing additional future-proofing.</p>
<p>I claim no originality, since I was neither alive nor on the Internet for the webring heyday, but I don&rsquo;t think I&rsquo;ve seen this structure in any of the other (modern) webrings I&rsquo;ve found. I don&rsquo;t see any reason why this architecture couldn&rsquo;t have been supported by the early Web — Netscape added support for <code>&lt;frame&gt;</code>s, a predecessor to <code>&lt;iframe&gt;</code>s, <a href="https://en.wikipedia.org/wiki/Frame_(World_Wide_Web)#History">in 1996</a>, and sites were being hosted by servers already anyways. To be honest, I haven&rsquo;t dug into the history of WebRing.com or any of the other webring providers, so maybe that&rsquo;s indeed how they worked.</p>
<h2 id="web-whorls">Web Whorls</h2>
<p>The static Webring² website has links to navigate between sites in the ring, but I also wanted to build out an interaction where scanning the ring multiple times would automatically advance the user&rsquo;s &lsquo;position&rsquo; in the webring. The obvious way to do this is to somehow change the URL stored on the ring each time it was scanned, but there&rsquo;s no way to make a self-modifying record as far as I know. You could try making some standalone app to force the user to both read/write to the ring, but I wanted my site to work on the web, as was originally intended! This is also why I had to use the one-centralized-site architecture, since otherwise I wouldn&rsquo;t be able to change the view to the selected website.</p>
<p>If you go through <a href="https://github.com/kewbish/webringsquared/blob/master/src/index.html">the HTML</a> and <a href="https://github.com/kewbish/webringsquared/blob/master/functions/progress/%5Bipkey%5D.js">the Pages Function</a>, you&rsquo;ll see that the app is quite simple.</p>
<ul>
<li>In the HTML, we fetch from the <code>api.ipify.org</code> API to get the user&rsquo;s public IP, then pass this as an identifier <code>ipkey</code> to the Pages Function.</li>
<li>The Pages Function maps the IP address to the current position in the webring and returns the current URL alongside the current index and the list of URLs.</li>
<li>The frontend then displays the current URL in the <code>&lt;iframe&gt;</code>.</li>
<li>When the user clicks the &lsquo;previous&rsquo; or &rsquo;next&rsquo; links, the frontend makes a request to the Pages Function to set the current user&rsquo;s index.</li>
<li>This way, the next time the user taps the ring, the index will increment again in the Pages Function, and they&rsquo;ll be sent to the next site.</li>
</ul>
<p>This is well and good if you have a dedicated IP address, but nowadays your public IP will be shared by multiple devices on your network, or even at a higher level, by other households on your ISP. At this point, the site only maps an IP to a position, so if I scanned my ring and clicked &rsquo;next&rsquo; a few times, my parents on the same network would see my state instead of starting from the beginning. This isn&rsquo;t the end of the world — it&rsquo;s the whole reason that webrings are a cycle in the first place. However, I wanted to drill down more, so ideally each device would be able to have its own position in the webring. I came up with three potential approaches and prototyped one of them out. The other two were very interesting reading, but I decided they were a bit too invasive to implement, especially for a page of this scale (read: no real users).</p>
<p>The first idea I had was to find a way to figure out the user&rsquo;s local IP. This is the address that&rsquo;s used intra-network, and would uniquely identify the device among the others sharing the public IP. The WebRTC API seemed to promise a solution and path forward. The WebRTC API is used for real-time communication: video and voice in particular. It enables screensharing, streaming, and sending messages between peers. WebRTC needs to know the local IPs of devices in order to negotiate connection information between them. You can see this in action on <a href="https://net.ipcalf.com">net.ipcalf.com</a>, which will display a <code>.local</code> address, or by running JS similar to this Gist:</p>


<script src="https://gist.github.com/antyakushev/a5d153654e02036d81cb9aec21125bdf.js"></script>


<p>The address we get back is a <code>.local</code> address, not in typical IP octet format. That in itself is fine, since I only need some unique identifier for the device, and I don&rsquo;t care about what that ID looks like. You&rsquo;ll notice that if you refresh your tab, though, the <code>.local</code> address will change. This <code>.local</code> address is a <a href="https://en.wikipedia.org/wiki/Multicast_DNS">mDNS</a> protocol address — mDNS is like DNS but for small networks where you don&rsquo;t need a hierarchy of nameservers and can just address peers directly. It&rsquo;s a bit like <a href="https://en.wikipedia.org/wiki/Address_Resolution_Protocol">ARP</a>:</p>
<ul>
<li>The requesting device will multicast a request for the local IP address linked to the <code>.local</code> address.</li>
<li>The device matching the <code>.local</code> address will multicast back its local IP address as its response.</li>
<li>All devices except the one that matches the address don&rsquo;t respond to the request, but can read the response and cache it for future reference.</li>
</ul>
<p>At this point, you might realize that being able to access local IP addresses from anywhere on the Internet, just via a simple API call, feels a little iffy privacy-wise. That&rsquo;s why the WebRTC API uses mDNS instead. The browser will dynamically generate a <code>.local</code> address for you each time you create a connection and resolve it for you behind the scenes. This way, your local IP is never leaked into the Internet, but unfortunately that means your local mDNS address can never be used for identifying your device for webring purposes either. Notwithstanding the fact that the <code>.local</code> address kept changing on refresh, I think the API also threw errors on mobile Safari, though I can&rsquo;t be sure since I can&rsquo;t see the console logs. This WebRTC connection code is still <a href="https://github.com/kewbish/webringsquared/blob/96a5b2440f4fae69433ea84b2f8a342f0c1e49b3/src/index.html#L178">left in the HTML source</a>, but it&rsquo;s commented out.</p>
<p>At this point, I realized I should probably stop fighting the privacy protections that people smarter than me had come up with, but I couldn&rsquo;t help myself from looking into a couple of other ways to identify users. After trying out the WebRTC API, I realized I could quite trivially generate a UUID and store it into the browser&rsquo;s <code>localStorage</code> or as a cookie, and reference that as an identifier. (I&rsquo;ll get around to adding this one day, but it&rsquo;s not up on the webring site now quite yet.) While looking into cookies, I came across the concept of <a href="https://en.wikipedia.org/wiki/Evercookie">Evercookies</a>, which were self-reconstructing cookies that couldn&rsquo;t be deleted. Instead of just storing data into a cookie, <code>localStorage</code>, or the IndexedDB, Evercookies hide themselves into weird, niche storage mechanisms like <a href="https://en.wikipedia.org/wiki/Evercookie#Description">reading cookies from the RGB values of force-cached images</a>. Usually, the typical &lsquo;clear cookies&rsquo; option on major browsers just wipes the cookies themselves. If any other pieces of the cookies are left, however, like a piece left in a Flash Shared Object, the JS is smart enough to reconstruct and restore all the cookies back where they came from. <a href="https://github.com/samyk/evercookie">Here&rsquo;s the source of the Evercookie API</a> — it&rsquo;s really something, and the list of places where you can sneakily store data is worth a read through. Though it doesn&rsquo;t have anything to do with this project per se, <a href="https://samy.pl/csshack/csshack.js">CSS history knocking</a> stood out to me in particular as an interesting way to exfiltrate visited status. It&rsquo;s a little scary being aware of all the ways that you can get around the basic browser controls to remove your history or web footprint, and that it seems so clean and simple to do.</p>
<p>Perhaps even scarier are the possibilities laid out by <a href="https://en.wikipedia.org/wiki/Device_fingerprint">browser fingerprinting</a>. JS libraries can combine your user agent, screen resolution, timezone information, plugins, fonts, and more to create a mostly unique identifier for you. <a href="https://github.com/fingerprintjs/fingerprintjs">FingerprintJS</a> claims 40-60% accuracy, which is already impressive, but their <a href="https://fingerprint.com/">closed-source version</a> claims 99.5%. <a href="https://codepen.io/vsbeats/pen/RjMQex">See a demo here</a> for the open-source version of FingerprintJS to get a sense of just how much identifying information you&rsquo;re transmitting with every request. Or, check out the closed-source version&rsquo;s site — I opened the site in a regular Chrome window, then in an incognito window, then after restarting Chrome, and all three times it got my identifier right.</p>
<p>I was super surprised that even with the user agent, screen resolution, and other parameters that the more limited open-source version tracks, it&rsquo;s able to pinpoint users so precisely. I&rsquo;d have expected that there&rsquo;d be billions of users on the internet, millions within my country and using my same ISP, and probably in the thousands using the same browser at the same standard laptop resolution. Even taking browsing time into account, I&rsquo;d have expected maybe at least ten other folks matching my browser version and parameters to be on the Web at any given time, but it&rsquo;s been so far quite impressive. Again, sorting out proper cookies or browser fingerprinting felt like too big of a lift for my weekend project, so I didn&rsquo;t really consider adding the library. Certainly fun (and spooky) to play around with, though.</p>
<h2 id="the-right-hand-rule">The Right-Hand Rule</h2>
<p>We&rsquo;ve gone through the webring site itself and how I navigate between pages on the webring — all the software components that make the site fully usable in a browser. This brings us, finally, to the physical ring itself. My ring is the cheapest model off <a href="https://store.nfcring.com/products/signature?variant=602072773">nfcring.com</a><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. I was worried the company wasn&rsquo;t even in business, since their forum was inactive and their stock fairly low, but a quick email assuaged my concerns. I wasn&rsquo;t too fussy about the <a href="https://cdn.shopify.com/s/files/1/0259/9785/t/17/assets/NFC_Ring_Datasheet_Signature.pdf">datasheet</a>, since I didn&rsquo;t have particular requirements on the NFC chip, as long as it could hold a tiny URL.</p>
<p>NFC tags are pretty easy to read and write — just download a writer/reader app on your phone and you&rsquo;re set. To write Webring²&rsquo;s URL to the ring, I used the <a href="https://apps.apple.com/us/app/nfc-tools/id1252962749">NFC Tools</a> app. For most record types, you don&rsquo;t even have to download a reader if you have a recent smartphone, so you can just wave your phone near a tag to automatically open the contact or whatever data&rsquo;s stored on it. You can see in the demo video above that I can just tap my phone on the ring to scan it without opening any particular app. I was at a cybersecurity competition recently, hosted in an official government building, and several participants had a lot of fun surreptitiously writing their own data to the NFC-enabled visitor lanyards we were required to wear (This is your warning to not do this.) Some folks also brought their <a href="https://flipperzero.one/">Flipper Zeros</a>, which is a standalone device that can, among many other things, scan and emulate NFC cards, so there might have been some shenanigans with cloning hotel room cards. (Again, don&rsquo;t do this.)</p>
<p>To understand how NFC tags work, you&rsquo;ll need to take a throwback to high school physics, and the electromagnetism unit in particular. The high-level overview goes like this:</p>
<ul>
<li>NFC tags themselves, like the one in my ring, doesn&rsquo;t have a power source of its own. These are called passive NFC devices.</li>
<li>Your active NFC device, like your reader, has some power source. This power source can generate an electromagnetic field when you pass the current (electricity) through a coil.</li>
<li>Remember the right-hand rule from physics class? It turns out that if you put a coil into a magnetic field, you also get current back out. If you look closely at the NFC ring, you&rsquo;ll see a little coil of wire, which now can get some current running through it.</li>
<li>A capacitor is like a mini-battery: it charges up and can release all the power in a short burst.</li>
<li>This provides enough power for the NFC tag&rsquo;s microprocessor to create its own magnetic fields, which the phone can then read. It&rsquo;s like the NFC tag is wirelessly tapping power from your phone in order to transmit its own information. The official term for this is &lsquo;magnetic induction&rsquo;. Transferring power this way isn&rsquo;t very efficient, however, so it has to be done at very close intervals.</li>
<li>Data is stored on NFC tags in raw bytes, which can be formed into one of several record types <a href="https://gototags.com/nfc/ndef/record-types#nfc-forum">defined by the NFC forum</a>. These include records like URLs, contact information, WiFi passwords, or application-specific NDEF records.</li>
</ul>
<p>NFC tags typically differ in terms of their capacity and speed, and are categorized into one of <a href="https://nfc-forum.org/build/specifications">five types</a>. Type 1 tags are older and slower, and the tags generally go up in performance as their type number increases. The tag on my ring is the <code>NTAG203</code> type, which <a href="https://ubitap.com/ntag203">falls under Type 2</a>. It has 144 bytes of space, which is limited but more than enough for my single URL. I don&rsquo;t notice any speed issues, but I&rsquo;ll note that it can sometimes be difficult to scan the ring. I think the problems are due to the curved surface of the ring, but in the spirit of PEBKAC, are just as likely to be because I don&rsquo;t quite know where the NFC antenna is on my phone. I&rsquo;ve tried scanning the ring with a thinner plastic case, which works, but it wouldn&rsquo;t scan through some of my friends&rsquo; thicker cases (e.g. Otter) or wallet cases. Again, not sure if the problem is on me or the ring.</p>
<p>I was surprised by how long ago NFC tags existed, even on smartphones. By 2010, Nokia released the <a href="https://en.wikipedia.org/wiki/Near-field_communication#History">first NFC-enabled smartphone</a>, and it&rsquo;d already been used in public transportation networks in 2009. Today, I think the most prevalent use-case for NFC that most people have interacted with is wireless payments and digital wallets like Apple Pay, as well as transit cards and other tap-based ecosystems. NFC stickers are fairly cheap now too: I found some to bulk order on AliExpress from $0.03 a piece.</p>
<p>Here&rsquo;s an interesting aside: NFC chip hand implants have been around since at least 2015. It&rsquo;s the same underlying technology as a ring, but you don&rsquo;t have to remember to bring it with you anywhere anymore. <a href="https://www.jhsgo.org/article/S2589-5141(24)00057-4/fulltext">This paper</a> estimates that 50K to 100K people have some sort of chip in their hand, so if you maybe cut that number in half for NFC implants in particular, that&rsquo;s still a sizeable 25K. <a href="https://www.npr.org/2018/10/22/658808705/thousands-of-swedes-are-inserting-microchips-under-their-skin">A 2018 NPR post</a> says it&rsquo;ll run you about $180, but if you&rsquo;re a DIY hacker (which I&rsquo;d expect most people who&rsquo;d think about injecting a chip into their hand would be), you can <a href="https://dangerousthings.com/product/xnt/">buy a kit to insert it yourself</a> for as little as $69. When I was younger, I briefly considered getting an implant, just because it was <em>weird</em> and it&rsquo;d have been a hell of a fun fact, but I also don&rsquo;t have much of a use for it. Giving someone a high five to pass on your LinkedIn is cool, but a little too extreme for a one-day Linux conference.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Every time I build a small side project over a weekend, I find myself learning much more than I&rsquo;d have imagined. I try to prototype out unique ideas that I haven&rsquo;t seen done before, or at least ones that combine fields that I know of, but not fully understand. Building Webring² and <a href="https://kewbi.sh/blog/posts/240721/">my HTML Day 2024</a> have inspired me to humour myself more and keep occasionally hacking on ideas that catch my fancy. The self-contained, timeboxed nature of these projects makes them more approachable than returning to my long-running projects, so maybe this is all just productive procrastination.</p>
<p>This has been the story of how I built one Webring², but I&rsquo;ve been toying around with the idea of buying up a bunch of NFC rings for my friends so we can have a Webring² ring — a Webring³, if you will. We could use a system slightly different than the current one, where each ring statically links to its own &lsquo;starting position&rsquo; (the URL of the friend that has the ring) but can navigate to any of the other sites. On the other hand, we could use the current implementation, where we dynamically fetch the starting URL on scan and have all the rings use the same position in the webring, but I think this&rsquo;d be a bit less personalized for each person with a ring.</p>
<p>There&rsquo;s probably more untapped potential in doing fun (or cursed) things with the NFC ring — I haven&rsquo;t looked too far into the technical details, but I&rsquo;d reckon there&rsquo;s some hacky stuff I could do. Even though the ring is a passive tag, <a href="https://www.reddit.com/r/homeassistant/comments/113acfr/what_do_you_use_nfc_tags_for/?rdt=33530">there are some very unique ideas for automations</a> I could rip off. If you&rsquo;ve been thinking of getting into home automation, or just playing around with NFC in particular, go <a href="https://github.com/kewbish/webringsquared">take a look at the repo</a> and set up your own. I&rsquo;m looking forward to seeing more webrings (or Webring²s) in the future!</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>To be fair, the other two were certainly available, but with my limited time there I didn&rsquo;t have much luck. Everyone simply redirected me to their online job board and I was busy during the preplanned mixers.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>It was one of the only manufacturers at this price point that had ring sizes small enough for my finger. I found several cheaper alternatives on Etsy and Amazon, but their ring sizes started at 10. For reference, that&rsquo;d probably be several millimeters too loose, even on my thumb. Small detail, but made me think about the target demographic and demand served a bit.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Compile Your Life</title>
      <link>https://kewbi.sh/blog/posts/240728/</link>
      <pubDate>28 Jul 2024</pubDate>
      
      <description>On front-loading forethought.</description>
      <content:encoded><![CDATA[<p>When I was <a href="https://blog.cloudflare.com/introducing-the-2023-intern-ets">interning at Cloudflare</a>, my manager taught me about the concept of a &ldquo;WIP cloud&rdquo; and drilled it into the team. A WIP cloud is all the dangling PRs, unfinished work, loose threads that you have in flight at once, and it&rsquo;s dangerous if you let it grow. A WIP cloud starts out fairly easy to manage: you&rsquo;re wrapping up a PR or have just put something up for review, and now find yourself blocked on others with some spare time on your hands. Being an eager engineer, you look for something else to work on, or perhaps start iterating on the next PR <a href="https://kewbi.sh/blog/posts/230611/">in your stack</a>. Then, you wrap that up — maybe your original PR is still waiting for review — and poke around for some other paper cut to solve. Over time, you amass more and more stuff to just keep on your radar for later.</p>
<p>And then all your PRs get returned at the same time, or all your JIRAs switch from &lsquo;Waiting for response&rsquo; to &lsquo;Awaiting team response&rsquo;. The WIP cloud grows too heavy and starts to pour. You&rsquo;re suddenly swamped. Now all of those little odds and ends that were easy to keep track of require attention all at once, and while already under pressure, you need to figure out how to prioritize and action on them.</p>
<p>I find myself feeling overwhelmed when I have a WIP cloud brewing, particularly during busy weeks at school or when I have soft deadlines approaching at work. The commonly-cited <a href="https://lawsofux.com/millers-law/">Miller&rsquo;s Law</a> states that we can only keep seven items in working memory. After that, we need to rely on context clues to recall things — it&rsquo;s like paging from disk when the values can&rsquo;t be found in the cache. When I hit those WIP cloud limits and memory cache misses, I can tell I don&rsquo;t do very well figuring out what to tackle on the fly.</p>
<p>I&rsquo;m the type of person that says yes to too much and expects a lot of herself, so in some respects I&rsquo;ve come to anticipate the WIP cloud before the storm. I try to keep WIP in mind when I go about my work, but avoiding it isn&rsquo;t the most important. It&rsquo;s what I do to process the WIP, plan it out, and reduce mental load of having to swap things in and out of my working bubble that matters to me.</p>
<p>I&rsquo;ve found something that works well for me: a cycle of collection, curation, and execution that I do ahead of time so I can focus in the moment when the WIP storm&rsquo;s passing by. The metaphor I use for it is <em>compilation</em> — just like compilers, put in some work before the action so you can optimize and take away some computational load while running.</p>
<p>For example, something many &ldquo;how to become a morning person&rdquo; articles mention is laying your clothes out the night before, so you don&rsquo;t have to think about it in the morning, when you&rsquo;re groggier and vulnerable to taking any excuse to stay in bed. This lets you take advantage of your current, more aware, state, and gives you more time to spot imperfections with your outfit (it&rsquo;s a very me thing to do, but maybe it&rsquo;s not a good idea to wear dress pants for a picnic after all).</p>
<p>Compiling your life introduces a split between a more deliberate preparation phase and an execution phase that&rsquo;s ideally as frictionless as possible. This is adjacent to the divide between <a href="https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking">System 1 and 2 thinking</a> popularized by Daniel Kahneman&rsquo;s <em>Thinking, Fast and Slow</em>. System 1 is a faster, snap-judgement mode of thinking, whereas System 2 is slower and requires more mental calculation. We don&rsquo;t want the execution of our work to be done in System 1, per se — it&rsquo;s still important work and we need to be deeply focused for it too. But we want to remove all barriers to starting that work, so we don&rsquo;t want to be forced to plan what work we&rsquo;ll do as we&rsquo;re doing it to mitigate procrastination and bikeshedding. We want to be able to access what we&rsquo;ll do in System 1 mode, so we can spend our System 2 energy on building, creating, and achieving.</p>
<p>If you&rsquo;re like me, I think you should compile your life too; at least, the times of high pressure and stakes. Make use of more self aware states to make sure even your future unmotivated, frazzled self knows what to turn to. Taking time to do all the logistics, prioritization, and prework first makes the actual work much easier. I&rsquo;ve used these strategies to make it through six finals seasons and three internships so far. While I think it&rsquo;s a bad idea to minutely preplan downtime like this, I&rsquo;ve found it easier to decompress and step away from my responsibilities if I know I can rely on having precompiled what I need to do when I do return.</p>
<p>This post will walk you through how I compile parts of my life, spin off into some loosely adjacent metaphors on compilation, and give you a better sense of how I&rsquo;ve applied my strategies from hell weeks to hijack my habits.</p>
<h2 id="get-in-loser-were-going-planning">Get in Loser, We&rsquo;re Going Planning</h2>
<p>The first pass of compilation is planning — collecting and curating whatever you&rsquo;ll be working on. I first started doing my planning in batches in advance when it came to my first finals season. It&rsquo;s too easy to realize it&rsquo;s the last week of class and your first finals are in a few days. When you&rsquo;re in that high-stress mindset and feeling like you have too many chapters to review and practice problems to work through, the last thing you want to do is spend more valuable time figuring out what to study when. But that&rsquo;s exactly what I think led to my success in my first few years: I made sure to carve out just an hour or so to figure out a game plan, try my best to cover everything optimally, then forget about editing it and start to focus.</p>
<ul>
<li>I make a Google Tasks list each time I have a lot of work to organize. Google Tasks is rather slow and frustrating, but it&rsquo;s easy to drag around tasks on the calendar, which makes reorganizing work quickly easier.</li>
<li>I go through and dump out all the chapters, exercises, review sessions, flashcards, or other things I need to do. This is the collection part of planning. See below for how I do this for each class.</li>
<li>I go in order of the closest exam or whatever I&rsquo;m most worried about, and space out each task to load balance across the time I have left.</li>
<li>I go to the next group of tasks, and repeat the same spreading out of work.</li>
<li>I go over everything and make sure no one day is too heavy. I also edit in some buffer time at this point if I have free days, and a few smaller time blocks to reassess how things are going and adjust my plan if need be.</li>
<li>I now have a plan of everything I need to do on that day. I&rsquo;ll sometimes copy over tasks into <a href="https://calcurse.org/">Calcurse</a> so I can time block and plan on the per-day level.</li>
<li>Then, when I have a study session or wake up for the day, I just reference my list and get to work. I don&rsquo;t doom about having so much to do, and I trust in my past self to have allocated time properly.</li>
<li>Sometimes, things come up, and I need to reorder work or add more. I block out more explicit planning time, drag things around, then go back into execution mode where I don&rsquo;t think about the what, just the how.</li>
</ul>
<p>The way I dump out my tasks is also somewhat meta-compiled. I have this template for each course of what I need to reference for each chapter or unit. It might be something like the exercises in the workbook, the review questions at the end of each chapter, and listening and speaking exercises from Canvas, for my French class, and the slides, the PrairieLearn questions, the textbook exercises, the clickers, and my flashcards, for my operating systems class. Then, for each unit, I might have specific areas I want to focus on, so I&rsquo;ll allocate more time and exercises from those sections. This is a little like <a href="https://rustc-dev-guide.rust-lang.org/backend/monomorph.html">monomorphization</a>, a Rust compiler construct for creating explicit instances of generic functions for each type that they&rsquo;re called with. Here, I&rsquo;m creating explicit tasks from the coursework templates for each of the units I have to work through<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>I also take time to prioritize during this organization phase: the curation part of planning. Part of making it through the WIP cloud is knowing that to cut or delay (delegation isn&rsquo;t usually an option for students). When things are laid out across my week in Google Calendar, I can start to see when certain days are too heavy, and if I can&rsquo;t move things around, I&rsquo;ll need to decide what&rsquo;s most important to focus on. A key part of this strategy, though, is making these decisions once while planning, and perhaps scheduling in explicit touchpoints throughout the few weeks that I&rsquo;m planning ahead. I try not to touch the prioritization outside of this time so I have one less thing that I can do to procrastinate, but more on this later.</p>
<p>During finals week, I can barely find the motivation to drag myself from bed most mornings (especially during the Fall term when I have to wake up in the gloom and dark), so taking the time to plan in advance is helpful so I can start my day right away and know I can make progress.</p>
<h2 id="from-clothes-to-chrome-tabs">From Clothes to Chrome Tabs</h2>
<p>The next pass of compilation is what I call the precomputation phase — substituting constants and doing basic computation ahead of time. There are certain algorithm problems where it&rsquo;s more efficient to batch compute all the results at initialization, cache it somewhere, then access those results at runtime. That&rsquo;s exactly what this preparation stage is useful for in real life as well.</p>
<p>We&rsquo;ve all heard trite advice somewhere to lay your clothes out the night before to become a morning person. When you&rsquo;re tired and grouchy, having already made your decision to lay out your workout clothes and your work fit makes it easier to just get up in the morning and go. That&rsquo;s the same principle precomputation exploits.</p>
<p>You might have heard of the concept of a &ldquo;trigger list&rdquo;, an idea first developed in <a href="https://gettingthingsdone.com/wp-content/uploads/2022/06/GTD_Incompletion_Trigger_List.pdf">&ldquo;Getting Things Done&rdquo;</a>, or a list of all the things you might need to remember or think about on a recurring basis. For example, it might look something like:</p>
<pre tabindex="0"><code>- meals:
	- planning
	- restaurants for eating out
- outfits
- chores:
	- laundry
- cleaning:
	- bathroom
</code></pre><p>This precomputation phase takes this idea one step further. Run through the list of triggers you have based on the plan you have, and set up your environment so that you&rsquo;ve done as much of The Thing as possible without actually doing it. For example, after deciding on your workout fit, fill your water bottle, roll out your yoga mat, and set out your equipment. Pull up the video you&rsquo;re planning to follow, pair your headphones, and queue your favourite playlist. By putting in all this prep, you&rsquo;re priming yourself to get up the next morning and just do the thing. Besides, it&rsquo;ll be easier than putting everything back away again.</p>
<p>One of my first Python projects was a script that&rsquo;d open up all the tabs I&rsquo;d want to check through each morning for notifications, including my email, social media, and messages. I haven&rsquo;t applied quite the same level of janky automation to my studying, but I follow a similar routine. I wrap up each day by going through my todo list for the next session and opening up the textbooks, practice problems, exams, and study tools that I&rsquo;ll need. When I open my laptop the next morning, I&rsquo;m greeted not by a blinking screen inviting me to tab over and scroll through Hacker News for an hour, but by what I need to get done.</p>
<p>For work and personal projects, I do the same — at 5PM, or whenever I&rsquo;m done for the day with my side project, I take a few minutes to figure out what I&rsquo;ll get done the next day, then open or bookmark the tabs I&rsquo;ll need to get started. For work, this tends to be opening up my PRs on GitHub so I can refresh and check their statuses the next morning, or the service deploy page so I can remember to hit the button and kick off some tests. For personal projects, I open up my design files for reference or docs pages for the libraries I&rsquo;ll be using for my next steps.</p>
<p>This principle is inspired by the <a href="https://en.wikipedia.org/wiki/Mise_en_place"><em>mise en place</em></a> cooking technique, so it&rsquo;s fitting that I also apply it to my meal prep. I don&rsquo;t follow recipes usually, so I write up my own list of prep steps and from there, set out all my ingredients and cookware and utensils. The weirdest example of this is probably what I do to set up for breakfast: the night before, I&rsquo;ll get all my cookware (pan, bowl, etc.) in place so the next morning, I can just turn on the stove and start cooking<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. This <em>mise</em> step is a textbook example of precomputation: doing the little things to get your station and environment set up so the actual cooking is much easier, and you&rsquo;re not scrambling around in your cupboards looking for a whisk while your sauce is scalding.</p>
<p>Collecting as much of the paraphernalia related to your work as possible ahead of time helps you avoid distractions. This is most obvious when it&rsquo;s applied to studying and work, but even in the kitchen or when I&rsquo;m doing chores, I find that not only knowing what I have to do, but also that I have everything in the right places to get it done, helps with removing all my mental blocks to getting in the flow.</p>
<h2 id="jit-compiling-and-spontaneity">JIT Compiling and Spontaneity</h2>
<p>You might think that this all sounds very rigorous and rigid, and it&rsquo;s supposed to be. Compiling your life is most effective for heads-down periods of life. There are times (e.g. finals week) where I don&rsquo;t want to think too hard about what I need to do and just execute. I do build in some escape hatches though: above, I&rsquo;ve mentioned allowing for checkpoints to rejig my schedule, say, in the middle of the week, if need be.</p>
<p>I also give myself the option to &ldquo;panic&rdquo; out and restructure at any time. However, I try to ensure that this decision is intentionally done — like an explicit context switch from my &ldquo;doing&rdquo; phase to &ldquo;planning&rdquo;. Forcing myself to only do so deliberately avoids situations where I don&rsquo;t want to actually work, so I make myself feel productive by reorganizing my time blocks, or revenge plan after feeling bad for not getting work done. It&rsquo;s also worth just recognizing what mode you&rsquo;re operating in at any time to be more cognizant if you find yourself flipping between modes often in order to better plan around that. <a href="https://linear.app/blog/planning-for-unplanned-work">This Linear blog post</a>, which inspired this post, also has some advice on planning for unplanned work. It&rsquo;s focused more on product work, but I think its ideas translate fairly well to areas of personal life.</p>
<p>There are plenty of times when I&rsquo;m less under pressure and I don&rsquo;t need so much of a drill-sergeant approach — in fact, I&rsquo;d say that most of the time putting so much effort into planning isn&rsquo;t fruitful for me. Planning and precomputation are useful when you have very clear goals for a shorter time horizon, when it&rsquo;s worth sticking to your metaphorical initially-thought-out guns. On the other hand, they&rsquo;re also premature optimization for lots of other situations. Your mileage may vary, and you&rsquo;ll have to define for yourself what sorts of times you need these tools and how far you&rsquo;ll take them.</p>
<p>For more daily-level plans, I try to use JIT compiling: I figure out what I&rsquo;ll do for the day the day-of, or at the start of a study session. I set aside some time to go through a less-structured version of what I have to do, including high level things I need to think about, and decide then. I timebox these times though, since I feel like it&rsquo;s super easy for me to get off track trying to figure out the best way to do something, when I just have to go do it.</p>
<p>This summer, I don&rsquo;t have as many strict responsibilities, so I&rsquo;m letting myself be looser with all this. I precompute mostly for menial, repetitive tasks, like cleaning and meal prep, and I&rsquo;ve been blocking in more time to let things come up.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Program, precompute, perform. This is, so far, my recipe for compiling my life, and this is how I&rsquo;ve gotten through the last few years of my university and industry career.</p>
<p>I&rsquo;ve been told this sounds robotic, but I&rsquo;ve realized it&rsquo;s just like being your own <a href="https://en.wikipedia.org/wiki/Secretary#Executive_assistant">executive assistant</a>. Executives tell their ABPs the high-level initiatives they want to focus on, the presentations and tasks they have to focus on, and the events they need to attend: all the execution work they need to do. Then the ABPs and EAs go out and do all the legwork, the organization, the prepwork, to make it happen. EAs are a separate person from the executive, which lines up well with my ideas of splitting up planning and prework into a distinct phase before execution. My notion of precomputation isn&rsquo;t even that novel: sure, maybe the EAs don&rsquo;t go to the extent of logging onto their exec&rsquo;s laptop to open up all their tabs for them, but they prepare summaries and readings and generally set up their mental environment. If the high net-worth individuals and successful businesspeople of the world have decided to spend money on outsourcing their planning and precomputing so they can focus on the executing, I think there&rsquo;s some value in doing the same for ourselves too.</p>
<p>The next time you start feeling overwhelmed, consider compiling parts of your work. Do as much of the pre-work and the hard thinking ahead of time, when you&rsquo;re in a planning mindset, as possible — as much of it as you can without actually doing it. Make the execution the easy part.</p>
<p>I still remember my manager intoning &ldquo;Don&rsquo;t let that WIP cloud grow!&rdquo; at most team strategy meetings. At my current internship I try to remind myself of that whenever I have a free moment and reflexively think of picking something new up. Sometimes I listen and I don&rsquo;t go for the shiny new thing, and sometimes I do. But when all the consequences of my pending, in-progress, &ldquo;waiting on action&rdquo; work hit at the same time, compiling my life helps me make sense of the chaos. Whenever my WIP storm touches down on my mental ground zero, I trust that I&rsquo;ve done the work ahead of time to make it through.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I will admit this metaphor is a little stretched, but I really wanted to mention monomorphization. A throwback for those who know.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>I keep the food itself in my fridge though. I don&rsquo;t think <em>mise en place</em> is a good idea if you&rsquo;re not immediately preparing the food.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
