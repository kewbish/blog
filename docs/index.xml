<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Yours, Kewbish - a collection of </title>
    <link>https://kewbi.sh/blog/</link>
    <description>Latest Yours, Kewbish posts</description>
    <managingEditor>(Emilie Ma ◦ Kewbish)</managingEditor>
    <lastBuildDate>Sun, 13 Jun 2021 14:52:15 -0700</lastBuildDate>
    
	<atom:link href="https://kewbi.sh/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Indie Games: Influences</title>
      <link>https://kewbi.sh/blog/posts/210613/</link>
      <pubDate>13 Jun 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On the ideal aesthetic behind my game dev.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>This is a continuation of my last post: if you&rsquo;re interested, I discussed some of the <a href="https://kewbi.sh/blog/posts/210523/">tools and engines</a> I used over my indie game dev journey back then. In it, I reminisced on the process of finding new gamemaking tools to try out, mostly drawing from memories of the little experiments I used to work with. I will also confess that I was mistaken in that post: I do actually <a href="https://kewbi.sh/blog/posts/210523/#fn:2">have the original files</a> for a good number of old projects. The other day, I was looking through my backups and archives from a couple years ago, and found a few interesting folders. Here&rsquo;s a look at what eleven-year-old me thought was peak indie game development:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">archives/
├─ aninfinitebath.zip/
├─ bleedingpenguins.zip/
├─ botanicpiano.zip/
├─ closer.zip/
├─ ohmagosh.zip/
</code></pre></div><p>These are some of my mid-Unity-phase games, put together a couple years ago sometime before the end of 2018. I&rsquo;ll expand a bit more on the actual projects in a bit, but just looking through the old files&rsquo;s brought me right back to developing each of the experiences. Back then, I had no idea what I actually wanted to aim for in terms of game mechanics, genre, or style, so I focused on copying my ideal aesthetic.</p>
<p>That &lsquo;ideal aesthetic&rsquo; was developed over many an hour trawling through <a href="https://itch.io">itch.io</a>, a digital marketplace focusing on sharing and selling indie games of all genres. I really liked the vibe of the site as a kid - there was just something about the simple theming and easily discoverable games<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. When I started looking for places to share my games (after all, I very much was validated by watching download counts tick very slowly up over time), I went straight to customizing my profile and uploading little HTML5 games to itch.io. I spent a while learning CSS to fine-tune my landing pages there, and I think it&rsquo;s made a clear impact in the aesthetic that continues to influence my design decisions to this day. Game jams and development communities centered on the site also gave me a starting point and many sources of inspiration throughout the process of trying to learn how to develop - in short, it was a pretty interesting environment.</p>
<p>In this post, I&rsquo;d like to reflect on some of my past projects and other aspects of my game dev journey, such as the various influences that somehow combined to build what I&rsquo;ll continue to call my &lsquo;aesthetic&rsquo; for games. I can&rsquo;t seem to find a better word for the phenomenon, but I mean the general feel, artistic style, production quality, and story types that featured in games that I came to love and admire.</p>
<h2 id="itchio-inspiration">Itch.io Inspiration</h2>
<p>I&rsquo;ve already mentioned the impact of itch.io on my sources of inspiration, but I can&rsquo;t highlight enough how much of an influence it had over what I chose to create. I remember somewhat illegally joining their Discord (by illegally, I mean age-wise, but let&rsquo;s hope I don&rsquo;t get my account suspended for not following TOS), and subscribing to the daily progress updates. Each day, I&rsquo;d look forward to the <code>@DailyDev</code> ping that rolled in sometime in the morning, and watch the channels get flooded with cute screenshots and GIFs of fascinating mechanics in progress. I generally lurked in the server, never interacting unless I really wanted to post a couple screenshots of art or request feedback when I was &lsquo;launching&rsquo; a game. However, just being able to see the amazing work and concepts that were also being created in parallel with my projects was a healthy motivation boost. I think having this initial community that I could sort of pseudo-participate in was a very fun experience, and I can&rsquo;t thank the whole itch.io community enough for fostering that space.</p>
<p>Itch.io also introduced me to the thriving community of game jams, and the often unpolished, though wonderful, experiences that would come out of them. For the uninitiated, game jams are short events, usually under a tight time crunch, where developers and artists gather to create a game based on a hidden theme. Some of the bigger ones that you might have heard of are <a href="https://globalgamejam.org/">Global Game Jam</a> and <a href="https://ldjam.com/">Ludum Dare</a> - I&rsquo;d advise going through some of the event galleries for meetups and game showcases: the end results are super creative and surprising. Itch.io had its own online game jam functionality, and the list of jams hosted on the site is only growing. <a href="https://itch.io/jams">This page</a> highlights all the jams happening at any one time - just today, I can see at least forty or fifty jams running, and I didn&rsquo;t even scroll that far down the page. Larger jams often stemmed out of, or would host, their own Discord communities, which gave eleven-year-old me extra content to feast on. Looking through project galleries was hugely inspiring - seeing the efforts of just a couple people over just a few hours was oddly motivating.</p>
<p>Though I never really got into the whole game jam lifestyle, I did like to look through past jams and projects for their themes. At this point in time, I had no original ideas, really, and was just trying to emulate all the cool projects I&rsquo;d seen online. I&rsquo;d piece together different game mechanics or slap together a slightly more creative story, and call it a day. As you&rsquo;ll see later on, I focused not on making full releasable games, but on smaller scenes and cute experiments, which were mostly an excuse to make new Unity projects and spend much too long on custom pixel art again. That means I was constantly looking for new ideas to feed my tiny games, and the more frequently running game jams were a godsend for sparking new schemes. I particularly had a thing for the <a href="http://www.weeklygamejam.com/">Weekly Game Jams</a>, which put out new themes each week. I also liked drawing on other people&rsquo;s interpretations of these prompts later when developing my own games, since I never stuck to the strict weekly schedule or even formally entered in any jams, as far as I can remember. The nice thing about these jams, especially the week-long shorter ones, was that there was no pressure to polish (or even present, since I didn&rsquo;t officially participate) anything that came out of those experiences. That incessant stream of new thoughts and potential games was incredibly fun to think about as a kid, and I used to be constantly dreaming about new things to make. I think there&rsquo;s something interesting to consider with these tight creative feedback loops and constant states of tinkering - a continuous imaginative cycle of producing new things for the sake of honing my skills and just having fun with the process.</p>
<h2 id="experiments-and-examples">Experiments and Examples</h2>
<p>Back then, I liked making proof of concepts, toying around with environments and game mechanics, instead of worrying about gameplay. This helped me learn how to work through design problems, and piece together how to create simple interactive environments. Having a system of just picking up new ideas and working on them as long as I wanted before moving on to the next idea in my backlog allowed me create a pace of continual creative thinking, and remain motivated to even work on development. While no major games came out of this cycle, I think my brain likes these smaller experiences more, and having smaller &lsquo;investments&rsquo; to have to make with each game let me develop my aesthetic and refine my ideas well.</p>
<p>Let&rsquo;s go through a quick summary of some of the games I mentioned earlier, as well as some I just very vividly remember putting together. I discussed in my last blog post that I had a couple tool &lsquo;phases&rsquo;, in which I would fall into a rabbit hole of endlessly exploring on specific engine, and then jump to dabbling with the next. I can&rsquo;t really remember anything I made in GameMaker, I only put together a couple platformers in GDevelop, and I can&rsquo;t access my Roblox anymore, so I&rsquo;ll go into some of the work I put together in two main tools: Bitsy and Unity.</p>
<p><a href="https://ledoux.itch.io/bitsy">Bitsy</a> is a minimalist, retro-ish game engine that focuses on story- and rudimentary interaction- based games. I made a bunch of games in Bitsy, mostly because the boilerplate required was absolutely nothing, and it was a quick way to capture whatever questionable narrative I wanted to express. After a couple exploration games (I think I really had a thing for trying to do super scaled-down pixel art back then), I worked on a couple &lsquo;proper&rsquo; games. One of my favourites was based off a play on words between Caesar, the individual who was brutally murdered by his closest confidants, to the salad, which I don&rsquo;t think involves any violence. Eleven-year-old me thought it would be funny to create a whole Ancient Rome-esque world, in which the main character played a spy out to poison Caesar, with, well, a salad. The player would wander round a bunch of rooms, looking for the right rotten tomatoes (it had not yet dawned on me that the presence of tomatos would make it closer to a Greek salad) and toxic lettuce to finish off the poor general. I remember getting very carried away with the art, meticulously painting together little salad bowls and baker NPCs selling their loaves that the player would buy to make croutons out of. It was a very amusing little game, and I&rsquo;m honestly sort of proud that I went all in on the pun. I think the last thing I tried to make in Bitsy was an elaborate network of rooms that would each depict a phase in the main character&rsquo;s life, all connected to form their entire life story, but it got a bit too complicated, so I scrapped it.</p>
<p>Unity was where I made the majority of my games after my Bitsy adventures, though I suppose a better word for what came out of my tinkering would be &lsquo;experiments&rsquo;. Even just looking at the things I worked on in 2018 (that I archived, I remember working on plenty more projects that never went past the player controller script or so and were therefore not saved properly), I had a pretty interesting streak of ideas:</p>
<ul>
<li><em>An Infinite Bath</em> - This was something to do with balancing a bathtub, and trying to balance the rubber duck and the soap and whatever suds in the basin while the game randomly started to tip it. It resembled the IRL game of &lsquo;keep it up&rsquo; that I used to play in elementary school, so I suppose that might have been an inspiration.</li>
<li><em>Bleeding Penguins</em> - A painstakingly hand-pixellated ice sheet, complete with icebergs and snowflakes, and a sliding penguin that you could drag around. The &lsquo;bleeding&rsquo; part of the title refers to the fact that, naturally, the penguin was moved not by a mysterious force, but by gently prodding it with a knife (hence the blood spatters that I also thought were necessary to maintain the atmosphere). I genuinely don&rsquo;t have an explanation for this one (besides maybe one of those word generators?) - I was an interesting child.</li>
<li><em>Botanic Piano</em> - On the complete opposite side of the questionability spectrum, this involved a calming musical loop with nice rain and wind sounds (that were ripped directly from somewhere off YouTube). The player jumped around a flowerpot, landing on magical flowers that would play a single note. Very oddly charming, and sort of relaxing as well.</li>
<li><em>Closer</em> - I think this pivoted from being a C# script (yes, I had a bit of a thing for terminal apps even then) to a half-hearted Unity game. The premise was that you&rsquo;d try to get as close as possible to another character, and then eventually have them push you away. I remember making the itch.io cover art, and including a bunch of hearts, which means that I&rsquo;d intended this to be a somewhat romance-related game, but I really don&rsquo;t know how that came through, since the gameplay was essentially a PowerPoint slideshow.</li>
<li><em>OHMagosh</em> - Another play on words, this was one of the times I tried to actually make a playable game and learn more about the programming side of things. It was meant to be an infinite runner, since that was what I was following <a href="https://www.youtube.com/watch?v=5M7vX_z6B9I">this tutorial</a> for. I think this was also the first time I&rsquo;d tried to look into a game jam (without actually committing by signing up or anything), which explains why the theme was something to do about electricity. The main character played a cute little (pixel-art; are you seeing the recurring theme here?) janitor, running around with their toolkit to put resistors in the correct slots. I had a bit of trouble actually learning how to code this, and didn&rsquo;t end up finishing or submitting it, but I do have the art, which I think was pretty adorable given I had no actual experience:
<figure><img src="https://i.imgur.com/PXiCISc.png"
         alt="Figure 1. My attempts at a character and assets."/><figcaption>
            <p><em>Figure 1. My attempts at a character and assets.</em></p>
        </figcaption>
</figure>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>I don&rsquo;t think I&rsquo;ve even really figured out what my full aesthetic is, but if I had to sum it up in a couple phrases, it&rsquo;d be:</p>
<ul>
<li>first and foremost, pixel art - I had a huge thing for trying to make spritesheets and distill complex images into a couple pixels</li>
<li>experientially focused - I wasn&rsquo;t too bothered with the game length aspect, and was more concerned about their feel</li>
<li>very odd ideas - what can I say? I twisted even game jam themes into pretty interesting interpretations</li>
<li>one-upping the last - each game was focusing on a different aspect of development that I was trying to learn, and this method of tackling one thing at a time was very effective in learning the engine</li>
</ul>
<p>I could go on forever, diving into all the old hidden archives I have, but I think it might be a bit more interesting to focus on the takeaways I&rsquo;ve learned from this whole nostalgic look back. First, I find it really interesting that I was drawn to such simple and relatively unengaging experiences to build, and I think the fact that I had a severely limited programming ability was a major factor. I&rsquo;ve noted that game dev kind of helped me learn how to learn to develop on my own, and properly learning how to develop lead to me being able to create quote-unquote better games. As well, it&rsquo;s fascinating how my game dev focus also shifted over the years as I hopped between tools, and how my style and preferred game type changed with each engine. With GDevelop, an engine suited well to event-based games (and with a built-in platformer tutorial), I fell back to making platformers and action games. On the other hand, Bitsy was built for worldbuilding and storylines, which I focused on when using the tool. Unity&rsquo;s relative difficulty in getting started and learning curve lead to smaller experiences with which I tried to work on learning how the engine worked. And finally, I&rsquo;d also like to reflect on the tight creation loops and the steady stream of games I was putting out back then. I think the whole game jam community and the influences I was surrounding myself with digitally helped to push me towards a system of tiny projects, made and finished quickly, which also benefited my creative thinking, and later, my development skills.</p>
<p>Moving forward, while it&rsquo;d certainly be fun to get back into game jams, I think their rather time-crunch-y nature doesn&rsquo;t make them a good fit for what I like to do (also a reason that the couple weekend hackathons I&rsquo;ve done were more stressful and unenjoyable than the two-month long one I&rsquo;ve participated in). Something I&rsquo;d like to bring back into my life, however, is the &lsquo;creation state&rsquo; that I was in when I was younger. I really liked being able to constantly work on something and dive back into tinkering with little systems whenever I wanted, and I think I&rsquo;ll be shifting around my current projects to reflect that. Whether it be CTF problems<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, personalized CLI tools, or even reinstating my weekly writing habits, I&rsquo;d like to return to that creative state, and with summer coming up, it&rsquo;ll be the perfect opportunity to dive into whatever I&rsquo;d like to tackle.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I specifically remember spending way too much time at school clicking through the <a href="https://itch.io/randomizer">randomizer</a>, which you could fine-tune to narrow down tags and platform types. There was something very magical about the way it managed to spit out highly appealing games every couple clicks, though I suppose that&rsquo;s also a testament to the quality of the games hosted there. itch.io also has a very nice tagging system, which I recall tabbing through as well. The <a href="https://itch.io/games/tag-pixel-art">pixel art</a>, <a href="https://itch.io/games/tag-2d">2D</a>, <a href="https://itch.io/games/tag-casual">casual</a>, and <a href="https://itch.io/games/tag-cute">cute</a> tags were the ones I frequented the most, which I guess exposes my entire taste right there.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I&rsquo;ve also been getting back into attempting some <a href="https://play.picoctf.org/practice">picoGym</a> problems, as well as taking a look at some crypto resources, namely <a href="https://cryptohack.org/">Cryptohack</a> and <a href="http://cryptopals.com/">Cryptopals</a>. They&rsquo;re pretty challenging, but it&rsquo;s fun to properly learn the basics and familiarize myself with common attacks and such.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Indie Games: A Trail of Tools</title>
      <link>https://kewbi.sh/blog/posts/210523/</link>
      <pubDate>23 May 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On my game dev toolbelt as I got started.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I think I&rsquo;ve mentioned it before, but ironically, the platform that hooked me into programming was low- and no-code tools. Specifically, I had a bit of a phase in which I fancied myself a game developer, while exclusively relying on drag-and-drop engines and scripting-free tools. I think game dev was my first real foray into any sort of programming (unless those endless rounds of <a href="https://lightbot.com/">Lightbot</a> in elementary school computer class counted). I recall it being surprisingly easy to get started: there&rsquo;s a wealth of game-making tools available that don&rsquo;t require any coding and are specifically targeted at kids: from the ubiquitous <a href="https://scratch.mit.edu/">Scratch</a>, to <a href="https://roblox.com">Roblox</a>, the addicting launcher and editor that supplied many an hour of obbying fun<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. While I no longer have original files<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> for most of these projects, I thought it&rsquo;d be interesting to take a dive into the tools and engines that, well, &lsquo;raised&rsquo; me as a programmer - at least until I found out what web development was.</p>
<p>I used to play quite a few games as a kid - I think I started with the first versions of the Dora games (where an oddly grown-up version of the title character would go around with her gang of friends and rescue puppies). There was also the Build-a-Bear Bearville universe, which I can no longer find any archives of, and apparently shut down in early 2015. I was very intrigued by seeing my physical teddy bear pixellated on a screen, and I think I spent way too long on customizing my in-game house. It was odd how accurate my character was, and trying to figure out how the game magically copy-pasted my toy directly into the Cub Condo was an interesting thought experiment for six year old me. <a href="https://en.wikipedia.org/wiki/Moshi_Monsters">Moshi Monsters</a> was another super fun game - though also now deprecated due to Flash requirements. I remember spending ages trying to figure out all the puzzles and quests, and inevitably falling into the YouTube clickhole of walkthroughs and clues. When I got a bit older, I went into a pretty heavy grind with <a href="https://en.wikipedia.org/wiki/Club_Penguin">Club Penguin</a>, and I used to meet up with friends to do the <a href="https://clubpenguin.fandom.com/wiki/PSA_Secret_Missions">PSA Secret Missions</a>. There are tonnes more Flash and (pseudo-)educational games I used to spend my free time on, and I credit the experience of these engaging game mechanics with sparking my interests in game development.</p>
<p>Somwhere along the way, I got the idea that I could replicate or extend some of my favourite games, so I started Googling around for &lsquo;how to make games no code&rsquo;. It&rsquo;s interesting to note that I even understood the concept of code, and that I didn&rsquo;t have the skills to write it, in the first place. I think it&rsquo;s kind of poetic that what ended up drawing me to development were such low-code (and low-effort) tools. Most of the games I get nostalgic over are the bubbly, vibrant, slightly buggy Flash games that popped up in the early 2010s, and back then, that was all I wanted to replicate. Game-mechanics-wise, my projects weren&rsquo;t much more than drag and drop world builders, or side-scrolling puzzle platformers. But I saw something in the process of building each of these game worlds, from the carefully crafted quests and characters to the infinitely customizable housing systems in many of the games. That something was enough to encourage me to jump (well, attempt to awkwardly stumble) into the world of game development, and it&rsquo;s brought me, through a very disjointed and meandering path, to where I am today.</p>
<p>In the process of writing this post, I realized I had a lot more to reminisce about than I&rsquo;d initially thought, so I&rsquo;ll split this post into two. This post will cover the tools that I used, and how each of them shaped my development journey. The next post, whenever that comes out, will tackle more about the projects I worked on and the impacts game development and indie game culture have had on my experiences to date.</p>
<h2 id="the-gamemaker-era">The GameMaker Era</h2>
<p><a href="https://www.yoyogames.com/en/gamemaker">GameMaker</a> wasn&rsquo;t the first programming experience I had - that honour goes to the battered copy of &lsquo;Javascript for Dummies&rsquo; I picked up at the local library sometime in third grade. It taught the basics of console logging<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, and eventually got into how to bodge together HTML5 games. I can&rsquo;t remember what exactly led me to download GameMaker on the first old Toshiba laptop I had essential free reign over, but I remember being spontaneously inspired to see if I could make JS games without programming. Oh, the naivete of little me - though I guess it&rsquo;s sort of funny that even 9 year old me was already frustrated by programming.</p>
<p>I don&rsquo;t think that GameMaker was even paid when I installed it, but I recall being very intimidated by all its buttons and menus. GameMaker games can be put together with GameMaker Language, the proprietary scripting system, though I was nowhere near prepared enough for that. Even the visual drag and drop systems were a bit overwhelming. I doubt that&rsquo;s a fault of GameMaker&rsquo;s - I was glancing through a couple tutorials earlier, and it&rsquo;s comparable to Unity. But what can I say: I was probably 9 or 10, and I simply was unprepared for the wild world of &lsquo;actual programming&rsquo;, even though I guess GML is more visual scripting than anything. After discounting GameMaker as a viable tool (because I could not for the life of me understand it, and the concept of Googling niche websites for tutorials had not revealed itself  yet), I delved into a search for another engine: something that might be less feature-heavy, but that would be more comprehensible.</p>
<h2 id="hacking-gdevelop">&lsquo;Hacking&rsquo; GDevelop</h2>
<p>That tool ended up being <a href="https://gdevelop-app.com/">GDevelop</a>, which actually did spark a lot of small creations and my first couple finished games. GDevelop has a custom event-based scripting system that&rsquo;s pretty advanced for its child-friendly interfaces. I probably didn&rsquo;t make use of half the features available, but I think this was roughly when I started to think about proper mechanics and ideas - I was no longer too handicapped by my lack of programming skills, so I could focus on what I really wanted to make. (Not that I had any original ideas, but it was definitely rewarding to see the actual playable fruits of my efforts.) Exporting was also super simple, so I started to be able to actually play my games and show them off to my classmates. (I think this was also the point when I made an <a href="https://itch.io">itch.io</a> account as well.)</p>
<p>I&rsquo;ll talk a bit more about some of my projects in the other post, but the first couple experiments I made in GDevelop were definitely platformers. I had a thing for the genre (probably due to a minor dinosaur game addiction), so I spent a lot of time drafting up rudimentary &lsquo;AI&rsquo; (if-statements) in the editor. No matter what scuffed little projects I worked on - the important thing was that I could actually make things now. Whatever ideas I had - I could (probably) bodge together a solution, and that freedom was pretty addicting as a kid.</p>
<h2 id="bitsy">Bitsy</h2>
<p>Sometime vaguely concurrent with my GDevelop escapades was my foray into <a href="https://ledoux.itch.io/bitsy">Bitsy</a>, a little story game maker that&rsquo;s decently popular in the indie game community. There was a charming painting pane where I could pixel-art whatever characters I wanted to build, a tile editor to lay out my story, and a few rudimentary animation and item settings. Things were dead simple to rig together, and while the editor certainly had its limitations (which were intentional design features, I&rsquo;m sure), I found the restrictions more freeing than anything. Instead of making proper shooters or scripting complex game behaviours, I could focus on writing my storyline, and improve my world-building skills.</p>
<p>Dialog and drawing out the worlds were the key pillars of the whole Bitsy experience, and while I didn&rsquo;t come up with any cinematic masterpieces, the whole retro + limited aesthetic has made a lasting impression on my content preferences. It&rsquo;s built a very niche, indie community, and I value that while it might not be the choice for a fast-paced action interaction, the experiences people have worked Bitsy into are very impressive and inspiring. I might take a stab at another few Bitsy games in my spare time (not that I have any at this point, but I can dream), just because they&rsquo;re so cute and fun to make.</p>
<h2 id="climbing-the-social-ladder">Climbing the Social Ladder</h2>
<p>I can&rsquo;t think back about my game development phase without mentioning <a href="https://roblox.com">Roblox</a>. At first, I didn&rsquo;t even know I&rsquo;d installed the editor, since it was just bundled in with the default installer. I only opened it after trawling through Windows Appdata folders looking for something, but once I opened it, I immediately started playing around with the modelling and setup tools. Roblox itself was an amazing, engaging game environment, and since I&rsquo;d been playing a bunch of the various games with my friends, I had references and inspiration to draw ideas from. Roblox&rsquo;s editor was definitely a step up from the simplicity of GDevelop, but the basics were simple enough: drag and drop models from this pane, make your own over here, and fiddle with object settings in this one. It&rsquo;s surprisingly comparable to Unity, though the scripting is done in Lua instead. I remember spending ages scrolling through Roblox tutorials on YouTube - <a href="https://www.youtube.com/channel/UCp1R0TBvgM7gj0rwTYULmSA">AlvinBlox</a> was one of my favourites. I had no idea how to get anything new done, since I was copying code directly over from video courses, but it was still something.</p>
<p>Given the odd section title, you&rsquo;re probably thinking some dramatic backstory happened with grade 5 me. I&rsquo;ve mentioned this a couple times before <a href="https://kewbi.sh/blog/posts/210124/">in other posts</a>, but my Roblox shenanigans involved making little games for my classmates to show off my tried-and-true hackerman skills. This was sort of an expansion of my experience with GDevelop and Bitsy, but Roblox also offered a platform to share my experiments on, and one that my friends were already spending way too much time on. In a way, I guess Roblox shares a similar vein with TikTok in that remixing and sharing content is super easy, and this low barrier of creation lends itself nicely to the empire of content both apps have been building. As well, seeing how my classmates played my team games led to new feature ideas, which then fed my need to learn programming, so by the end of my Roblox journey, I&rsquo;d developed a decent understanding of how &lsquo;real&rsquo; game engines worked.</p>
<h2 id="pixelpad-and-unity">Pixelpad and Unity</h2>
<p>This came in handy, since by this point, my parents had picked up on my whole programming spiel and wanted me to learn &lsquo;properly&rsquo;. That meant shipping me off to coding classes once a week, where I sat in an overly bright schoolroom and copied code directly from what the instructor was writing out. No shade at all - in later classes they tried to get us to build our own functions first, but thinking back, one of the main reasons I stopped was because it felt very repetitive and, frankly, boring to be essentially regurgitating lines of script. There wasn&rsquo;t much creative thinking involved, and since each session was oriented around making similar versions of the curriculum project, I felt a bit shackled by all the restrictions of fitting to a pre-built game. (However, this did end up expanding my actual programming skills quite nicely, so while I maybe lacked freedom in my gamedev, I certainly ended up making more polished and playable final products.)</p>
<p>My first year there involved working with <a href="https://pixelpad.io/">Pixelpad</a>, a Python-based web interface. It has a pretty detailed core library that makes programming in it very different from vanilla Python, but it was easy enough to hack away at. I took away none of the Python syntax and had only scratched the surface of what it was capable of, but Pixelpad was my first instructor-led look into properly scripted games. While I didn&rsquo;t really grasp the library well other than what was used in classes, I&rsquo;d learned the basics of thinking in a game loop and started thinking about possible recipes that I could reuse in other languages and engines.</p>
<p>Once I&rsquo;d <del>started to fancy myself an actual game developer</del> graduated to the next module of the program, I started working with Unity. (This continued for a couple years before I finally decided making websites was more attractive and quit.) Unity was certainly a step and a half up above Pixelpad, so while not being able to control exactly what I was making, having an instructor guide me through what was going on helped cement the scripting system better than if I&rsquo;d tried to tackle it on my own. A lot of the maths concepts (vectors used for jumping and 3D world space movement) went completely over my head, and it honestly wasn&rsquo;t until last year when I revisited Unity (for an unrelated project) that I finally understood them. Despite its challenging interface and complex starting point, Unity&rsquo;s been what I turn to for any small game development for school projects now - it&rsquo;s a nicely popular, full-featured engine that I have enough experience in to bodge games together with.</p>
<h2 id="conclusion">Conclusion</h2>
<p>It&rsquo;s been a fun trip to navigate through what I have left of old projects and memories of when I was getting started - I should do this more often. What&rsquo;s been most interesting to personally note as I&rsquo;ve charted my journey through a minefield of various engines is how my annoyances and frustrations with each tool logically lead for a search for the next. Following the trail somehow leads all the way to where I am now - I think each of the tools I&rsquo;ve mentioned above has changed my approach to programming in a significant, though perhaps minor, way. Game dev was where I got started with real, applicable programming, and that makes it something I&rsquo;d like to at least consider dabbling around with in the future.</p>
<p>I&rsquo;ve fallen pretty far out of from game development now - the last time I touched it was for a school project, and before that, I hadn&rsquo;t even kept Unity downloaded on my system for ages. However, I think the cultures and communities that I somewhat illicitly joined (I was definitely under 13 when I made an itch.io, but we&rsquo;ll keep that one to ourselves) certainly made an impact - not just on my programming ability and game design skills, but also on my aesthetic, and the types of content I find appealing today. Or maybe it goes vice versa - perhaps the whole indie aesthetic drew me to the collaborative, close-knit sphere of game development. I could go on for ages about this, but I&rsquo;ll keep my discussion about my projects and inspirations to another post. I&rsquo;m excited to expand more on some of my old experiments, so look forward to that story when it comes out.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>We used to have to share laptops in grade 6, so while most people would fight over their assigned partner to finagle the most screen time, my friend and I agreed to use one computer and play together. Oddly more democratic and a lot less chaotic than most other arrangements, but that&rsquo;s besides the point. We were both into obbies, or glorified 3D platformers that generally had elaborate level design and often story levels, though our favourite, which I think was called Wipeout, was a pretty straightforward obby in terms of mechanics. One of us used to control the WASD keys, and the other would deal with jumping. To be honest, it was a lot more efficient than most teamwork I had since then, which might either say something about the sheer focus put into making precarious jumps, or something about effective organization.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Well, I technically do have an archive of all of my work dating back roughly to 2019, which is when I just took all the work previously and zipped it up. However, I don&rsquo;t think half the project files would load properly with recent versions of the tools, and I can&rsquo;t be bothered to deal with the hassle of trying to find old releases and fix everything up for a few screenshots.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Oh dear - I can tell this will be a footnote heavy post, but there are a lot of tangents I want to reminisce about, but I suppose you can skip these if you&rsquo;d like. Before picking up Javascript for Kids or Dummies or whatever it was, we used to use Internet Explorer at home, while the old clunky laptops at school were slowly transitioning to Chrome. Well, to get that spicy console inspector, the book directed me to download a copy of Chrome, which I remember thinking was the absolute coolest thing ever. I was <em>installing my very own web browser</em> - in short, I may as well have been in sunglasses and an oversized black hoodie: I was a <em>hacker</em>. The next time we used the laptops, I pulled out my new <code>alert()</code> and <code>console.log()</code> magic to prank all my friends. I think the moment when they realized that no, the FBI was not, in fact, watching them was one of the most inspiring moments for 9-year-old me - my first computer science clout.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Dimensional Writing</title>
      <link>https://kewbi.sh/blog/posts/210516/</link>
      <pubDate>16 May 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On outlining and non-linear work.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I can&rsquo;t seem to find it again, but earlier this month, I saw a video on Twitter of a proof-of-concept zooming essay model. It featured a straightforward explanation of some maths, but what really struck me was the layering of the concepts: each &lsquo;sentence&rsquo; or major phrase was underlined in a different colour, and when clicked, would expand into a longer, more intuitive layman&rsquo;s explanation of the topic. Not every word was expandable, but, for example, a sentence involving a couple formula definitions would lengthen into several more phrases developing the background knowledge. That &lsquo;second level&rsquo; explanation in turn contained a little bit of theory based on some other assumptions, so the reader could click again to expand key points in that explanation, and so on. I think this continued for three or four levels, and what I found most interesting was that this augmentation wasn&rsquo;t limited to individual phrases. If I recall correctly, one of the sentences involved the definition of some probability statistics,which was also touched on later in the paragraph. Clicking once on the first definition would expand topics later on in the writing, so the entire piece of writing had several levels of explanation &lsquo;advancement&rsquo;, going from expert complexity, with lots of notation and terms; all the way to something comprehensible by even those with no maths background.</p>
<p>Imagine the possibilities if these were extended to mainstream explanations and articles. With most blog posts (including mine, newsletters, and platforms like <a href="https://buttondown.email">buttondown.email</a>, this level of expansion and &lsquo;for later investigation by the reader&rsquo; is already possible with footnotes, but not quite to the level that was demonstrated in the GIF. Sure, you can link relevant resources and direct the reader to other related ideas, but with the Twitter example mentioned above, there&rsquo;s an extra dimension of presentation control. The author can fine-tune the level of jargon and generalizations present in each expansion, and has more power to present their essay or text as they&rsquo;d like it to be experienced.</p>
<p>If you read any Wikipedia article, you&rsquo;ll find that the first paragraph or so is a simple, clear summary of the topic at hand. Further links lead the reader to additional materials to increase their understanding of the depth of the topic, but skimming that first chunk is enough to get a gist of the topic itself. I&rsquo;m reminded of the idea of incremental learning<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, where instead of starting from complex theory step by step, you build a general understanding of the topic first. You might have to make a couple overall generalizations and assumptions, but the reader&rsquo;s left with a basic grasp of most of the topic. Then, each iteration of a text can build on the level before, clearing up a specific point or introducing new vocabulary. At each step in the process, the learner has a working understanding - it might not be the deepest or most accurate, but it&rsquo;s there. This works well with a sort of reversed version of the Twitter example (I&rsquo;ll just call it that since I forgot the actual name of the creator and can&rsquo;t find the video anymore) - using each expansion to further comprehension, not explain a point. Same concept of levels of knowledge, different structures.</p>
<p>This post is an exploration of my thoughts on theories that expand beyond just lists and dry bullet points, how to efficiently pursue idea connection, and how I approach the writing process. I really like the idea of infinite subexplorations and the &lsquo;zooming&rsquo; magnification present in that demo, and I don&rsquo;t entirely know why. Perhaps it&rsquo;s that it affords the reader more opportunities to customize the text to their own reading and comprehension levels, or maybe it&rsquo;s that everything is structured very logically, with an overall outline that can be (almost) infinitely expanded. Honestly, thinking back to the long <a href="https://kewbi.sh/blog/posts/201220/">digressions I had on click-holes</a>, I think it&rsquo;s just what appeals to my brain the most.</p>
<h2 id="non-linear-thinking">Non-linear Thinking</h2>
<p>This type of thinking ties basically the whole non-linear notetaking workflow and recent networked thought revolution together. Processing information in a way that doesn&rsquo;t involve immediately writing down final notes or content sequentially, or what I call non-linear thinking, is something that&rsquo;s been gaining traction recently. People praise it for mimicking how their brain works, and are surprised with how much less restrictive the entire system is. Thinking like this is inherent in models like the Twitter example, where each &lsquo;layer&rsquo; of text interacts with others but stays independent (for example, you can expand one set of definitions, while leaving another about a topic you&rsquo;re more comfortable with as-is).</p>
<p>There are many different manifestations of platforms that I think fall somewhere under the non-linear umbrella, such as infinitely nesting notes, linked systems like the ever-popular Zettelkasten or Roam Research graphs, and outlining tools. Tools available in this area might overlap in one or more of the areas above, but the main point is that things don&rsquo;t (have) to happen sequentially or from start to finish in one go. Thoughts can have intermediate layers, and iterations can stand alone while being incomplete and marked for further revision. Systems like this work to reorganize and restructure large amounts of information quickly and efficiently. Think back to trying to edit context-heavy sentences that draw on its neighbours to provide transitions and such, versus copy-pasting a bunch of bullet points around, while retaining any links those may have to other points. Off the top of my head, I can think of two main players in the space.</p>
<p>While I&rsquo;ve never used <a href="https://workflowy.com/">Workflowy</a> as a daily notetaking driver, I&rsquo;ve heard it described as one of the original implementations of non-linear thinking. One of its biggest selling points is the infinite nesting and pagination present in its model. Each point, termed a &lsquo;bullet&rsquo;, is an entire page - sort of a lower level of what&rsquo;s available in Notion and Roam. Each bullet can contain infinitely many other bullets, which opens up the possibilities for a lot of outlining-style and level-zooming type interactions. On its marketing page, it states that:</p>
<blockquote>
<p>No other document has an infinitely deep structure that lets you choose the exact focus level you want.
which directly echoes the whole layers concept that I think is an interesting platform to work with.</p>
</blockquote>
<p>Roam Research is slightly different, but has equal following (especially on Twitter, with the whole #roamcult shebang) and vaguely similar aims. Also one of the most popular tools for building networked knowledge bases, its main selling point is its whole graphs ecosystem and the blocks model that it so popularly uses. It&rsquo;s a cult favourite in the <a href="https://kewbi.sh/blog/posts/200607/">Zettelkasten</a> community, and has been lauded for completely revitalizing how people work. I&rsquo;ve also never personally used Roam, so while I can&rsquo;t speak directly to its apparent life-changing potential, I think it marks something interesting: the shift in awareness and prevalence of non-linear thinking tools.</p>
<h2 id="dimensional-dilution">Dimensional Dilution</h2>
<p>Over the past couple months at school, I&rsquo;ve realized that I keep returning to one &lsquo;way&rsquo; of doing schoolwork. Every time I create a new document for some homework assignment and finish all the setup of 12pt Times New Roman and double spacing, I start by copying over the guiding questions<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, which I find is a nice way of sparking thoughts and feeling a lot more productive than I really am. Oh well. Then, I start going through each question - and where I used to start by going systematically in with fully-fledged answers right away, I tend to just create a new bulleted list and come up with my main points and subpoints. I call this system outlining, and it&rsquo;s been pretty surprising how much it&rsquo;s taken over how I work.</p>
<p>Outlining is a bit of a one-dimensional version of the general ecosystem of networked and infinitely capable knowledge management tools. It dilutes (or well, not dilute, since the concentration of thought is the same, if not more) the complex process of creating full notes with perfect grammar and fully thought-out ideas into a more iterative process. I can quickly lay out each of my points, while not having to worry about grammar, coherence, or even having a proper idea. I tend to use super casual language, and just go ahead with stream-of-consciousness style writing, full of &lsquo;like&rsquo;s and &lsquo;whatever&rsquo;s and such. I don&rsquo;t have to worry about crafting each sentence until I&rsquo;ve actually developed my idea and figured out what I actually want to say, and it&rsquo;s a lot easier to work through several levels of iteration in the process. At this stage, things can still be reordered and ideas can be more developed very efficiently, and you&rsquo;re not locked in by any concrete &lsquo;work&rsquo;. Once I&rsquo;m done with my outline, I go back to restructure the text into full sentences and paragraphs, taking out all the slang, replacing repeated words, and refining the overall thoughts.</p>
<p>This kind of ties back to &lsquo;conversational notetaking&rsquo;: I find that with just typing out whatever I feel, I end up writing vaguely sentence-like thoughts, but they&rsquo;re still less focused on the wording and more on the idea. Feedback loops are very short, and I can work to develop my ideas more quickly than if I&rsquo;d have to go directly in with worrying about grammar and stressing over the correct language to use. Oddly, I&rsquo;ve found that I end up using most of the right words anyways, but I&rsquo;ve found that the writing process still goes by much more quickly than if I&rsquo;d started with an empty document and started grinding through full sentences. At each iteration of the outlining process, I have a full document - all my ideas at each point in time are laid out on the screen. An advantage of this method over the more linear ways of working is exactly that - the layering and successive development makes each step more efficient, and it definitely helps with avoiding that helpless feeling, since each thought is at a technically completed state with each stage of the system.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Strangely enough, even having found that my brain really likes the intermediary structures of outlining and the networked capabilities of a linked notes database, I still write blog posts the &lsquo;normal&rsquo; way: just start to end, composing full sentences as I go. I guess part of it is that articles here feel a lot more casual and stream-of-lightly-edited-and-filtered-consciousness here as opposed to more formal schoolwork, but I think it&rsquo;s also that I have a pretty good understanding of what I want to write about every time I sit down to work through a post. I don&rsquo;t have to struggle to structure my thoughts more, so while I lay out a couple of markdown headers with work-in-progress headers and put down a couple key bullet points, I largely just go ahead without a formal &lsquo;outlining&rsquo; process. I do jump around a bunch when sentences pop up to the top of my head, but I really have no idea why I haven&rsquo;t tried outlining a post the way I&rsquo;d write other work. Something to consider for the next post.</p>
<p>Speaking of posts, it&rsquo;s been a while, and it might continue to be a while. It feels weird to be apologizing (?) with each post, but I genuinely don&rsquo;t feel like I&rsquo;ve been putting in enough time to write, even when I do have ideas. School was expected to start winding down roundabout now, but it&rsquo;s started ramping up with final projects and such instead, and I&rsquo;m looking ahead to prepare as best I can for UBC. The next couple weeks look pretty packed, but I think I won&rsquo;t bother writing unless I make it a personal assignment, so I will certainly attempt to slot in more timeblocks in my calendar. This blog is a place I feel that I can sort of finally expand on and formulate my own thoughts, and it serves as a reminder of what I was thinking of each week in time - I&rsquo;d like to keep it up as much as possible. Oh well - next week we&rsquo;ll see what&rsquo;s going on, and we&rsquo;ll see if I come up with another couple coherent thoughts or not.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I guess this is why the education system (at least in Canada) is structured in such a spiralling method, where we cover a topic, then go up a grade and do essentially the same thing, but in an ever so slightly more advanced way. I&rsquo;m not entirely sure why learning in layers (such as a textbook organized in the Twitter demo-esque way) is appealing while I find the spiral method awfully slow. I suspect it might have something to do with <a href="https://brianlui.dog/2020/05/10/beware-of-tight-feedback-loops/">tighter feedback loops</a> and having the ability to control your own speed in one (self-learning) but not the other (school). An interesting thought.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Generally, most of my work ends up being stuff like reflections, essays, question / problem sets, which apply well to my system. With things that are more free-form, this process still works well, but there&rsquo;ll be an intermediate step of brainstorming actual creative directions and ideas instead of just copy pasting any requirements over.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Problem Solving</title>
      <link>https://kewbi.sh/blog/posts/210425/</link>
      <pubDate>25 Apr 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On an ideal substrate for problem solving.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I was working on a physics problem earlier today: something to do with a ferris wheel, centripetal acceleration, and calculating the range of something dropped at a certain point on the wheel. It wasn&rsquo;t particularly difficult, but it&rsquo;s a good example of the ways I&rsquo;ve had to wrangle with existing tools in order to work the way I&rsquo;d like to. Normally, when I complete practice problems, I don&rsquo;t bother writing out full equations or even a good amount of work, and just stick to a couple notes for formulas and things I&rsquo;ve moved around dashed out in Chrome&rsquo;s address bar. The rest of the arithmetic part ends up being bodged together in the omnibar&rsquo;s built-in calculator, which I find is more than good enough for most problems. When I&rsquo;m doing practice for myself, I&rsquo;m just focusing on if I can get the formula and the problem&rsquo;s givens somehow into the correct answer, and I know that if I properly tried, I could get the steps down anyhow.</p>
<p>However, this specific problem was for a friend who wanted a written solution, which meant that I had to work an actual diagram out. I didn&rsquo;t fancy trying to <a href="https://asciiflow.com">ASCII art</a> one together in Vim or something, so I turned to <a href="https://www.whiteboard.team/">whiteboard.team</a>, a free, no-account-needed (which is actually great, since most of the time, my boards are temporary and just for sketching out ideas and such) online whiteboard app. I&rsquo;ve found the lack of a cloud-sync or saving option while online not to be a problem at all - again, I&rsquo;m generally only keeping boards for a couple minutes for a screenshot. I sketched out the little wheel, slapped together a poorly-formatted, rather terse solution, snapped a screenshot, and sent it off. Close board, and go about the rest of my day.</p>
<p>Chemistry labs, physics problem sets, and calculus reviews have a couple things in common besides a general feeling of dread, accompanied at times by procrastination: they involve manipulating equations and working with data in ways that often don&rsquo;t work entirely well with existing tools. For example, with the physics problem example above, I&rsquo;d have loved to get a way to format equations with at least proper subscripts and integrate a quick calculator in the whiteboard, so I wouldn&rsquo;t have to keep switching between a myriad of new tabs with nothing but half-baked expressions in the omnibar and a Unicode reference page to copy out special characters.</p>
<p>I think tools nowadays tend to do either one thing very well à la the Unix philosophy, or several things half decently - something like the spread of things like Notion and other one-size-fits-all-problems software. On this specificity spectrum, I&rsquo;d still rather my tools tend towards the &lsquo;one thing very well&rsquo; side - I&rsquo;d like to have the power to do more complex things when I need to rather than be handrailled in. However, the problem with having a wide toolkit of highly specific programs tends to be sprawl, where the programs you need to have open to do one given thing increases as the required functionality gets split across more and more apps. As well, as bemoaned by most of the HCI / developer community, most tools lack a centralized standard, or even expose their internal API, to move information from app to app in a non-manual way. Especially when apps are very seemingly disconnected, requests for connections and integrations are very (understandably) niche, and end up serving only a couple users. Why can&rsquo;t I get a way to move equations between document formats, by, say, exporting a Word equation to clipboard for evaluation in Desmos or Chrome or whatever calculator, and then automatically copying the answer back into my doc? I doubt Word and Desmos / Chrome would ever build a proper two-way integration (rightfully so, but that&rsquo;s besides the point), so I either have to resort to manually repeating things like this, or have to change tools (well, apparently I can evaluate functions in Excel, but that&rsquo;s still a bit of a hurdle).</p>
<p>Maybe it&rsquo;s the influence of HCI Twitter and the amazing tools for thought I&rsquo;ve seen prototypes for on my timeline, but I&rsquo;ve been thinking a lot about a possible ideal mix of all these problem-solving softwares, or at least a combination of features that&rsquo;d personally benefit me best. With the amount of apps and things I&rsquo;ve tried out, I&rsquo;m surprised no one&rsquo;s thought about integrating the best of each of these tools, but hey, &lsquo;software to automatically evaluate and nicely format my equations in a way that&rsquo;s acceptable by my teachers&rsquo; is a pretty niche specification. Consider this thought-chain a speculative dream of what could have been (and hey, what might be, if I ever decide to take a stab at integrations myself one day).</p>
<h2 id="desmos-comes-close">Desmos Comes Close</h2>
<p>I&rsquo;d like start by extolling the virtues of <a href="https://www.desmos.com/">Desmos</a>, specifically focusing on their wonderful graphing calculator. With labels for notes, arbitrary point insertion, variable assignment, and immediate cell evaluation, it&rsquo;s become an invaluable tool, especially for formula- and repetition-heavy work. Though I sort of neglect the graph itself for most of my problem solving (save for in maths), I&rsquo;m pleasantly surprised at how full-featured and flexible the calculator itself is. Returning to the physics workflow example, I can pre-define constants and pre-program common formulas, while keeping changeable variables for mass, velocity, and other values that change between problems. This feature alone has saved so much time - instead of looking back for intermediate values or estimating them and losing precision, I can simply define them and reuse them in future calculations. Because Desmos also calculates the expression value immediately, I can get the convenience of the Chrome omnibar calculator with added annotation and manipulation powers.</p>
<p>Text labels have weirdly helped me think through problems and substitution more effectively than just trying to keep formulas, values, and all the next steps in my head. Part of it is that it&rsquo;s a lot easier to see where you are in a problem when everything&rsquo;s written out, especially when determining next steps. Visually seeing possible substitutions and figuring out what&rsquo;s next is plenty simpler when I&rsquo;m able to view both my notes and the calculations in one place. Previously, when using just Chrome, I&rsquo;d have to tab between calculations and formula notes, and it was honestly an information overload, as I had to keep each tab open to preserve intermediate values and could never find the work I was looking for.</p>
<p>Tables have also been especially useful in chemistry, with all the <a href="https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Supplemental_Modules_(Physical_and_Theoretical_Chemistry)/Equilibria/Le_Chateliers_Principle/Ice_Tables">ICE tables</a> we need to compose for our calculations. Calculating K values is an area where I find I need the guidance and actual visual information of a table, since there are way too many values to tackle to lay one out mentally. They&rsquo;re also super useful for applying formulas to a range of values without having to create a new Excel workbook for a problem that&rsquo;ll take a couple minutes - a past overhead that Desmos now obviates. While these tables are nowhere near as powerful as Excel cells, they&rsquo;re more than enough for calculating intermediate values and sketching out work.</p>
<p>Images, however, is one way Desmos falls short of what I&rsquo;d ideally need. I generally find that I need to diagram things for physics (or, at least, it&rsquo;s good practice), and trying to diagram anything other than a circle or a line is a lot more work than I&rsquo;d like. Sure, I can quickly draw something out in <a href="https://vectr.com">Vectr</a> and upload it, but I often find I&rsquo;d rather just go without and edit an explanation in in post, or forgo the diagram entirely. It&rsquo;s no fault of Desmos&rsquo;s - the entire point of the calculator is that it specializes in graphing and scientific computations, and it&rsquo;s gone above and beyond what I need from it. However, it&rsquo;d be amazing to figure out a way to combine both the power of the calculator and, say, something like Vectr or even a rudimentary version of whiteboard.team. Most of the drawing functions are redundant and overcomplicated, but even a box, circle, line, and arrow set of functions would be amazing. Oh well - it&rsquo;s outside of the scope or purpose of Desmos anyways.</p>
<h2 id="free-form-structure">Free-form Structure</h2>
<p>I find that my work in solving these science problems feels sort of like sketching, albeit perhaps on a digital canvas, rather than physical paper. When I&rsquo;m trying to work at my speed of thought, the most friction-free experience is generally with text, but diagrams and laying things out spatially can help sort out how to manipulate the formulas and such. I use the term manipulate, since it really does feel like you&rsquo;re slotting things in and moving terms around.</p>
<p>Highly limiting mediums like ASCII take away the aesthetics side of things, where I almost feel like I <em>need</em> to make something pretty and presentable. However, I generally don&rsquo;t want to make diagrams in ASCII, especially when there are more abstract shapes and arrows to work with (physics won&rsquo;t work, though chemistry might, since it&rsquo;s more text heavy) Especially when using more rudimentary tools that impose a certain structure, it feels that tools are pushing you against the decision paralysis presented by more complex and full-featured tools. That&rsquo;s why I tend towards quick scrawling even when solving problems - I&rsquo;d rather check that I can understand and produce the answer, rather than fuss over how to get a subscript in another subscript<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Tools like Vectr are great for producing more polished drawings, but I end up spending much too long fiddling with fonts to get everything on a page to look nice and cohesive. whiteboard.team&rsquo;s sketching tools are quicker to work with, and while everything comes out looking a bit like an MS Paint attempt at modern art, it works for sorting the problem out quickly.</p>
<p>I guess this sort of touches on the presentation side of things, and the purpose of whatever I&rsquo;m sketchnoting. If it&rsquo;s something just for me, scribbling down a couple boxes with unlabelled arrows is generally enough for me to get the gist of what I need to do. However, if (like in the scenario I shard in the introduction) it&rsquo;s something I need to present for marks, I&rsquo;ll put more effort in. This &lsquo;effort spectrum&rsquo; is something that sort of changes the given toolkit I use for a given purpose.</p>
<h2 id="but-also-compatibility">But also, compatibility</h2>
<p>Speaking of changing the tools I use for a given purpose, I also have a minor point with file formats and such. Word, at least in my program, is the de-facto standard for documents and homework, so I&rsquo;m required to work with .docx files - even if I don&rsquo;t have to directly edit in Word, I need to produce something Word-parseable in the end<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Working with Word equations is not that painful of an experience - while my classmates seems to collectively agree that handwriting chemistry equations is much easier than typing them out, I find that working with digital equations is as fast as and as convenient as working on paper. Perhaps it&rsquo;s just a matter of medium preference.</p>
<p>However, one thing that I definitely find tedious is editing equations and working with calculations in the same workflow. When building a lab report, for example, I have plenty of sample calculations to transcribe, and generally data points for these equations source directly from raw data. I usually keep a separate Excel sheet with formulas I can easily drag around and apply to groups of cells, but it&rsquo;s a pain to try to copy around end values and work with calculations within Word itself. If I&rsquo;m not Excel-ing things, I keep a Chrome window open, and it&rsquo;s sort of frustrating to jump around to do calculations. It also introduces a new surface for error - I don&rsquo;t want to talk about the number of times I&rsquo;ve mispasted a value or missed an exponent by one.</p>
<p>It&rsquo;s relatively painless to fix things up if this wrong value happens at the end of a calculation, but when it&rsquo;s an intermediate value that other calculations depend on, reworking all my equations is an especially tedious task. This is when I tend to crave the variable recalculation abilities of Desmos, which immediately redoes all depending calculations, and Excel, where I can use cell references to keep values &lsquo;bound together&rsquo;. LibreOffice (/ Word) seems to have a variable function to define numbers and reuse them in the document, but I haven&rsquo;t found a way to run formulas on them, or integrate them in equation blocks.</p>
<p>I don&rsquo;t think it&rsquo;s worth making a point of introducing a new file standard for something like this (<a href="https://xkcd.com/927/">relevant XKCD</a>), and I also don&rsquo;t think it&rsquo;s worth bothering to ask if I can submit in a PDF or whatever quirky file format an &lsquo;ideal&rsquo; software would kick back. I wouldn&rsquo;t mind having to work with an intermediate file format, as long as it&rsquo;s fully integrated and exportable to Word (or LaTeX). I think these are pretty lofty goals, however, so I think I&rsquo;ll just have to live with the monotony of redoing a full set of equations four times over because I accidentally messed up in the first two sections - but that&rsquo;s a story for another day.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Whenever I&rsquo;m using only one of the above tools, it feels like I&rsquo;m missing something. With Word, I wish I&rsquo;d be able to calculate and substitute variables in equation blocks themselves. With Desmos, I lack the image and diagram manipulation features that help visualize problems at times. With whiteboard and other diagramming software, I lack the ability to format and present my work later, and also don&rsquo;t get any of the variable manipulation that streamlines my entire calculation workflow. I think my ideal scientific problem-solving software would be something like a combination of:</p>
<ul>
<li>Desmos&rsquo;s variable system and instant calculations</li>
<li>whiteboard.team&rsquo;s / Vectr&rsquo;s diagramming capabilities</li>
<li>Word&rsquo;s layouting, formatting, and text hiding, and</li>
<li>(maybe, would be nice to have) Vim&rsquo;s keyboard-driven philosophy</li>
</ul>
<p>I could replicate several parts of this system on physical paper, but again, I&rsquo;d be losing out on the variable calculation and the digitization aspects of my workflow. For me, it&rsquo;s also a lot easier to type things out, both in terms of remembering the solution work and efficiency (I type much more quickly than I can write). I&rsquo;d also prefer to figure out a toolkit digitally that can continue to work in the future, if the digital aspect does end up being a requirement sometime in university.</p>
<p>In terms of developing things like this, I&rsquo;m not entirely sure, but it might be possible to wire together Word extensions, a Desmos API, and some sort of diagramming API to make inserting and formatting work into Word more streamlined - I haven&rsquo;t done much research into the possibility. I think this might have something to do with the whole <a href="https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html">Bring Your Own Client</a> idea, where there&rsquo;s a need for more software to open up to remixing and inter-app data flow first. I&rsquo;d like to investigate possibilities and other tools that&rsquo;re easier to mix together in the future as well, especially tools that are simpler and more text-based. Developing a toolkit for scrap work and raw calculations is still a higher priority for me than Word integrations, but the whole file format thing is still a struggle, especially since most of the work I do is for school, and I need to follow assignment requirements.</p>
<p>I&rsquo;ve been putting off writing this post for a while, and I think I&rsquo;ve sort of lost the rhythm of writing weekly. Part of it is the homework (that they <em>did</em> say was supposed to decrease roundabout now, but oh well), and part of it was a lack of coherent thoughts. I&rsquo;ve went back and built a list of some ideas for future posts just now, so hopefully I&rsquo;ll be able to get back to writing more regularly. It&rsquo;s interesting how writing and outlining something like this sort of cements all the ideas and makes it clear what I personally think, so I guess that&rsquo;s a nice hidden benefit of writing. Writing this post actually inspired a different one that might come out in the near future, but we&rsquo;ll see how much time I have with school and such.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I use LibreOffice, since booting back to Windows is too much effort to bother with on a regular basis, and Word on Wine was both a pain to set up and to work with, so some of the instructions for Word didn&rsquo;t apply. In the end, apparently you&rsquo;re supposed to wrap the part of the equation to subscript with a set of curly braces. You can then apparently nest to whatever depth you&rsquo;d like to - a bit of a late discovery, but hey, late&rsquo;s better than never.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Apparently this changes to LaTeX in university, so there&rsquo;s something else to consider.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Weeks 9 and 10</title>
      <link>https://kewbi.sh/blog/posts/210418/</link>
      <pubDate>18 Apr 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On generative struggles and accumulators.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Last week, I think I predicted that these couple weeks would be some of the hardest so far in the course, and I think I wasn&rsquo;t far off. The lab and problem set for week 9 were especially difficult - it seemed to be very much a &lsquo;it&rsquo;s a matter of thinking&rsquo; type of problem. Generative search and this type of recursion are techniques I haven&rsquo;t even touched outside of Racket, so I think the lack of experience definitely didn&rsquo;t help, as well as my not understanding the problem half the time. Week 10&rsquo;s work wasn&rsquo;t much better - I&rsquo;m still working through the lab and problem set as of now. However, I feel like Week 10 &lsquo;clicks&rsquo; more than Week 9, but maybe that&rsquo;s just because Week 9 had a large problem example instead of smaller, more digestible ones. However, going through the practise problems and solutions has been helping, and I&rsquo;ve really learned that you cannot rush it - taking my time to work through problems fully has been a lot more helpful than trying to speedrun a couple easy check-expect cases.</p>
<p>As with every other CPSC 110 post, if you&rsquo;re not doing the course or don&rsquo;t have the very niche interest of tackling aforementioned generative recursion and accumulators, this is the part where you might want to go read one of my other posts. I promise there&rsquo;s some interesting thoughts somewhere in my post history, so feel free to go check those out instead.</p>
<h2 id="notes---week-9">Notes - Week 9</h2>
<p>This week covers generative recursion, and applies it to backtracking search, a method of search that generates all possible permutations of a problem in a tree before eliminating invalid ones.</p>
<ul>
<li>generative recursion differs from previous structural recursion =&gt; instead of taking a sub-piece of data as argument to next call, we now generate entirely new data to call
<ul>
<li>fractals are a good example of this =&gt; layering images onto each other</li>
</ul>
</li>
<li>use the HtDF recipe for generative recursion =&gt; instead of an empty case, we have a trivial case and a non-trivial generative case
<ul>
<li>generally nest images around other recursive cases, instead of only having a recursive expression</li>
<li>base case for generative recursive check-expect is the case that doesn&rsquo;t recurse anymore =&gt; set a cutoff constant
<ul>
<li>next ones can be those that do recurse (generally one or two &lsquo;steps&rsquo;)</li>
</ul>
</li>
<li>can use locals to avoid redundant competition (i.e. when multiple recursive areas or multiple of the same nonrecursive cases)</li>
<li>can re-call the recursive function =&gt; make sure to operate on the arguments (generally for side length)</li>
</ul>
</li>
<li>can&rsquo;t count on type comment rules to determine that the recursion will end =&gt; halting problem
<ul>
<li>need to use our own proofs: three-part system of base case, reduction steps, and halting or termination argument
<ul>
<li>base case is the trivial question expression in the cond</li>
<li>reduction step is the, well, reduction of the expression argument</li>
<li>then use logic to state an argument that repeating the reduction will eventually reach the base case</li>
</ul>
</li>
</ul>
</li>
<li>use lambda (λ) expressions to avoid having to create a whole local function =&gt; anonymous function
<ul>
<li>only use in place of expressions that will only be used once =&gt; like Python lambdas</li>
<li>ensure the body is easily understood and that the naming adds nothing to its comprehension</li>
<li>format: <code>(λ (n) (&gt; n 5))</code> where the n expression is the list of other expressions</li>
</ul>
</li>
<li>backtracking search is composed of several parts =&gt; structural recursion for the tree structure, and handling function composition
<ul>
<li>use the HtDF backtracking search template =&gt; use local functions to nest all required functions in a single expression</li>
<li>two main parts =&gt; the &lsquo;trivial&rsquo; or success case, and the subs, or the descendents case</li>
<li>descendents generally requires a couple helper functions =&gt; break the problem down into several smaller steps to solve with function composition, abstract builtins, or other methods</li>
</ul>
</li>
</ul>
<h2 id="notes---week-10">Notes - Week 10</h2>
<p>Week 10 deels with accumulators, a new technique used to preserve context that&rsquo;s often lost in recursive functions.</p>
<ul>
<li>structural recursion templates are very powerful =&gt; easy to abstract upon
<ul>
<li>however, cannot see &lsquo;where&rsquo; they are in a data structure</li>
<li>cannot preserve past-touched data, or accumulate data to add to future computations</li>
</ul>
</li>
<li>context preserving accumulator =&gt; brings data from parent/child or keeps track of other values that need to stay constant within a sub-traversal
<ul>
<li>wrap the function body in a local expression and add a trampoline with a base accumulator</li>
<li>add an argument to the inner functions</li>
<li>the context preserving accumulator changes every step depending on the fn behaviour</li>
<li>add parameter to where it might be used in a function</li>
</ul>
</li>
<li>also introduces the concept of tail recursion =&gt; any recursion placed in the last expression position in function, not wrapped in anything
<ul>
<li>reduces the problem where many sub-expressions are created before reducing the answer</li>
<li>optimized in many languages, including Racket</li>
<li>instead of a context-preserving accumulator, now a result-so-far accumulator is introduced
<ul>
<li>represents the built-up information (such as the sum function)</li>
<li>generally used to produce tail-recursive functions instead of cons-ing infinitely</li>
</ul>
</li>
</ul>
</li>
<li>third accumulator type is the worklist, where you consistently build onto a list that&rsquo;s called each function iteration
<ul>
<li>run the mutually recursive list function on the todo worklist instead
<ul>
<li>take the first of the worklist and operate on it, then if using another accumulator attach to that</li>
</ul>
</li>
<li>used often when operating on data with more than one graph cycle =&gt; arbitrary arity trees with tail-recursion</li>
</ul>
</li>
<li>general accumulator advice
<ul>
<li>when writing accumulators, ensure a base accumulator is set in the trampoline =&gt; empty, 0, depends on function behaviour</li>
<li>to debug accumulators, draw out an example of a call tree including the arguments and how they&rsquo;re expected to be operated on</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Only a couple modules left - though those might take a while to get through, given that they&rsquo;re the last, and probably most difficult sections of the entire course. I foresee a lot of cross-module work, as well as more complex program design. I&rsquo;m looking forward to tackling it, but a bit hesitant to find out what &lsquo;graphs&rsquo; and &lsquo;mutation&rsquo; are supposed to mean<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I&rsquo;m still on track to finishing CPSC 110 well before summer break, but I think I might have to take things a little slower given with how school&rsquo;s going. Perhaps more consistent but less intense work with the course will be more effective, anyways?</p>
<p>I haven&rsquo;t found the time to write a proper post in a while, but I think it&rsquo;s high time I went back to more regular posts - I have a list of pretty viable ideas that I&rsquo;d like to expand more on, and maybe a couple addendums and things to other posts that I might update. YK was started as half a joke, but I think it&rsquo;s become more a place to swirl thoughts together and hypothesize about the very niche things I&rsquo;m into. I don&rsquo;t think my posting style&rsquo;d fit in more micro-blog formats, so I plan on continuing to tend this digital garden (hey, am I trendy now?) for a very long time - and that means keeping my consistently posting schedule. I got a bit lax in the past month - while my very rigid posting schedule maybe wasn&rsquo;t the best for quality in 2020, it did incentivize me to stick to it, and at least put something out. Anyways, I hope I&rsquo;ll manage to edit up my latest post and have it up soon, and follow it up with a bunch of other thoughtchains. We&rsquo;ll see<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Did Kiczales intentionally name the last couple units the most vaguely just to add to the mystique?&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Also, if you&rsquo;ve read this far, it probably means that you&rsquo;re one of the few people that I talk to regularly and hey, if you unironically check the footnotes, I think I can trust y&rsquo;all enough. (Please don&rsquo;t spill to others though, at least since I&rsquo;m theoretically not supposed to talk about this yet.) So - life update! I made it into UBC, which still hasn&rsquo;t entirely hit. It&rsquo;s absolutely crazy that I&rsquo;ve got here, and at 15, too. (Not to mention the very spicy Schulich Leader scholarship - still kinda in shock.) 2020 and 2021 so far have been absolute rollercoasters, but hey, with GCI, GfTW, and now this - it&rsquo;s definitely been worth it.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Weeks 7 and 8</title>
      <link>https://kewbi.sh/blog/posts/210411/</link>
      <pubDate>11 Apr 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On local expressions and built-in abstractions.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>A couple weeks ago, I predicted that my CPSC 110 sprint was probably going to peter out, and would you look at that - I was somewhat right. A combination of school restarting, lots of homework to catch up on, and a general procrastination of writing anything all led to me sort of conveniently forgetting to go through a couple videos a day. It was also convenient that these couple of modules are starting to pick up in difficulty, and are generally the points where people start crying for help on the Piazza (or so I&rsquo;ve been told). All in all, I&rsquo;d definitely put off writing notes for the last few modules I&rsquo;ve completed until today, so I suppose here&rsquo;s a good place to start.</p>
<p>Local expressions and the section on one-of types were surprisingly comprehensible - I&rsquo;ve always admired how systematically this course builds on past material, but I suppose there&rsquo;s a reason why the course name is &lsquo;Systematic Program Design&rsquo;. Week 8&rsquo;s module on built-in abstractions was also relatively easy to understand - drawing on past experience with similar functions and styles in Python and especially Javascript definitely helped.</p>
<p>I think I&rsquo;ve said this something like five times before, but as always, you&rsquo;ll probably be very confused and disinterested in the contents of this article unless you&rsquo;re taking CPSC 110, or somehow have stumbled upon this in the interest of learning Racket (it&rsquo;s an experience). I&rsquo;ve put up the notes for the rest of the course up til this point in the posts preceding, so if you are indeed interested, <a href="https://kewbi.sh/blog/posts/">check those out</a>.</p>
<h2 id="notes---week-7">Notes - Week 7</h2>
<p>Week 7 discusses two one-of types (the cross product table), and local expressions.</p>
<ul>
<li>when a function&rsquo;s arguments have more than one type with one-of type comments, use cross product table to determine which cases to handle
<ul>
<li>design function based on model of function instead</li>
<li>create a table with the one of possibilities for type a horizontally, and possibilities for type b vertically
<ul>
<li>will have a box per case, which you can fill in with the desired behaviour for each case</li>
<li>often, can condense boxes that are next to each other and have the same behaviour (<code>#t</code>/<code>#f</code> cases)</li>
<li>collect into a <code>(cond)</code> expression</li>
</ul>
</li>
<li>helps with determining what to test =&gt; at least one per case in the <code>(cond)</code></li>
</ul>
</li>
<li>with more difficult behaviours =&gt; remember to keep natural recursion
<ul>
<li>even if this is a branching statement, keep in one <code>(cond)</code> QA pair</li>
<li>keep self-reference applying to the rest of the list (if it&rsquo;s one)</li>
</ul>
</li>
<li>we&rsquo;ve graduated to ISL =&gt; intermediate student language
<ul>
<li>one of its new feature is local expressions =&gt; function and variable definitions within a larger definition</li>
</ul>
</li>
<li>local expressions nest into another definition =&gt; <code>(local [(define x a)] (expression))</code>
<ul>
<li>any number of function or variable definitions are allowed =&gt; override any definitions outside of the local at top level</li>
<li>expression is evaluated to produce the result of the local</li>
<li>these local variables do not exist outside of the local =&gt; lexical scoping
<ul>
<li>definitions that exist at the top level are in the global scope</li>
<li>scope contours show where functions and variables are defined and redefined =&gt; like nesting boxes that only take the most specific one</li>
<li>definitions reference the innermost enclosing box =&gt; defaulting to top level</li>
</ul>
</li>
</ul>
</li>
<li>to evaluate local functions, use a method of renaming and lifting
<ul>
<li>combining all the rules previously learned =&gt; first start by substituting variables outside local as normal</li>
<li>then rename all local&rsquo;s references to a program-unique name</li>
<li>then lift the renamed definition into top level / global scope</li>
<li>then replace the local with a body expression</li>
<li>then replace any renamed definitions within the local with their values</li>
</ul>
</li>
<li>local expressions are used to encapsulate the ugly mutual reference functions, as well as prevent recomputing in recursive functions
<ul>
<li>encapsulation helps avoid practically, naming problems, and helps decomplicate the rest of the program
<ul>
<li>wrap the two mutually referential functions into a local definition, and run only one of the functions in the local expression (single)</li>
<li>delete all tests that reference the other definition (list), and rename the rest of the lists</li>
<li>can pre-encapsulate within the template, moving the same two function templates within a data definition&rsquo;s template</li>
</ul>
</li>
<li>in recursive functions, the time to evaluate a function rapidly increases =&gt; exponential
<ul>
<li>to avoid this, we wrap recursive function calls that are repeated in a local definition</li>
<li>look for the closest expression that wraps the function calls, and replace with pre-computed values =&gt; only compute these once, saving time</li>
<li>rename each of the function calls to the local definitions</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="notes---week-8">Notes - Week 8</h2>
<p>This week deals with using Racket&rsquo;s built-in abstract functions and creating your own. (Starting to get into things that are more closely related to what you stereotypically think of as functional programming.)</p>
<ul>
<li>abstraction helps reduce the amount of repetition in code, especially from templates that are very similar to each other
<ul>
<li>use function definitions to plug into other generalized function =&gt; more abstract fns</li>
</ul>
</li>
<li>basic example of abstraction =&gt; take several functions that are very similar, and make one generalized function that takes only the differing points as arguments
<ul>
<li>because most functions are directly based off templates =&gt; not much change between functions if same types and signature</li>
<li>add the check-expects for each function to the generalized function check-expects</li>
<li>add each argument to the check-expects and each function</li>
<li>edit the body of each function to make a call to the generalized function with its specialized predicate / differing points</li>
<li>purpose can just generalize to the main function</li>
<li>called higher-order functions =&gt; fns that call other functions</li>
</ul>
</li>
<li>signature and type notation is now changing =&gt; type inference
<ul>
<li>look at each argument =&gt; if it&rsquo;s a function that can apply to any types, instead of denoting the types that it uses, use abstract letters like X and Y
<ul>
<li>each function needs to be in parentheses =&gt; something like <code>(X =&gt; Boolean)</code></li>
</ul>
</li>
<li>look at argument functions that take in the same types, or produce the same types</li>
<li>also, can now use the <code>(listof X)</code> shorthand to avoid having to produce a data definition for the lists</li>
</ul>
</li>
<li>Racket also has a large number of built-in abstract functions:
<ul>
<li>check the type to input and the type to output, then find the corresponding function in the list below ⇓</li>
<li>build-list: <code>Natural =&gt; (listof X)</code></li>
<li>filter: <code>(listof X) =&gt; (listof X)</code></li>
<li>map: <code>(listof X) =&gt; (listof Y)</code></li>
<li>andmap: <code>(listof X) =&gt; Boolean</code></li>
<li>foldr (and foldl): <code>(listof X) =&gt; Y</code>
<ul>
<li>call with a function, a base case, and a list to operate on =&gt; similar to the list template</li>
</ul>
</li>
<li>can use these to form larger functions without all the template work</li>
</ul>
</li>
<li>closures =&gt; when a function requires access to a parameter part of the larger function =&gt; use local
<ul>
<li>for example, in a function with arguments x and fn1, where fn1 needs access to x</li>
<li>only passes one argument =&gt; unlike writing your own fold function where you have to pass all arguments</li>
</ul>
</li>
<li>produce your own fold functions from the template =&gt; abstract with each base case and function argument as an argument
<ul>
<li>in functions that you pass, then have to specify with all arguments of struct members</li>
<li>forex: fn1 that operates on an image takes two arguments now, not one like in closures</li>
<li>generally compose your own local functions to use in the fold function</li>
<li>can check like most other functions =&gt; just copy paste the check-expects over, wrapping functions as needed in local expressions</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>As of writing this conclusion, I&rsquo;ve actually managed to go through module 9 as well, so we&rsquo;ll see if I can manage to publish those notes soon as well. I can definitely see the course starting to ramp up in difficulty, but I think the design problems are a nice challenge, aside from the mundanity that can sometimes be trying to write check-expects and follow templates to a T. As I look back on each module, I&rsquo;m surprised to see how clear everything actually is - the first time round, everything certainly seemed a lot more difficult. I guess I&rsquo;ve just found that it really is impossible to try to rush through things, even the dull humdrum of copy-pasting stubs and templates and such. I&rsquo;m excited to see what the later couple weeks have in store, especially in terms of this magic they call &lsquo;functional programming&rsquo;.</p>
<p>I&rsquo;m also looking forward to making some more good progress before summer break, and seeing when I can finish the bulk of the course. I have several more modules left, but after that, I think I can start devoting more time to completing more start-to-end problems and tackling the practise finals from past years. Hopefully, I&rsquo;ll be able to finish up the course by June, though I genuinely don&rsquo;t know what else&rsquo;ll come up with school. I think I&rsquo;ve generally settled on challenging in September instead of the summer, which should give me some more time to prepare, and might hopefully lift a bit of the courseload (if I do manage to pass the challenge) in my first semester. I think I&rsquo;m well on track to this, and I&rsquo;m happy to start applying some of the more fun theoretical techniques to problems.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Weeks 5 and 6</title>
      <link>https://kewbi.sh/blog/posts/210328/</link>
      <pubDate>28 Mar 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On helpers and binary search trees.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Spring break is almost over, and perhaps so is my CPSC 110 sprint. For a lack of creative inspiration to work on anything other than practise problems, I&rsquo;ve been spending a good amount of my remaining break on very routine homework, including CPSC 110. The course&rsquo;s started to delve further into the theory side of things this couple weeks, and it&rsquo;s been very interesting to see how my methods for designing things in Racket have evolved with each successive module.</p>
<p>Part of me being able to complete a rather surprising (to me, at least) number of weeks over a short amount of calendar weeks was conveniently forgetting to do both the problem sets or labs for the past couple weeks. I&rsquo;d become part of my habit to do those after writing up a week&rsquo;s set of notes, but I think I got a bit too carried away somewhere in between weeks. In the process of having to go back and do said problem sets and labs, it was interesting to see how difficult it was to remember what techniques I was &lsquo;allowed&rsquo; to use. Somewhere between 6 and 7, some template rules get changed, and some shorthand is now added, which I almost reflexively tried to use before realizing I was supposed to operate in on a past set of guidelines while looking at problem set solutions. It&rsquo;s remarkable that I even forgot that there was a change in shorthand allowed - I think that&rsquo;s part of what makes CPSC 110 one of those fundamental courses: it encourages you to look at things very systematically, and builds on what you&rsquo;re supposed to do systematically, systematically. (In other words, the addition of new parts of information follows nicely from past weeks, and everything is consistent.)</p>
<p>As always, you&rsquo;re probably uninterested in the contents of this post unless you&rsquo;re taking CPSC 110 yourself or have the very niche interest of learning how to program in Racket. Feel free to check out some of my other posts (I promise I don&rsquo;t blather on about Racket this frequently usually, but Spring Break sort of encouraged me to do as much CPSC 110 as I could).</p>
<h2 id="notes---week-5">Notes - Week 5</h2>
<p>This week dealt with helper function design, as well as more information on inbuilt natural number functions.</p>
<ul>
<li>natural numbers are good to illustrate examples of self-referential data definitions
<ul>
<li>unlike lists, don&rsquo;t need to cons at all
<ul>
<li>the one off statement is either zero or <code>(add1 n)</code> =&gt; why it presents recursion</li>
</ul>
</li>
<li>use <code>(add1 n)</code> to add 1 to a number and <code>(sub1 n)</code> to subtract 1 =&gt; useful for recursion</li>
<li>add n to the template =&gt; easier to work with contribution of first rule</li>
</ul>
</li>
<li>function decomposition =&gt; breaking design problems down to one atomic purpose
<ul>
<li>in past weeks, we&rsquo;ve added helper functions: this week dives further into when to add them and how to do so</li>
</ul>
</li>
<li>places to put helper functions:
<ul>
<li>where there&rsquo;s a reference =&gt; natural place to insert a helper function
<ul>
<li>world design recipe =&gt; also using helpers</li>
<li>where types of what you&rsquo;re operating really changes</li>
</ul>
</li>
<li>when an expression operates on a list =&gt; arbitrarily far into the list
<ul>
<li>because this is a form of recursion</li>
</ul>
</li>
<li>when a function shifts into a new knowledge domain
<ul>
<li>knowledge domain =&gt; when you need to operate on a new facet of the data, or change what you need to &lsquo;know&rsquo;</li>
</ul>
</li>
</ul>
</li>
<li>essentially breaking everything down into individual steps for the problem =&gt; can begin seeing this in the <code>(check-expects)</code>
<ul>
<li>sometimes avoid referring to constants in these to fully illustrate the example</li>
<li>function composition only needs to test the composition
<ul>
<li>no need to deal with base case</li>
<li>can essentially test the two only together and call function in the check-expect</li>
<li>make it as obvious as possible if something&rsquo;s gone wrong</li>
</ul>
</li>
<li>work systematically referencing the wishlist as a todo list</li>
</ul>
</li>
</ul>
<h2 id="notes---week-6">Notes - Week 6</h2>
<p>This week describes binary search trees, as well as mutually referential data.</p>
<ul>
<li>have now graduated to BSL with List Abbreviations =&gt; use <code>(list 1 2 3)</code> to declare a list without all the <code>(cons)</code>s
<ul>
<li>if <code>(cons)</code> is applied to a list, concatenates it to the beginning</li>
<li><code>(append l1 l2)</code> takes two lists (not elements), and appends l2 to l1 so the list is flattened into <code>(list [elements of l1] [elements of l2])</code>
<ul>
<li>if you instead run list (or cons) on the two lists, you get a list containing two lists (not flattened, and with 1 list for <code>(cons)</code>)</li>
</ul>
</li>
</ul>
</li>
<li>here, we could use a self-referential data definition to create a list of any given element =&gt; concatenating an element onto the self-referential data def
<ul>
<li>can sort the list and use <code>(first)</code> and <code>(rest)</code> to traverse the list in order of magnitude
<ul>
<li>on average, n/2 elements searched</li>
</ul>
</li>
<li>however, faster on average to use a binary search tree, where elements are ordered on branches
<ul>
<li>middle value goes on the &lsquo;top&rsquo; of any given fractal part of the tree</li>
<li>smaller values go on the left, larger values go on the right =&gt; of a given element</li>
<li>balance the tree (shift things around) if it&rsquo;s looking sort of like a list =&gt; at that point you have no advantage</li>
</ul>
</li>
</ul>
</li>
<li>BST data definition utilizes compound data definitions with 2 self-reference cycles
<ul>
<li>create a struct with fields for BSTs for both left and right branches stemming from the given element
<ul>
<li>specify invariant rule =&gt; right/left interpretations</li>
</ul>
</li>
<li>run <code>(fn-for-bst)</code> on each self-reference =&gt; natural recursion</li>
<li>rendering BSTs =&gt; also with recursion
<ul>
<li>for the check-expects, remember to order according to test &lsquo;difficulty&rsquo; and test each case (right/left to right/left)</li>
</ul>
</li>
</ul>
</li>
<li>searching BSTs is a matter of determining whether the searched-for value is greater than, equal to, or less than the current node
<ul>
<li>then traverse either the left or right BSTs depending on above condition</li>
</ul>
</li>
<li>arbitrary arity tree =&gt; form of data that&rsquo;s arbitrarily large in two dimensions
<ul>
<li>arbitrary (as in length, can be an unspecified number of elements long), arity =&gt; arbitrarily long in two dimensions (folder =&gt; file)</li>
<li>to deal with these two dimensions, will need 2 cycles in type reference graph
<ul>
<li>generally have a data definition for an element, and one for its listofelement =&gt; use arbitrary data definition template</li>
<li>these two data definitions refer to each other =&gt; Element has a &lsquo;children&rsquo; field that refers to its list, and ListOfElement refers to Element in its <code>(cons)</code> branch of the one-of</li>
<li>known as mutual reference</li>
<li>reference arrows =&gt; describe mutual ref, then self ref, then find the normal ref</li>
</ul>
</li>
</ul>
</li>
<li>mutual reference template involves two HtDF problems, one of each type
<ul>
<li>name them with <code>([fn]--element)</code> and <code>([fn]--loe)</code>, or similar</li>
<li>at the points with a reference to the other type of mutual reference =&gt; insert a natural mutual reference recursion helper</li>
<li>test the base case (may not be the element case that&rsquo;s the simplest)
<ul>
<li>base case is the case in which no mutual reference is invoked =&gt; generally the empty or false of the LOE type</li>
<li>use <code>(check-expect)</code>s to clarify what the expected output will be</li>
</ul>
</li>
<li>usually, both functions produce the same type of data in the end</li>
</ul>
</li>
<li>backtracking search =&gt; use special signature of <code>[type] or [base]</code>
<ul>
<li>usually would be using something like an exception, except BSL doesn&rsquo;t have those</li>
<li>search for the desired value in all children, if not, runs on all siblings as well
<ul>
<li>if it produces false =&gt; check the siblings / rest of the LOE</li>
<li>use the <code>(if (not (false? (fn-for-loe))))</code> to check above condition</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>I&rsquo;ll save the notes for Week 7 for the next week I&rsquo;m looking for something share - I&rsquo;d rather keep the amount of double-weeks to a minimum. (I also doubt there&rsquo;ll be many more double weeks, since school&rsquo;s started again.) I&rsquo;m now past the midway point and on a good streak of work, so I hope I&rsquo;ll be able to finish the course well before school ends in June. I plan to spend some of the summer revising for the challenge before I actually take it, which I hope will be enough time. I&rsquo;ve looked at past exam papers, and they don&rsquo;t seem too bad at first glance, so let&rsquo;s hope a couple months of review is enough.</p>
<p>In other news, I helped run a hackathon this weekend, which was an amazing experience. <a href="https://vhhacks.ca">vhHacks 2021</a> was a super fun event to organize, mentor, judge, and run workshops for, and I was incredibly impressed at everything that was submitted (so congrats!). The majority of hackathon-esque events I&rsquo;ve been to have been online, which is usually something people label as &lsquo;unfortunate&rsquo;, but to be honest, there&rsquo;s something sort of nice about async hackathons and weekends spent grinding away alone at a project in the comfort of your office. I hope some of the wholesome hacker vibe that I personally got at my first online hackathon was successfully transmitted somewhere in the process, and that, most of all, it was fun<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I might write a bit about organizing the hackathon (not that I know what to write about regarding the entire event) in the future, but for now, I&rsquo;ll go back to catching up on problem sets and labs.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Preliminary survey results with people I know has been positive, but I&rsquo;m entirely sure they&rsquo;re biased and at least 50% trying to validate me, which is still much appreciated.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Weeks 3 and 4</title>
      <link>https://kewbi.sh/blog/posts/210314/</link>
      <pubDate>14 Mar 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On trusting the natural recursion.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Spring break has just begun, and I&rsquo;ve decided to devote some more significant time to CPSC 110. It helps that I&rsquo;m sort of floating between projects and want a bit of bland coursework to churn through at the moment, so I&rsquo;ve been spending my leisure time listening to Kiczales go on about data and recursion. I&rsquo;ve been ramping up my progress with CPSC 110 for the last couple weeks, and I&rsquo;ve managed to do a couple &lsquo;weeks&rsquo;, or modules, since I last published a set of notes. Regarding my old end date goal, I&rsquo;ve decided to shift my goal more towards a September challenge (of the exam), to give myself time over the summer to cram and practise with old papers. (Ironically, I&rsquo;d also decided at the beginning of the year that I&rsquo;d take this summer to rest and relax before university, but I suppose that&rsquo;s gone out the window in lieu of some hopefully more engaging plans. And hey, if I choose to relax that way, I guess it&rsquo;s a perfectly fine thing to do.)</p>
<p>After getting back in the swing of Racket and relearning the templates and design recipes, these couple modules haven&rsquo;t been too challenging. Adding systematically onto the recipes makes the logical jumps between concepts less sharp, and makes the course much less intimidating. Having a repository and tracking my progress with the course has definitely motivated me to work on it more. So, here&rsquo;s a couple modules' worth of notes - but as always, if you&rsquo;re not following along with CPSC 110 or have no interest in learning about compound and arbitrarily long data, you might want to go off and read a <a href="https://kewbi.sh/blog/posts/210307/">different post</a>.</p>
<h2 id="notes---week-3">Notes - Week 3</h2>
<p>Week 3 goes over how to define compound data (essentially adding structs to the data definition recipe), and integrates that data in building &lsquo;worlds&rsquo;, or GUI programs. Having a proper definition for data simplifies things in future weeks, and makes the data definitions seem more solid or &lsquo;real&rsquo;, in my opinion.</p>
<ul>
<li>ticks =&gt; update behaviour, but can be changed by interactive input
<ul>
<li>tick rate is defined by the program, can change</li>
<li>can use a data definition to interpret the current state</li>
</ul>
</li>
<li><code>(big-bang)</code> function used to make these graphical programs =&gt; called worlds
<ul>
<li>import <code>(2htdp/image)</code> and <code>(2htdp/universe)</code></li>
<li>use <code>(place-image)</code> and the <code>(empty-scene)</code> frequently to draw and render</li>
<li>rendering is done by setting the <code>(to-draw)</code>, and tick behaviour by <code>(on-tick)</code>
<ul>
<li>later use <code>(on-key)</code> and <code>(on-mouse)</code> to handle those behaviours</li>
</ul>
</li>
</ul>
</li>
<li>start by doing a domain analysis =&gt; what remains constant and what changes each tick
<ul>
<li>each function is first wish-listed as the overall world is structured</li>
<li>apply HtDD to design the program state data =&gt; structs in second half of week</li>
<li>apply standard HtDF to create functions used in big-bang</li>
<li>use constants in the <code>(check-expect)</code>s to maximize adaptability</li>
</ul>
</li>
<li>use <code>(define-struct name (args))</code> to define compound data =&gt; data that relate to each other
<ul>
<li>when expression run, generates the <code>(name?)</code>, <code>(name-args)</code>, and <code>(make-name)</code> operators</li>
<li>in HtDD example definitions and tests =&gt; now have to use <code>(make-name (args))</code>
<ul>
<li>include the data types here and intervals if using Naturals or Numbers</li>
</ul>
</li>
<li>need to add interpretation for data types with the <code>;; Name is ...</code> comment</li>
<li>add interpretation for each field in HtDD interpretation comment</li>
<li>HtDD <code>(fn-for-name)</code> now includes each of the fields used in the args</li>
<li>include number of fields with the compound keyword when listing template rules used</li>
<li>when using HtDF =&gt; add constraints and notes in the tests =&gt; clarity of examples and behaviour</li>
</ul>
</li>
<li><code>(on-mouse)</code> and the <code>(on-key)</code> events are handled with an overall cond
<ul>
<li>will take mouse event / key event as argument</li>
<li>need to check the state / key with <code>string=?</code> or <code>key=?</code></li>
</ul>
</li>
<li>use helper functions where possible to ensure function does one thing</li>
</ul>
<h2 id="notes---week-4">Notes - Week 4</h2>
<p>In Week 4, Kiczales discusses arbitrarily sized data, which is basically a convoluted way of working with lists. This week also has to deal a lot with recursion, which is something I&rsquo;ve sort of avoided as much as possible in the past. However, it&rsquo;s been pretty interesting to see how to solve problems recursively, which I think will come in handy down the line.</p>
<ul>
<li>we use recursive data definitions to model arbitrarily sized data =&gt; compound data
<ul>
<li>set a base case (empty, or false), as well as <code>(cons)</code>&lsquo;ing it with an element and then the original data definition
<ul>
<li>this element can be atomic non-distinct data, not just another data definition (reference)</li>
</ul>
</li>
<li>an example of self-reference, where the data definition involves itself</li>
<li>new primitives: <code>(first list)</code> returns the first element, and <code>(rest list)</code> returns everything but the first element</li>
</ul>
</li>
<li>with HtDF, several things have changed to accomodate new branches
<ul>
<li>refer to the type comment and how it refers to itself =&gt; preserve that in the function templates</li>
<li>template now needs to apply a <code>(fn-for-element)</code> for the first element
<ul>
<li>this should be another helper function generally, want the function to do one thing at a time</li>
</ul>
</li>
<li>template applies the <code>(fn-for-list)</code> for the rest of the list</li>
<li>generally use a <code>(cond)</code> to check if the list is empty (base case handling)</li>
<li>examples can help clarify the behaviour of the function first, and show where you might need helpers
<ul>
<li>also insert tests for base cases themselves</li>
</ul>
</li>
</ul>
</li>
<li>positions in list templates matter and have their own functions
<ul>
<li>base =&gt; when the function exits and &lsquo;bottoms out&rsquo;</li>
<li>contribution of first =&gt; the first element (type checking generally goes here)</li>
<li>combination =&gt; check other cases or perform operations on the value of the rest of the list</li>
</ul>
</li>
<li>when the recursive data definition handles another data definition =&gt; reference rule
<ul>
<li>produces a natural helper =&gt; abstract this to another function</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>As I write this, I&rsquo;m actually halfway through week 5, but it&rsquo;ll take me a good while to write up that double module&rsquo;s notes properly, and I&rsquo;d rather not extend this post too much. I&rsquo;m also almost at the halfway mark of the whole course (yay me!), but I&rsquo;ve noticed that most of the next modules are broken up into a and b sections, so I expect it&rsquo;ll probably be more work than the first couple weeks. I&rsquo;ve heard that the later weeks heavily build on the beginning weeks, so I might come back and update my notes posts every so often. I hope I&rsquo;ll be able to at least go through another couple weeks before spring break ends, but I also want to take enough time to relax and recharge<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>I have no big plans with regards to projects at the moment - I&rsquo;m just trying to keep everything stable before I graduate, and continue to explore opportunities I might like to take after I enter university. It&rsquo;s rather scary that I&rsquo;ll be an actual university student in a couple months, and that my quintessential &lsquo;high school experience&rsquo; is nearly over. A post about Racket is probably not the best place to digress into all the amazing experiences that&rsquo;ve filled the last couple years, but I will say it feels a bit strange to consider that I&rsquo;ll be one of &lsquo;them&rsquo; (an actual student) in the fall, and that I have no idea what I have time for left in the last three (well, two and a half, if we&rsquo;re going to be precise) months. Well, we&rsquo;ll figure it out eventually (and finish CPSC 110 somewhere in the process too).</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I suppose you can start laughing now, but I&rsquo;m trying, alright?&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Towards Web Monetization</title>
      <link>https://kewbi.sh/blog/posts/210307/</link>
      <pubDate>07 Mar 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On speculations about the future of WM.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>It&rsquo;s funny how scholarship essays can prompt thinking on topics you thought you&rsquo;ve forgotten, and spark new thoughts even after you&rsquo;ve penned your profile and sent it off to the selection committee. I applied to something recently, in which I had to go through the usual drivel of describing far-off plans for my future. I talked a bit about open source and a bit about leadership, but the part that&rsquo;s stuck with me was a part about impacting the future of the web. &lsquo;Reinventing the web&rsquo; seemed a bit lofty and grandiose, so I chose to focus a bit about my experience with Web Monetization.</p>
<p><a href="https://webmonetization.org/">Web Monetization</a> is something that&rsquo;s been on my mind&rsquo;s back burner since the hackathon <a href="https://dev.to/devteam/announcing-the-grant-for-the-web-x-dev-hackathon-winners-1nl4">Dev.to</a> hosted. (I&rsquo;ve written a post about the hackathon over <a href="https://kewbi.sh/blog/posts/200531/">here</a>, if you&rsquo;re interested.) If you&rsquo;re not familiar with Web Monetization, I highly recommend checking their website out, and looking at some of the projects and discussion that&rsquo;s sprung up around it. A four-way partnership between Mozilla, Creative Commons, Dev.to, and Coil, the hackathon encouraged people to build new toolkits to implement WM to work with and extend web environments. I&rsquo;d initially gone into it purely for the technical challenge <del>and for a chance at merch</del>, and had approached my second project, a GitHub revenue sharing Chrome extension also based on WM, with a similar perspective.</p>
<p>However, as I&rsquo;ve continued to see articles pop up every now and again about WM, I&rsquo;ve started to think a bit more about the monetization models of the web today, and how WM can potentially augment, extend, and change them. For example, there&rsquo;s these big tech giants who are <em>stealing all our data</em> and <em>greedily injecting ads wherever they can</em> and generally not doing very privacy-, or even human-friendly things. There&rsquo;s the counter-argument and justification that content has to be paid for in some way in order to produce it with any acceptable quality. There&rsquo;re perfectly rational people who would really rather not have to pay for anything, but have gotten roped into a couple larger publications and subscription instead of smaller, indie ones because bigger sources provide a higher sheer volume of content to consume - and hey, that technically equates to better money spent, right? There&rsquo;s the Substack revolution, and the rise of the independent web while people espouse the benefits and inherent aesthetic qualities of a more open web. There&rsquo;ve been ad-blockers, ad-blocker blockers, and ad-blocker blocker blockers, and who knows how long the war between corporation and Chrome extension will go on.</p>
<p>Web Monetization, to me, is a better fit for the &lsquo;indie web&rsquo;, as they call it, rather than larger, more clunky companies. With clear examples of hiding ads for paying users (a model that exists already), adding new content for paying consumers (augmenting the private subscription model), and sharing revenue (simplifying a model), they&rsquo;ve come up with an alternate pathway for monetization besides slapping ads between a couple paragraphs. Most of the sites I can see potentially adding this are the types of sites that don&rsquo;t even have ads in the first place, and it&rsquo;s an interesting possibility to investigate this more passive stream of revenue.</p>
<p>I&rsquo;ve been thinking about Web Monetization and the opportunities it presents ever since I wrote the essay. It&rsquo;s an interesting way to add new monetization streams on the web and rework existing ones - however, like most things, I think there&rsquo;s still some steps to be taken before we can see how WM will evolve and adapt<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<h2 id="project-check-ins">Project Check-ins</h2>
<p>Before I step into some of the issues and future possibilities I see in WM, I&rsquo;d like to check in on the state of some of my own projects in the WM area, and see how they&rsquo;re doing as WM evolves.</p>
<p>Let&rsquo;s start with <a href="https://github.com/kewbish/revshare">kewbish/revshare</a>. Long story short, it&rsquo;s a Javascript library with a couple custom web components to split payment. Instead of sending everything through to a central payment pointer and letting whoever&rsquo;s in charge of accounts to share revenue, all users need is a single JSON object linked to a rather janky component. This would update the monetization tag that&rsquo;s required to stream micropayments, and therefore change the stream of revenue. (Imagine an editor, writer, and photographer working together on an article - this way, they can split money according to their agreed-upon percentages, without having to deal with doling out the cash themselves.) People seem to still be using the project somewhere (or perhaps the NPM statistics are simply lying to me) - as of the writing of this post, I have something like 6 downloads this week. It&rsquo;s a small number, but it&rsquo;s infinitely more than what I&rsquo;d expected, and it&rsquo;s nice to know people are out there somewhere in the world using it.</p>
<p>Interestingly, as I was checking up on the general state of Web Monetization earlier this year, I noticed that WM had linked their own <a href="https://webmonetization.org/prob-revshare">revshare generator</a>, which does the same thing as Revshare, but in a probably easier-to-use format. While I&rsquo;m slightly miffed (no, I&rsquo;m really not, no one much was using the revshare project anyway, and I&rsquo;m happy that there&rsquo;s an easier way to split payments than loading in a JSON object and using scuffed custom web components), it&rsquo;s good to see that they&rsquo;ve started coming up with some of their own tools to facilitate solving some of the issues I&rsquo;d been having when I started out.</p>
<p>The second project I&rsquo;ve worked on involving WM is <a href="https://github.com/kewbish/revshare-gh">kewbish/revshare-gh</a><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, which is Revshare, but with GitHub Sponsors payment pointers and a little dependency kickback. GitHub Sponsors has a custom field or two in which project maintainers can fill in a WM payment pointer from whatever provider, which then gets added to the monetization tag, feeding creators a bit of revenue while people browse the repo. It also splits about 50% to whatever dependencies the project uses, if a WM payment pointer is present in the dependency repo&rsquo;s GH Sponsors tag. The idea was that open source maintainers could make a bit of cash off people browsing their repos, and also give some back to the projects that helped build it up.</p>
<p>As I&rsquo;ve continued to think over this idea, I&rsquo;ve realized that there&rsquo;s two main issues. One, there&rsquo;s a bit too much friction between the user (not the owner of the GH repo, but the user who&rsquo;ll be paying). Revshare-GH was built in the form of a Chrome extension, and I&rsquo;m not sure people would be willing to take the time to install and add their GH token to provide more support to maintainers. Even if you&rsquo;re paying, there&rsquo;s not any value added to the repo, and I don&rsquo;t think any fancy special content can be loaded, since Markdown doesn&rsquo;t have access to Javascript. Yes, I could rig up an external service to connect exclusive content locations to people who choose to donate, but I think that&rsquo;s best handled on the GH side of things. If GitHub itself includes WM tags as a repo option, this friction would be gone, and I&rsquo;d be inclined to think that people would be more enthusiastic about the project. Two, the amount of revenue kicked back to the creator would be minimal, and I&rsquo;m not sure if people would bother to include their payment pointer and ask their consumers to set something like this up for a couple cents a week (more on this a bit later). From my own browsing habits, I tend to only check repos out for a couple minutes, skimming the README and perhaps looking into a bit of the code if I&rsquo;d like to borrow a technique. If I&rsquo;m looking at the documentation, I&rsquo;ll stay for a bit longer, but oftentimes docs are hosted elsewhere from GitHub, meaning that the standard method of WM would likely work better there anyway.</p>
<p>Regardless of the problems I&rsquo;ve found, I&rsquo;m still happy with these two projects. They solved problems back when they were being created, which was the entire point of the exercise of working on them anyway.</p>
<h2 id="we-need-more-providers">We Need More Providers</h2>
<p>Coming back to WM itself, I think one of the more glaring issues seems to be adoption, specifically with WM providers. There are only a couple wallet providers, one or two search engines and browsers, a handful (though a healthy one at that) of platform integrations, and only one payment provider, Coil. That seems to be a bit sparse.</p>
<p>Part of this seems to be the feedback loop where companies don&rsquo;t see the benefits of investing in creating a payment processor for a niche area of monetization when there isn&rsquo;t widespread adoption and low profits to be made. In turn, because there&rsquo;s low adoption among existing companies, users perhaps don&rsquo;t see the point of creating a whole new account and subscribing to yet another service. Developers see that few people have accounts, and without a wallet at one of the few providers, might decide that the possible revenue would be too low to bother spending valuable time on it. And without high-profile companies integrating WM into their products, competing companies wouldn&rsquo;t bother to use WM, and so the cycle continues.</p>
<p>When I was participating in the Dev.to hackathon, I&rsquo;d honestly not have bothered to make a Coil account if they weren&rsquo;t giving a couple months of it away for free. (I&rsquo;m also not legally allowed to reap any of the benefits yet, which is part of the reason I haven&rsquo;t bothered to WM any of my sites or posts, but perhaps I will sweet talk my parents into something if I ever feel like it.)</p>
<p>Perhaps another part of this is that the <a href="https://webmonetization.org/specification.html">spec itself</a> hasn&rsquo;t been finished yet, and hasn&rsquo;t gone through whatever magic goes on at Google and Mozilla and all the tech giants before something gets integrated into major browsers, if at all. There still seems to be a good amount of activity on the spec and the GitHub, so I&rsquo;m excited to see how WM will spread and be adopted if something like Chrome adds it as an API. With it as a default option available in the browser, the potential audience of WM work is opened up from just tech-nerds with niche browsers (no shade), to a more general audience<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Developers, payment processors, wallet providers, and content creators will be more inclined to start WM&rsquo;ing their content - instead of a couple cents here and there, perhaps WM can start augmenting and eventually acting as a proper stream of revenue.</p>
<h2 id="for-the-consumer">For The Consumer</h2>
<p>Articles on WM generally center around the possibilities of revolutionizing the monetization models prevalent on today&rsquo;s web by shifting away from ads and towards user-initiated micropayments. While WM certainly has the capabilities to prompt a move away from ads (it even has a handy example on its docs detailing exactly how to do so), I think it&rsquo;ll take a lot of time and promotion before WM starts growing to something that even a decent fraction of an app or content creator&rsquo;s userbase will readily have.</p>
<p>With the ads-based models that seem to be the standard on the web, users don&rsquo;t have to physically (well, digitally) fork over any payment. The money creators make is not <em>directly</em> from you, but is still from you - your data, your analytics, and your preferences. The important thing, though, to note, is that the consumer never sees any of this, and even though the news has hopefully blasted the fact that companies are building scarily accurate profiles about you without your knowledge, it&rsquo;s taken for granted that things are &lsquo;free&rsquo; on the web. I&rsquo;ve asked my parents about this before, and they seem pretty nonplussed (&lsquo;I have nothing to hide - try to make me buy whatever you want&rsquo;).</p>
<p>Even if people pay, things seem to be easier and seem to be more &lsquo;worth it&rsquo; by supporting existing, larger organizations. A subscription to an online newspaper gives a reader access to exclusive breaking news, and hundreds of stories. A Patreon subscription might only give access to a couple of posts - and same goes for some of the new custom platforms creators are using to sell early access, special, or otherwise gatekept content. In order for WM to gain a wider adoption, I think it&rsquo;s necessary to shift people more towards indie sites, or towards sources of monetized content, so people feel comfortable with the process. Besides the technical limitations today (I don&rsquo;t think managing ILP wallets is something that most people would bother with to get started - I&rsquo;d think twice), it&rsquo;ll take time for the internet to shift to accept these models of monetization, and to trust in paid content. An interesting thing to note about the Substack revolution (is that what they&rsquo;re calling it?) is that it&rsquo;s hopefully prompting people to ask where they get their content from, and to contemplate the value of what they consume - is it worth a couple dollars a month? Hopefully, this, and other micro-monetization movements will pave the way for WM, and get people more comfortable with the idea of having to pay for things.</p>
<h2 id="conclusion">Conclusion</h2>
<p>WM is genuinely pretty cool. I think it&rsquo;s a possible stepping stone in the long pathway towards a more indie web community, and in the meantime, a nice way to get a couple cents where you otherwise might not have. It might also be a step to get people to more actively seek ways to control who&rsquo;s taking their data and money, but at the cost of having to knowingly give away money. It&rsquo;s interesting to ponder how WM can potentially rework monetization models that are now the norm, but it&rsquo;ll take a lot of adoption and investment into spreading the API first.</p>
<p>There are a lot of &lsquo;but&rsquo;s in the thoughts I&rsquo;ve been having about WM, but (haha, another one) I think it&rsquo;ll come with time. The recent uproar around NFTs (hey, even the local news aired a segment) proved that people are interested in this whirlwind of new money coming into cryptoart, and who&rsquo;s to say the same attention won&rsquo;t eventually turn to micropayments and other methods to monetization? Hopefully, widespread adoption and user comfort will increase with time, and we&rsquo;ll get to see WM as a cornerstone of a new age of the web.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Also, in an interesting turn of events, another article about Web Monetization popped up on <a href="https://news.ycombinator.com/item?id=26375857">HackerNews</a> just as I was going to write this, and there&rsquo;s some interesting discussion happening in the comments.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I have a vague feeling that if I don&rsquo;t mention Aadi for giving me the idea (thanks buddy), he&rsquo;ll be at least somewhat annoyed, so I&rsquo;ll add this here.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>They say RSS died away because it was never integrated directly into the browser, with explicit features to follow and interact with feeds. I&rsquo;m not entirely sure of the truth behind that, but I think that by increasing the size of the WM userbase, people will be more incentivized to use it, especially if it&rsquo;s built into a popular browser in an easy-to-understand way.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Week 2</title>
      <link>https://kewbi.sh/blog/posts/210221/</link>
      <pubDate>21 Feb 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On designing data in Racket.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Somehow through the whirlwind couple months it&rsquo;s been, I&rsquo;ve neglected to touch CPSC 110 at all. I&rsquo;ve been mostly focused with fixing <a href="https://github.com/kewbish/matter">Matter</a> up and adding all the quality-of-life features I&rsquo;d want in order to designate it a main information source. But that&rsquo;s besides the point: I&rsquo;ve decided I want to finish as much of CPSC 110 as I can before spring break, or at least during it. At the latest, I&rsquo;d like to sort everything out by summer, and see if I can finagle myself a spot in the summer session (fingers crossed).</p>
<p>I&rsquo;ve made myself a proper CPSC 110 repo and even bothered to figure out how to convert GUI DrRacket files into ones Vim can handle, so hopefully I&rsquo;ll be more motivated to solve the problem sets properly. Before I dove into this week&rsquo;s material, I had to rewatch most of week 1 to relearn the function recipes again, but I&rsquo;ve made more notes this time round (and referred to the ones on my blog - I told y&rsquo;all it would come in handy). Going into the data definitions section wasn&rsquo;t actually much of a challenge once I went through and watched the videos again.</p>
<p>The design recipes, as Kiczales mentions, are becoming ingrained into my memory now. It&rsquo;s very intuitive how they all slot together, and though sometimes it feels extremely repetitive to keep making examples and stubs, I can see why it helps when debugging more complex parts on top of the recipe. This week, I&rsquo;d gotten ahead of myself and briefly tried to do things with structs, but that really wasn&rsquo;t the point of this week yet (I&rsquo;m told it&rsquo;s part of week 3.). It&rsquo;s rather surprising to see how each recipe and definition builds on the others, though sometimes I&rsquo;m left wondering if all these conventions are really all that useful.</p>
<p>If you&rsquo;re uninterested in wrangling with data definition recipes, this might not be very fascinating, but I think keeping this as a record of what I&rsquo;ve been doing with Racket will be helpful for later revision.</p>
<h2 id="notes">Notes</h2>
<p>Week 2 deals with designing data, and how to create data definitions that work with the function definition recipe.</p>
<ul>
<li>cond expressions are if statements with multiple branches
<ul>
<li>use square brackets to test the question =&gt; <code>[(Q) A]</code></li>
<li>if only else body =&gt; the then block is evaluated instead</li>
<li>evaluation steps: evaluate the first expression&rsquo;s Q block
<ul>
<li>if it&rsquo;s false, it gets removed from evaluation</li>
<li>keep evaluating and removing until you meet a true block, then return the answer</li>
</ul>
</li>
</ul>
</li>
<li>data definitions =&gt; information represented in problem domain, and restricts what is allowed
<ul>
<li>type signature comment, what it is</li>
<li>interpretation of what the data is supposed to represent</li>
<li>examples of the data =&gt; &lsquo;one of&rsquo; comments</li>
</ul>
</li>
<li>atomic non-distinct =&gt; can&rsquo;t break into meaningfully smaller pieces
<ul>
<li>now have a data driven template =&gt; <code>fn-for-x</code>, then have a body from the table
<ul>
<li>never actually use it, so keep it commented</li>
</ul>
</li>
<li>when atomic non-distinct =&gt; <code>(... x)</code>, if distinct, then just <code>(...)</code>
<ul>
<li>write a comment detailing the data driven template body type</li>
</ul>
</li>
</ul>
</li>
<li>following the HtDF recipe is easier to understand + already learned metadesign
<ul>
<li>function recipe is independent to data definitions, so don&rsquo;t need to learn a new one</li>
</ul>
</li>
<li>interval data definition =&gt; numbers within a certain range
<ul>
<li>when giving type comment, use range =&gt; use proper interval notation</li>
</ul>
</li>
<li>enumeration =&gt; two or more distinct values
<ul>
<li>for rules used, add &lsquo;one of&rsquo;, and the number of cases / subclasses</li>
<li>use a cond to represent each case in body</li>
<li>don&rsquo;t need to use examples =&gt; add comment to explain redundancy</li>
</ul>
</li>
<li>itemization =&gt; two or more categories, but one or more of which isn&rsquo;t distinct
<ul>
<li>for example, a preflight, postflight, and inflight altitude</li>
<li>type guard required for each case if mixed data types</li>
<li>last condition will be an else, because we know that by process of elimination it must be that value
<ul>
<li>if all remaining data types are same data type, no guard needed</li>
</ul>
</li>
</ul>
</li>
<li>amount of tests will differ based on the data
<ul>
<li>with an interval =&gt; closed boundaries and midpoints (~3)</li>
</ul>
</li>
<li>when using HtDF with own data definitions =&gt; can reuse template
<ul>
<li>function recipe and prompt gives information about tests, etc</li>
<li>design behaviour of function while designing tests</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>I actually managed to work my way through the lab and problem set while trying to learn the material at the same time (not very fun, do not recommend because you&rsquo;ll be very confused at the conventions that the example solution assumes), so I developed my own way of doing things the first time. It was interesting to contrast how I took shortcuts the first way round: not putting down enough <code>check-expect</code>s or ignoring the stub parts of recipes. Again, sometimes it really does feel like a chore to have to repeat the steps over and over again, but maybe that&rsquo;s part of how you learn things<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>Spending a month and a bit away from Racket, then suddenly returning was a bit disorienting at first - I had to familiarize myself with the syntax again, and the various builtins. The way I write Racket has been tinted a lot by the procedural way of doing things that&rsquo;s been prescribed by the course, so it was an experience to go from writing essentially whatever fit without much proper testing (Matter), to having to make testing an integral part of the programs.</p>
<p>I&rsquo;d forgotten how much fun listening to 2x lectures was - I suppose it&rsquo;s just part of the natural recursion<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. I&rsquo;ve been trying to make CPSC a priority in my free time (of which I have very little - oh, the woes of senior year), so hopefully I&rsquo;ll be back next week with either more notes or a proper post. I have ideas for both, but we&rsquo;ll see.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>No matter how many times Kiczales repeats the fact that whatever semicolons is a comment and whatever semicolons is for a stub or purpose, I cannot remember.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I don&rsquo;t think I&rsquo;ve gotten far enough in for Kiczales to have made the joke yet, but I&rsquo;m still somehow aware of this.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
