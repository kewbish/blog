<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Yours, Kewbish - a collection of </title>
    <link>https://kewbi.sh/blog/</link>
    <description>Latest Yours, Kewbish posts</description>
    <managingEditor>(Emilie Ma ◦ Kewbish)</managingEditor>
    <lastBuildDate>Sun, 25 Apr 2021 08:11:59 -0700</lastBuildDate>
    
	<atom:link href="https://kewbi.sh/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Problem Solving</title>
      <link>https://kewbi.sh/blog/posts/210425/</link>
      <pubDate>25 Apr 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On an ideal substrate for problem solving.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I was working on a physics problem earlier today: something to do with a ferris wheel and centripetal acceleration and calculating the range of something dropped at a certain point on the wheel. It wasn&rsquo;t particularly difficult, but it&rsquo;s a good example of the ways I&rsquo;ve had to force existing tools to work in order to solve things. Normally, when I complete practise problems, I don&rsquo;t bother writing out full equations or even a good amount of work, and just stick to a couple notes for formulas and things I&rsquo;ve moved around dashed out in Chrome&rsquo;s address bar. The rest of the arithmetic part ends up being bodged together in the omnibar&rsquo;s built-in calculator, which I find is more than good enough for most problems. When I&rsquo;m doing practise for myself, I&rsquo;m just focusing on if I can get the formula and the problem&rsquo;s givens somehow into the correct answer, and I know that if I properly tried, I could get the steps down anyhow.</p>
<p>However, this specific problem was for a friend who wanted a written solution, which meant that I had to get an actual diagram out. I didn&rsquo;t fancy trying to <a href="https://asciiflow.com">ASCII-art</a> one together in Vim or something, so I turned to <a href="https://www.whiteboard.team/">whiteboard.team</a>, a free, no-account-needed (which is actually great, since most of the time, boards are temporary and just for sketching out ideas and such) online whiteboard app. I&rsquo;ve found the lack of a cloud-sync or saving option while online not to be a problem at all - again, I&rsquo;m generally only keeping boards for a couple minutes for a screenshot. I sketched out the little wheel, slapped together a poorly-formatted, terse solution, and sent it off. Close board, and go about the rest of my day.</p>
<p>Chemistry labs, physics problem sets, and calculus reviews have a couple things in common: a general feeling of dread, accompanied at times by procrastination; but also: they involve manipulating equations and working with data in ways that often don&rsquo;t work with existing tools. For example, with the physics problem example above, I&rsquo;d have loved to get a way to format equations with at least proper subscripts and integrate a quick calculator in the whiteboard, so I wouldn&rsquo;t have to keep switching between a myriad of new tabs with only half-baked expressions in the omnibar and the unicode reference page to copy out special characters.</p>
<p>I think tools nowadays tend to do either one thing very well à la the Unix philosophy, or several things average-ly - something like the spread of things like Notion and other one-size-fits-all-problems software). On this spectrum, I&rsquo;d still rather my preferred tools tend to the one thing very well side - I&rsquo;d like to have the power to do more complex things when I need to rather than be guiderailled in. However, the problem with having a wide toolkit of specific programs tends to be sprawl, where the programs you need to have open to do one given thing increases as the required functionality gets split across more and more advanced apps. As well, as bemoaned by most of the HCI / developer community, most tools lack a centralized standard, or even individualized API, to move information from app to app in a non-manual way. Especially when apps are very seemingly disconnected, requests for connections and integrations are very niche, and end up serving only a couple users. Why can&rsquo;t I get a way to move equations between document formats, by, say, exporting a Word equation to clipboard for evaluation in Desmos or Chrome or whatever calculator, and then automatically copying the answer back into my doc? I doubt Word and Desmos / Chrome would ever build a proper two-way integration, so I either have to resort to manually repeating things like this, or have to change tools (well, apparently I can evaluate functions in Excel, but that&rsquo;s still a bit of a hurdle).</p>
<p>Maybe it&rsquo;s the influence of HCI twitter and the amazing tools for thought I&rsquo;ve seen prototypes for on my timeline all day, but I&rsquo;ve been thinking a lot about a possible ideal mix of all these problem-solving softwares, or at least a combination of features that&rsquo;d personally benefit me. With the amount of apps and things I&rsquo;ve tried out, I&rsquo;m surprised no one&rsquo;s thought about integrating the best of each of these tools, but hey, &lsquo;software to automatically evaluate and nicely format my equations in a way that&rsquo;s acceptable by my teachers&rsquo; is a pretty niche specification. Consider this thought-chain a speculative dream of what could have been (and hey, what might be, if I ever decide to take a stab at integrations myself).</p>
<h2 id="desmos-comes-close">Desmos Comes Close</h2>
<p>I&rsquo;d like start by extolling the virtues of <a href="https://www.desmos.com/">Desmos</a>, specifically focusing on their wonderful graphing calculator. With labels for notes, arbitrary points, variable assignment, and immediate cell evaluation, it&rsquo;s become an invaluable tool, especially for formula- and repetition-heavy work. Though I sort of neglect the graph itself for most of my problem solving (save for in maths), I&rsquo;m pleasantly surprised at how full-featured and free the calculator itself is. Returning to the physics workflow example, I can pre-define constants and pre-program common formulas, while keeping variables for mass, velocity, and other values that change between problems. This feature alone has saved so much time - instead of looking back for intermediate values or estimating them and losing precision, I can simply define them and reuse them in future calculations. Because Desmos also calculates the expression value immediately, I can get the convenience of the Chrome omnibar calculator with added annotation and manipulation powers.</p>
<p>Text labels have weirdly helped me think through problems and substitution more effectively than just trying to keep formulas, values, and all the next steps in my head. Part of it is that it&rsquo;s a lot easier to see where you are in a problem when everything&rsquo;s written out, especially when determining next steps. Visually seeing possible substitutions and figuring out what&rsquo;s next is plenty simpler when I&rsquo;m able to view both my notes and the calculations in one place. Previously, when using just Chrome, I&rsquo;d have to tab between calculations and formula notes, and it was honestly an information overload, as I had to keep each tab open to preserve intermediate values and could never find the work I was looking for.</p>
<p>Tables have been especially useful in chemistry, with all the <a href="https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Supplemental_Modules_(Physical_and_Theoretical_Chemistry)/Equilibria/Le_Chateliers_Principle/Ice_Tables">ICE tables</a> we need to compose for our calculations. Calculating K values is an area where I find I need the guidance and actual visual information of a table, since there are way too many values to consider to lay one out mentally. They&rsquo;re also super useful for applying formulas to a range of values without having to create a new Excel workbook for a problem that&rsquo;ll take a couple minutes - a past overhead that Desmos now obviates. While these tables are nowhere near as powerful as Excel cells, they&rsquo;re more than enough for calculating intermediate values and sketching out work.</p>
<p>Images, however, is one way Desmos doesn&rsquo;t quite cut it for me. I generally find that I need to diagram things for physics (or, at least, it&rsquo;s good practice), and trying to diagram anything other than a circle or a line is a lot more work than I&rsquo;d like. Sure, I can quickly draw something out in <a href="https://vectr.com">Vectr</a> and upload it, but I often find I&rsquo;d rather just go without and edit an explanation in in post, or forgo the diagram entirely. It&rsquo;s no fault of Desmos&rsquo;s - the entire point of the calculator is that it specializes in graphing and scientific computations, and it&rsquo;s gone above and beyond what I need from it. However, it&rsquo;d be amazing to figure out a way to combine both the power of the calculator and, say, something like Vectr or even a rudimentary version of whiteboard.team. Most of the drawing functions are redundant and overcomplicated, but even a box, circle, line, and arrow set of functions would be amazing. Oh well.</p>
<h2 id="free-form-structure">Free-form Structure</h2>
<p>I find that my work in solving these science problems feels sort of like sketching, albeit perhaps on a digital canvas, rather than physical paper. When I&rsquo;m trying to work at my speed of thought, the most friction-free experience is generally with text, but diagrams and laying things out spatially can help sort out how to manipulate the formulas and such. I use the term manipulate, since it really does feel like you&rsquo;re slotting things in and moving terms around.</p>
<p>Things like ASCII take away the aesthetic requirements, where I almost feel like I <em>need</em> to make something pretty and presentable. However, I generally don&rsquo;t want to make diagrams in ASCII, especially when there are more abstract shapes and arrows to work with (physics won&rsquo;t work, though chemistry might, since it&rsquo;s more text heavy) Especially when using more rudimentary tools that impose a certain structure, it feels that tools are encouraging you against the decision paralysis presented by more complex tools. That&rsquo;s why I tend towards quick scrawling even when solving problems - I&rsquo;d rather check that I can understand and produce the answer, rather than fuss over how to get a subscript in another subscript<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Tools like Vectr are great for producing more polished drawings, but I end up spending too long fiddling with fonts to get everything on a page to look nice and cohesive. whiteboard.team&rsquo;s sketching tools are quicker to work with, and while everything comes out looking a bit like an MS Paint attempt at modern art, it works for sorting the problem out quickly.</p>
<p>I guess this sort of touches on the presentation side of things, and the purpose of whatever I&rsquo;m sketchnoting. If it&rsquo;s something just for me, scribbling down a couple boxes with unlabelled arrows is generally enough for me to get the gist of what I need to do. However, if (like in the scenario I shard in the introduction) it&rsquo;s something I need to present for marks, I&rsquo;ll put more effort in. This &lsquo;effort spectrum&rsquo; is something that sort of changes which tools I use for a given purpose.</p>
<h2 id="but-also-compatibility">But also, compatibility</h2>
<p>Speaking of changing the tools I use for a given purpose, I also have a minor point with file formats and such. Word, at least in my school, is the de-facto standard for document and homework sharing, so I&rsquo;m required to work with .docx files at least - even if I don&rsquo;t have to directly edit in Word, I need to produce something Word-parseable in the end<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Working with Word equations is not that painful of an experience - while my classmates seems to collectively agree that handwriting chemistry equations is much easier than typing them out, I find that working with digital equations is as fast as and as convenient as working on paper. Perhaps it&rsquo;s just a matter of medium preference. However, one thing that I definitely find tedious is editing equations and working with calculations in the same workflow. When building a lab report, for example, I have plenty of sample calculations to provide, and generally data points for these equations source from raw data. I usually keep a separate Excel sheet with formulas I can easily drag around and apply to groups of cells, but it&rsquo;s a pain to try to copy around end values and work with calculations within Word itself. If I&rsquo;m not Exceling things, I keep a Chrome window open, and it&rsquo;s sort of frustrating to jump around to do calculations. It also introduces a new surface for error - I don&rsquo;t want to talk about the number of times I&rsquo;ve mispasted a value or missed an exponent by one.</p>
<p>It&rsquo;s relatively painless to fix things up if this wrong value happens at the end of a calculation, but when it&rsquo;s an intermediate value that other calculations depend on, reworking all my equations is an especially tedious task. This is when I tend to crave the variable recalculation abilities of Desmos, which immediately redoes all depending calculations, and Excel, where I can use cell references to keep values &lsquo;bound together&rsquo;. LibreOffice (/ Word) seems to have a variable function to define numbers and reuse them in the document, but I haven&rsquo;t found a way to run formulas on them, or integrate them in equation blocks.</p>
<p>I don&rsquo;t think it&rsquo;s worth making a point of introducing a new file standard for something like this - <a href="https://xkcd.com/927/">relevant XKCD</a>, and I also don&rsquo;t think it&rsquo;s worth bothering to ask if I can submit in a PDF or whatever quirky file format an &lsquo;ideal&rsquo; software would kick back. I wouldn&rsquo;t mind having to work with an intermediate file format, as long as it&rsquo;s fully integrated and exportable to Word (or LaTeX). I think these are pretty lofty goals, however, so I think I&rsquo;ll just have to live with the monotony of redoing a full set of equations four times over because I accidentally messed up in the first two sections.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Whenever I&rsquo;m using only one of the above tools, it feels like I&rsquo;m missing something. With Word, I wish I&rsquo;d be able to calculate and substitute variables in equation blocks themselves. With Desmos, I lack the image and diagram manipulation features that help visualize problems at times. With whiteboard and other diagramming software, I lack the ability to format and present my work later, and also don&rsquo;t get any of the variable manipulation that streamlines my entire calculation workflow. I think my ideal scientific problem-solving software would be something like a combination of:</p>
<ul>
<li>Desmos&rsquo;s variable system and instant calculations</li>
<li>whiteboard.team&rsquo;s / Vectr&rsquo;s diagramming capabilities</li>
<li>Word&rsquo;s layouting, formatting, and text hiding, and</li>
<li>(maybe) Vim&rsquo;s keyboard-driven philosophy</li>
</ul>
<p>I could replicate several parts of this system on physical paper, but again, I&rsquo;d be losing out on the variable calculation and the digitization aspects of my workflow. For me, it&rsquo;s also a lot easier to type things out, both in terms of remembering the solution work and efficiency (I type much more quickly than I can write). I&rsquo;d also prefer to figure out a toolkit digitally that can continue to work in the future, if the digital aspect does end up being a requirement sometime in university.</p>
<p>In terms of developing things like this, I&rsquo;m not entirely sure, but it might be possible to wire together Word extensions, a Desmos API, and some sort of diagramming API to make inserting and formatting work into Word more streamlined. I think this might have something to do with the whole <a href="https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html">Bring Your Own Client</a> idea, where there&rsquo;s a need for more software to open up to remixing and inter-app data flow. I&rsquo;d like to investigate possibilities and other tools that&rsquo;re easier to mix together in the future as well, especially tools that are simpler and more text-based. Developing a toolkit for scrap work and raw calculations is still a higher priority for me than Word integrations, but the whole file format thing is still a struggle, especially since most of the work I do is for school, and I need to follow assignment requirements.</p>
<p>I&rsquo;ve been putting off writing this post for a while, and I think I&rsquo;ve sort of lost the rhythm of writing weekly. Part of it is the homework (that they did say was supposed to decrease roundabout now, but oh well), and part of it was a lack of coherent thoughts. I&rsquo;ve went back and built a list of some ideas for future posts just now, so hopefully I&rsquo;ll be able to get back to writing more regularly. It&rsquo;s interesting how writing and outlining something like this sort of cements all the ideas and makes it clear what I personally think, so I guess that&rsquo;s a nice hidden benefit of writing. Writing this post actually inspired a different one that might come out in the near future, but we&rsquo;ll see how much time I have.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I use LibreOffice, since booting back to Windows is too much effort, and Word on Wine was both a pain to set up and to work with, so some of the instructions for Word didn&rsquo;t apply. In the end, apparently you&rsquo;re supposed to wrap the part of the equation to subscript with a set of curly braces. You can then apparently nest to whatever depth you&rsquo;d like to - a bit of a late discovery, but hey, late&rsquo;s better than never. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Apparently this changes to LaTeX in university, so there&rsquo;s something else to consider. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Weeks 9 and 10</title>
      <link>https://kewbi.sh/blog/posts/210418/</link>
      <pubDate>18 Apr 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On generative struggles and accumulators.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Last week, I think I predicted that these couple weeks would be some of the hardest so far in the course, and I think I wasn&rsquo;t far off. The lab and problem set for week 9 were especially difficult - it seemed to be very much a &lsquo;it&rsquo;s a matter of thinking&rsquo; type of problem. Generative search and this type of recursion are techniques I haven&rsquo;t even touched outside of Racket, so I think the lack of experience definitely didn&rsquo;t help, as well as my not understanding the problem half the time. Week 10&rsquo;s work wasn&rsquo;t much better - I&rsquo;m still working through the lab and problem set as of now. However, I feel like Week 10 &lsquo;clicks&rsquo; more than Week 9, but maybe that&rsquo;s just because Week 9 had a large problem example instead of smaller, more digestible ones. However, going through the practise problems and solutions has been helping, and I&rsquo;ve really learned that you cannot rush it - taking my time to work through problems fully has been a lot more helpful than trying to speedrun a couple easy check-expect cases.</p>
<p>As with every other CPSC 110 post, if you&rsquo;re not doing the course or don&rsquo;t have the very niche interest of tackling aforementioned generative recursion and accumulators, this is the part where you might want to go read one of my other posts. I promise there&rsquo;s some interesting thoughts somewhere in my post history, so feel free to go check those out instead.</p>
<h2 id="notes---week-9">Notes - Week 9</h2>
<p>This week covers generative recursion, and applies it to backtracking search, a method of search that generates all possible permutations of a problem in a tree before eliminating invalid ones.</p>
<ul>
<li>generative recursion differs from previous structural recursion =&gt; instead of taking a sub-piece of data as argument to next call, we now generate entirely new data to call
<ul>
<li>fractals are a good example of this =&gt; layering images onto each other</li>
</ul>
</li>
<li>use the HtDF recipe for generative recursion =&gt; instead of an empty case, we have a trivial case and a non-trivial generative case
<ul>
<li>generally nest images around other recursive cases, instead of only having a recursive expression</li>
<li>base case for generative recursive check-expect is the case that doesn&rsquo;t recurse anymore =&gt; set a cutoff constant
<ul>
<li>next ones can be those that do recurse (generally one or two &lsquo;steps&rsquo;)</li>
</ul>
</li>
<li>can use locals to avoid redundant competition (i.e. when multiple recursive areas or multiple of the same nonrecursive cases)</li>
<li>can re-call the recursive function =&gt; make sure to operate on the arguments (generally for side length)</li>
</ul>
</li>
<li>can&rsquo;t count on type comment rules to determine that the recursion will end =&gt; halting problem
<ul>
<li>need to use our own proofs: three-part system of base case, reduction steps, and halting or termination argument
<ul>
<li>base case is the trivial question expression in the cond</li>
<li>reduction step is the, well, reduction of the expression argument</li>
<li>then use logic to state an argument that repeating the reduction will eventually reach the base case</li>
</ul>
</li>
</ul>
</li>
<li>use lambda (λ) expressions to avoid having to create a whole local function =&gt; anonymous function
<ul>
<li>only use in place of expressions that will only be used once =&gt; like Python lambdas</li>
<li>ensure the body is easily understood and that the naming adds nothing to its comprehension</li>
<li>format: <code>(λ (n) (&gt; n 5))</code> where the n expression is the list of other expressions</li>
</ul>
</li>
<li>backtracking search is composed of several parts =&gt; structural recursion for the tree structure, and handling function composition
<ul>
<li>use the HtDF backtracking search template =&gt; use local functions to nest all required functions in a single expression</li>
<li>two main parts =&gt; the &lsquo;trivial&rsquo; or success case, and the subs, or the descendents case</li>
<li>descendents generally requires a couple helper functions =&gt; break the problem down into several smaller steps to solve with function composition, abstract builtins, or other methods</li>
</ul>
</li>
</ul>
<h2 id="notes---week-10">Notes - Week 10</h2>
<p>Week 10 deels with accumulators, a new technique used to preserve context that&rsquo;s often lost in recursive functions.</p>
<ul>
<li>structural recursion templates are very powerful =&gt; easy to abstract upon
<ul>
<li>however, cannot see &lsquo;where&rsquo; they are in a data structure</li>
<li>cannot preserve past-touched data, or accumulate data to add to future computations</li>
</ul>
</li>
<li>context preserving accumulator =&gt; brings data from parent/child or keeps track of other values that need to stay constant within a sub-traversal
<ul>
<li>wrap the function body in a local expression and add a trampoline with a base accumulator</li>
<li>add an argument to the inner functions</li>
<li>the context preserving accumulator changes every step depending on the fn behaviour</li>
<li>add parameter to where it might be used in a function</li>
</ul>
</li>
<li>also introduces the concept of tail recursion =&gt; any recursion placed in the last expression position in function, not wrapped in anything
<ul>
<li>reduces the problem where many sub-expressions are created before reducing the answer</li>
<li>optimized in many languages, including Racket</li>
<li>instead of a context-preserving accumulator, now a result-so-far accumulator is introduced
<ul>
<li>represents the built-up information (such as the sum function)</li>
<li>generally used to produce tail-recursive functions instead of cons-ing infinitely</li>
</ul>
</li>
</ul>
</li>
<li>third accumulator type is the worklist, where you consistently build onto a list that&rsquo;s called each function iteration
<ul>
<li>run the mutually recursive list function on the todo worklist instead
<ul>
<li>take the first of the worklist and operate on it, then if using another accumulator attach to that</li>
</ul>
</li>
<li>used often when operating on data with more than one graph cycle =&gt; arbitrary arity trees with tail-recursion</li>
</ul>
</li>
<li>general accumulator advice
<ul>
<li>when writing accumulators, ensure a base accumulator is set in the trampoline =&gt; empty, 0, depends on function behaviour</li>
<li>to debug accumulators, draw out an example of a call tree including the arguments and how they&rsquo;re expected to be operated on</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Only a couple modules left - though those might take a while to get through, given that they&rsquo;re the last, and probably most difficult sections of the entire course. I foresee a lot of cross-module work, as well as more complex program design. I&rsquo;m looking forward to tackling it, but a bit hesitant to find out what &lsquo;graphs&rsquo; and &lsquo;mutation&rsquo; are supposed to mean<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I&rsquo;m still on track to finishing CPSC 110 well before summer break, but I think I might have to take things a little slower given with how school&rsquo;s going. Perhaps more consistent but less intense work with the course will be more effective, anyways?</p>
<p>I haven&rsquo;t found the time to write a proper post in a while, but I think it&rsquo;s high time I went back to more regular posts - I have a list of pretty viable ideas that I&rsquo;d like to expand more on, and maybe a couple addendums and things to other posts that I might update. YK was started as half a joke, but I think it&rsquo;s become more a place to swirl thoughts together and hypothesize about the very niche things I&rsquo;m into. I don&rsquo;t think my posting style&rsquo;d fit in more micro-blog formats, so I plan on continuing to tend this digital garden (hey, am I trendy now?) for a very long time - and that means keeping my consistently posting schedule. I got a bit lax in the past month - while my very rigid posting schedule maybe wasn&rsquo;t the best for quality in 2020, it did incentivize me to stick to it, and at least put something out. Anyways, I hope I&rsquo;ll manage to edit up my latest post and have it up soon, and follow it up with a bunch of other thoughtchains. We&rsquo;ll see<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Did Kiczales intentionally name the last couple units the most vaguely just to add to the mystique? <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Also, if you&rsquo;ve read this far, it probably means that you&rsquo;re one of the few people that I talk to regularly and hey, if you unironically check the footnotes, I think I can trust y&rsquo;all enough. (Please don&rsquo;t spill to others though, at least since I&rsquo;m theoretically not supposed to talk about this yet.) So - life update! I made it into UBC, which still hasn&rsquo;t entirely hit. It&rsquo;s absolutely crazy that I&rsquo;ve got here, and at 15, too, and ███████ a ████████ ██████████ too (that&rsquo;ll stay redacted until I&rsquo;m properly legally allowed to talk about it.). 2020 and 2021 so far have been absolute rollercoasters, but hey, with GCI, GfTW, and now this - it&rsquo;s definitely been worth it. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Weeks 7 and 8</title>
      <link>https://kewbi.sh/blog/posts/210411/</link>
      <pubDate>11 Apr 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On local expressions and built-in abstractions.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>A couple weeks ago, I predicted that my CPSC 110 sprint was probably going to peter out, and would you look at that - I was somewhat right. A combination of school restarting, lots of homework to catch up on, and a general procrastination of writing anything all led to me sort of conveniently forgetting to go through a couple videos a day. It was also convenient that these couple of modules are starting to pick up in difficulty, and are generally the points where people start crying for help on the Piazza (or so I&rsquo;ve been told). All in all, I&rsquo;d definitely put off writing notes for the last few modules I&rsquo;ve completed until today, so I suppose here&rsquo;s a good place to start.</p>
<p>Local expressions and the section on one-of types were surprisingly comprehensible - I&rsquo;ve always admired how systematically this course builds on past material, but I suppose there&rsquo;s a reason why the course name is &lsquo;Systematic Program Design&rsquo;. Week 8&rsquo;s module on built-in abstractions was also relatively easy to understand - drawing on past experience with similar functions and styles in Python and especially Javascript definitely helped.</p>
<p>I think I&rsquo;ve said this something like five times before, but as always, you&rsquo;ll probably be very confused and disinterested in the contents of this article unless you&rsquo;re taking CPSC 110, or somehow have stumbled upon this in the interest of learning Racket (it&rsquo;s an experience). I&rsquo;ve put up the notes for the rest of the course up til this point in the posts preceding, so if you are indeed interested, <a href="https://kewbi.sh/blog/posts/">check those out</a>.</p>
<h2 id="notes---week-7">Notes - Week 7</h2>
<p>Week 7 discusses two one-of types (the cross product table), and local expressions.</p>
<ul>
<li>when a function&rsquo;s arguments have more than one type with one-of type comments, use cross product table to determine which cases to handle
<ul>
<li>design function based on model of function instead</li>
<li>create a table with the one of possibilities for type a horizontally, and possibilities for type b vertically
<ul>
<li>will have a box per case, which you can fill in with the desired behaviour for each case</li>
<li>often, can condense boxes that are next to each other and have the same behaviour (<code>#t</code>/<code>#f</code> cases)</li>
<li>collect into a <code>(cond)</code> expression</li>
</ul>
</li>
<li>helps with determining what to test =&gt; at least one per case in the <code>(cond)</code></li>
</ul>
</li>
<li>with more difficult behaviours =&gt; remember to keep natural recursion
<ul>
<li>even if this is a branching statement, keep in one <code>(cond)</code> QA pair</li>
<li>keep self-reference applying to the rest of the list (if it&rsquo;s one)</li>
</ul>
</li>
<li>we&rsquo;ve graduated to ISL =&gt; intermediate student language
<ul>
<li>one of its new feature is local expressions =&gt; function and variable definitions within a larger definition</li>
</ul>
</li>
<li>local expressions nest into another definition =&gt; <code>(local [(define x a)] (expression))</code>
<ul>
<li>any number of function or variable definitions are allowed =&gt; override any definitions outside of the local at top level</li>
<li>expression is evaluated to produce the result of the local</li>
<li>these local variables do not exist outside of the local =&gt; lexical scoping
<ul>
<li>definitions that exist at the top level are in the global scope</li>
<li>scope contours show where functions and variables are defined and redefined =&gt; like nesting boxes that only take the most specific one</li>
<li>definitions reference the innermost enclosing box =&gt; defaulting to top level</li>
</ul>
</li>
</ul>
</li>
<li>to evaluate local functions, use a method of renaming and lifting
<ul>
<li>combining all the rules previously learned =&gt; first start by substituting variables outside local as normal</li>
<li>then rename all local&rsquo;s references to a program-unique name</li>
<li>then lift the renamed definition into top level / global scope</li>
<li>then replace the local with a body expression</li>
<li>then replace any renamed definitions within the local with their values</li>
</ul>
</li>
<li>local expressions are used to encapsulate the ugly mutual reference functions, as well as prevent recomputing in recursive functions
<ul>
<li>encapsulation helps avoid practically, naming problems, and helps decomplicate the rest of the program
<ul>
<li>wrap the two mutually referential functions into a local definition, and run only one of the functions in the local expression (single)</li>
<li>delete all tests that reference the other definition (list), and rename the rest of the lists</li>
<li>can pre-encapsulate within the template, moving the same two function templates within a data definition&rsquo;s template</li>
</ul>
</li>
<li>in recursive functions, the time to evaluate a function rapidly increases =&gt; exponential
<ul>
<li>to avoid this, we wrap recursive function calls that are repeated in a local definition</li>
<li>look for the closest expression that wraps the function calls, and replace with pre-computed values =&gt; only compute these once, saving time</li>
<li>rename each of the function calls to the local definitions</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="notes---week-8">Notes - Week 8</h2>
<p>This week deals with using Racket&rsquo;s built-in abstract functions and creating your own. (Starting to get into things that are more closely related to what you stereotypically think of as functional programming.)</p>
<ul>
<li>abstraction helps reduce the amount of repetition in code, especially from templates that are very similar to each other
<ul>
<li>use function definitions to plug into other generalized function =&gt; more abstract fns</li>
</ul>
</li>
<li>basic example of abstraction =&gt; take several functions that are very similar, and make one generalized function that takes only the differing points as arguments
<ul>
<li>because most functions are directly based off templates =&gt; not much change between functions if same types and signature</li>
<li>add the check-expects for each function to the generalized function check-expects</li>
<li>add each argument to the check-expects and each function</li>
<li>edit the body of each function to make a call to the generalized function with its specialized predicate / differing points</li>
<li>purpose can just generalize to the main function</li>
<li>called higher-order functions =&gt; fns that call other functions</li>
</ul>
</li>
<li>signature and type notation is now changing =&gt; type inference
<ul>
<li>look at each argument =&gt; if it&rsquo;s a function that can apply to any types, instead of denoting the types that it uses, use abstract letters like X and Y
<ul>
<li>each function needs to be in parentheses =&gt; something like <code>(X =&gt; Boolean)</code></li>
</ul>
</li>
<li>look at argument functions that take in the same types, or produce the same types</li>
<li>also, can now use the <code>(listof X)</code> shorthand to avoid having to produce a data definition for the lists</li>
</ul>
</li>
<li>Racket also has a large number of built-in abstract functions:
<ul>
<li>check the type to input and the type to output, then find the corresponding function in the list below ⇓</li>
<li>build-list: <code>Natural =&gt; (listof X)</code></li>
<li>filter: <code>(listof X) =&gt; (listof X)</code></li>
<li>map: <code>(listof X) =&gt; (listof Y)</code></li>
<li>andmap: <code>(listof X) =&gt; Boolean</code></li>
<li>foldr (and foldl): <code>(listof X) =&gt; Y</code>
<ul>
<li>call with a function, a base case, and a list to operate on =&gt; similar to the list template</li>
</ul>
</li>
<li>can use these to form larger functions without all the template work</li>
</ul>
</li>
<li>closures =&gt; when a function requires access to a parameter part of the larger function =&gt; use local
<ul>
<li>for example, in a function with arguments x and fn1, where fn1 needs access to x</li>
<li>only passes one argument =&gt; unlike writing your own fold function where you have to pass all arguments</li>
</ul>
</li>
<li>produce your own fold functions from the template =&gt; abstract with each base case and function argument as an argument
<ul>
<li>in functions that you pass, then have to specify with all arguments of struct members</li>
<li>forex: fn1 that operates on an image takes two arguments now, not one like in closures</li>
<li>generally compose your own local functions to use in the fold function</li>
<li>can check like most other functions =&gt; just copy paste the check-expects over, wrapping functions as needed in local expressions</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>As of writing this conclusion, I&rsquo;ve actually managed to go through module 9 as well, so we&rsquo;ll see if I can manage to publish those notes soon as well. I can definitely see the course starting to ramp up in difficulty, but I think the design problems are a nice challenge, aside from the mundanity that can sometimes be trying to write check-expects and follow templates to a T. As I look back on each module, I&rsquo;m surprised to see how clear everything actually is - the first time round, everything certainly seemed a lot more difficult. I guess I&rsquo;ve just found that it really is impossible to try to rush through things, even the dull humdrum of copy-pasting stubs and templates and such. I&rsquo;m excited to see what the later couple weeks have in store, especially in terms of this magic they call &lsquo;functional programming&rsquo;.</p>
<p>I&rsquo;m also looking forward to making some more good progress before summer break, and seeing when I can finish the bulk of the course. I have several more modules left, but after that, I think I can start devoting more time to completing more start-to-end problems and tackling the practise finals from past years. Hopefully, I&rsquo;ll be able to finish up the course by June, though I genuinely don&rsquo;t know what else&rsquo;ll come up with school. I think I&rsquo;ve generally settled on challenging in September instead of the summer, which should give me some more time to prepare, and might hopefully lift a bit of the courseload (if I do manage to pass the challenge) in my first semester. I think I&rsquo;m well on track to this, and I&rsquo;m happy to start applying some of the more fun theoretical techniques to problems.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Weeks 5 and 6</title>
      <link>https://kewbi.sh/blog/posts/210328/</link>
      <pubDate>28 Mar 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On helpers and binary search trees.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Spring break is almost over, and perhaps so is my CPSC 110 sprint. For a lack of creative inspiration to work on anything other than practise problems, I&rsquo;ve been spending a good amount of my remaining break on very routine homework, including CPSC 110. The course&rsquo;s started to delve further into the theory side of things this couple weeks, and it&rsquo;s been very interesting to see how my methods for designing things in Racket have evolved with each successive module.</p>
<p>Part of me being able to complete a rather surprising (to me, at least) number of weeks over a short amount of calendar weeks was conveniently forgetting to do both the problem sets or labs for the past couple weeks. I&rsquo;d become part of my habit to do those after writing up a week&rsquo;s set of notes, but I think I got a bit too carried away somewhere in between weeks. In the process of having to go back and do said problem sets and labs, it was interesting to see how difficult it was to remember what techniques I was &lsquo;allowed&rsquo; to use. Somewhere between 6 and 7, some template rules get changed, and some shorthand is now added, which I almost reflexively tried to use before realizing I was supposed to operate in on a past set of guidelines while looking at problem set solutions. It&rsquo;s remarkable that I even forgot that there was a change in shorthand allowed - I think that&rsquo;s part of what makes CPSC 110 one of those fundamental courses: it encourages you to look at things very systematically, and builds on what you&rsquo;re supposed to do systematically, systematically. (In other words, the addition of new parts of information follows nicely from past weeks, and everything is consistent.)</p>
<p>As always, you&rsquo;re probably uninterested in the contents of this post unless you&rsquo;re taking CPSC 110 yourself or have the very niche interest of learning how to program in Racket. Feel free to check out some of my other posts (I promise I don&rsquo;t blather on about Racket this frequently usually, but Spring Break sort of encouraged me to do as much CPSC 110 as I could).</p>
<h2 id="notes---week-5">Notes - Week 5</h2>
<p>This week dealt with helper function design, as well as more information on inbuilt natural number functions.</p>
<ul>
<li>natural numbers are good to illustrate examples of self-referential data definitions
<ul>
<li>unlike lists, don&rsquo;t need to cons at all
<ul>
<li>the one off statement is either zero or <code>(add1 n)</code> =&gt; why it presents recursion</li>
</ul>
</li>
<li>use <code>(add1 n)</code> to add 1 to a number and <code>(sub1 n)</code> to subtract 1 =&gt; useful for recursion</li>
<li>add n to the template =&gt; easier to work with contribution of first rule</li>
</ul>
</li>
<li>function decomposition =&gt; breaking design problems down to one atomic purpose
<ul>
<li>in past weeks, we&rsquo;ve added helper functions: this week dives further into when to add them and how to do so</li>
</ul>
</li>
<li>places to put helper functions:
<ul>
<li>where there&rsquo;s a reference =&gt; natural place to insert a helper function
<ul>
<li>world design recipe =&gt; also using helpers</li>
<li>where types of what you&rsquo;re operating really changes</li>
</ul>
</li>
<li>when an expression operates on a list =&gt; arbitrarily far into the list
<ul>
<li>because this is a form of recursion</li>
</ul>
</li>
<li>when a function shifts into a new knowledge domain
<ul>
<li>knowledge domain =&gt; when you need to operate on a new facet of the data, or change what you need to &lsquo;know&rsquo;</li>
</ul>
</li>
</ul>
</li>
<li>essentially breaking everything down into individual steps for the problem =&gt; can begin seeing this in the <code>(check-expects)</code>
<ul>
<li>sometimes avoid referring to constants in these to fully illustrate the example</li>
<li>function composition only needs to test the composition
<ul>
<li>no need to deal with base case</li>
<li>can essentially test the two only together and call function in the check-expect</li>
<li>make it as obvious as possible if something&rsquo;s gone wrong</li>
</ul>
</li>
<li>work systematically referencing the wishlist as a todo list</li>
</ul>
</li>
</ul>
<h2 id="notes---week-6">Notes - Week 6</h2>
<p>This week describes binary search trees, as well as mutually referential data.</p>
<ul>
<li>have now graduated to BSL with List Abbreviations =&gt; use <code>(list 1 2 3)</code> to declare a list without all the <code>(cons)</code>s
<ul>
<li>if <code>(cons)</code> is applied to a list, concatenates it to the beginning</li>
<li><code>(append l1 l2)</code> takes two lists (not elements), and appends l2 to l1 so the list is flattened into <code>(list [elements of l1] [elements of l2])</code>
<ul>
<li>if you instead run list (or cons) on the two lists, you get a list containing two lists (not flattened, and with 1 list for <code>(cons)</code>)</li>
</ul>
</li>
</ul>
</li>
<li>here, we could use a self-referential data definition to create a list of any given element =&gt; concatenating an element onto the self-referential data def
<ul>
<li>can sort the list and use <code>(first)</code> and <code>(rest)</code> to traverse the list in order of magnitude
<ul>
<li>on average, n/2 elements searched</li>
</ul>
</li>
<li>however, faster on average to use a binary search tree, where elements are ordered on branches
<ul>
<li>middle value goes on the &lsquo;top&rsquo; of any given fractal part of the tree</li>
<li>smaller values go on the left, larger values go on the right =&gt; of a given element</li>
<li>balance the tree (shift things around) if it&rsquo;s looking sort of like a list =&gt; at that point you have no advantage</li>
</ul>
</li>
</ul>
</li>
<li>BST data definition utilizes compound data definitions with 2 self-reference cycles
<ul>
<li>create a struct with fields for BSTs for both left and right branches stemming from the given element
<ul>
<li>specify invariant rule =&gt; right/left interpretations</li>
</ul>
</li>
<li>run <code>(fn-for-bst)</code> on each self-reference =&gt; natural recursion</li>
<li>rendering BSTs =&gt; also with recursion
<ul>
<li>for the check-expects, remember to order according to test &lsquo;difficulty&rsquo; and test each case (right/left to right/left)</li>
</ul>
</li>
</ul>
</li>
<li>searching BSTs is a matter of determining whether the searched-for value is greater than, equal to, or less than the current node
<ul>
<li>then traverse either the left or right BSTs depending on above condition</li>
</ul>
</li>
<li>arbitrary arity tree =&gt; form of data that&rsquo;s arbitrarily large in two dimensions
<ul>
<li>arbitrary (as in length, can be an unspecified number of elements long), arity =&gt; arbitrarily long in two dimensions (folder =&gt; file)</li>
<li>to deal with these two dimensions, will need 2 cycles in type reference graph
<ul>
<li>generally have a data definition for an element, and one for its listofelement =&gt; use arbitrary data definition template</li>
<li>these two data definitions refer to each other =&gt; Element has a &lsquo;children&rsquo; field that refers to its list, and ListOfElement refers to Element in its <code>(cons)</code> branch of the one-of</li>
<li>known as mutual reference</li>
<li>reference arrows =&gt; describe mutual ref, then self ref, then find the normal ref</li>
</ul>
</li>
</ul>
</li>
<li>mutual reference template involves two HtDF problems, one of each type
<ul>
<li>name them with <code>([fn]--element)</code> and <code>([fn]--loe)</code>, or similar</li>
<li>at the points with a reference to the other type of mutual reference =&gt; insert a natural mutual reference recursion helper</li>
<li>test the base case (may not be the element case that&rsquo;s the simplest)
<ul>
<li>base case is the case in which no mutual reference is invoked =&gt; generally the empty or false of the LOE type</li>
<li>use <code>(check-expect)</code>s to clarify what the expected output will be</li>
</ul>
</li>
<li>usually, both functions produce the same type of data in the end</li>
</ul>
</li>
<li>backtracking search =&gt; use special signature of <code>[type] or [base]</code>
<ul>
<li>usually would be using something like an exception, except BSL doesn&rsquo;t have those</li>
<li>search for the desired value in all children, if not, runs on all siblings as well
<ul>
<li>if it produces false =&gt; check the siblings / rest of the LOE</li>
<li>use the <code>(if (not (false? (fn-for-loe))))</code> to check above condition</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>I&rsquo;ll save the notes for Week 7 for the next week I&rsquo;m looking for something share - I&rsquo;d rather keep the amount of double-weeks to a minimum. (I also doubt there&rsquo;ll be many more double weeks, since school&rsquo;s started again.) I&rsquo;m now past the midway point and on a good streak of work, so I hope I&rsquo;ll be able to finish the course well before school ends in June. I plan to spend some of the summer revising for the challenge before I actually take it, which I hope will be enough time. I&rsquo;ve looked at past exam papers, and they don&rsquo;t seem too bad at first glance, so let&rsquo;s hope a couple months of review is enough.</p>
<p>In other news, I helped run a hackathon this weekend, which was an amazing experience. <a href="https://vhhacks.ca">vhHacks 2021</a> was a super fun event to organize, mentor, judge, and run workshops for, and I was incredibly impressed at everything that was submitted (so congrats!). The majority of hackathon-esque events I&rsquo;ve been to have been online, which is usually something people label as &lsquo;unfortunate&rsquo;, but to be honest, there&rsquo;s something sort of nice about async hackathons and weekends spent grinding away alone at a project in the comfort of your office. I hope some of the wholesome hacker vibe that I personally got at my first online hackathon was successfully transmitted somewhere in the process, and that, most of all, it was fun<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I might write a bit about organizing the hackathon (not that I know what to write about regarding the entire event) in the future, but for now, I&rsquo;ll go back to catching up on problem sets and labs.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Preliminary survey results with people I know has been positive, but I&rsquo;m entirely sure they&rsquo;re biased and at least 50% trying to validate me, which is still much appreciated. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Weeks 3 and 4</title>
      <link>https://kewbi.sh/blog/posts/210314/</link>
      <pubDate>14 Mar 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On trusting the natural recursion.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Spring break has just begun, and I&rsquo;ve decided to devote some more significant time to CPSC 110. It helps that I&rsquo;m sort of floating between projects and want a bit of bland coursework to churn through at the moment, so I&rsquo;ve been spending my leisure time listening to Kiczales go on about data and recursion. I&rsquo;ve been ramping up my progress with CPSC 110 for the last couple weeks, and I&rsquo;ve managed to do a couple &lsquo;weeks&rsquo;, or modules, since I last published a set of notes. Regarding my old end date goal, I&rsquo;ve decided to shift my goal more towards a September challenge (of the exam), to give myself time over the summer to cram and practise with old papers. (Ironically, I&rsquo;d also decided at the beginning of the year that I&rsquo;d take this summer to rest and relax before university, but I suppose that&rsquo;s gone out the window in lieu of some hopefully more engaging plans. And hey, if I choose to relax that way, I guess it&rsquo;s a perfectly fine thing to do.)</p>
<p>After getting back in the swing of Racket and relearning the templates and design recipes, these couple modules haven&rsquo;t been too challenging. Adding systematically onto the recipes makes the logical jumps between concepts less sharp, and makes the course much less intimidating. Having a repository and tracking my progress with the course has definitely motivated me to work on it more. So, here&rsquo;s a couple modules' worth of notes - but as always, if you&rsquo;re not following along with CPSC 110 or have no interest in learning about compound and arbitrarily long data, you might want to go off and read a <a href="https://kewbi.sh/blog/posts/210307/">different post</a>.</p>
<h2 id="notes---week-3">Notes - Week 3</h2>
<p>Week 3 goes over how to define compound data (essentially adding structs to the data definition recipe), and integrates that data in building &lsquo;worlds&rsquo;, or GUI programs. Having a proper definition for data simplifies things in future weeks, and makes the data definitions seem more solid or &lsquo;real&rsquo;, in my opinion.</p>
<ul>
<li>ticks =&gt; update behaviour, but can be changed by interactive input
<ul>
<li>tick rate is defined by the program, can change</li>
<li>can use a data definition to interpret the current state</li>
</ul>
</li>
<li><code>(big-bang)</code> function used to make these graphical programs =&gt; called worlds
<ul>
<li>import <code>(2htdp/image)</code> and <code>(2htdp/universe)</code></li>
<li>use <code>(place-image)</code> and the <code>(empty-scene)</code> frequently to draw and render</li>
<li>rendering is done by setting the <code>(to-draw)</code>, and tick behaviour by <code>(on-tick)</code>
<ul>
<li>later use <code>(on-key)</code> and <code>(on-mouse)</code> to handle those behaviours</li>
</ul>
</li>
</ul>
</li>
<li>start by doing a domain analysis =&gt; what remains constant and what changes each tick
<ul>
<li>each function is first wish-listed as the overall world is structured</li>
<li>apply HtDD to design the program state data =&gt; structs in second half of week</li>
<li>apply standard HtDF to create functions used in big-bang</li>
<li>use constants in the <code>(check-expect)</code>s to maximize adaptability</li>
</ul>
</li>
<li>use <code>(define-struct name (args))</code> to define compound data =&gt; data that relate to each other
<ul>
<li>when expression run, generates the <code>(name?)</code>, <code>(name-args)</code>, and <code>(make-name)</code> operators</li>
<li>in HtDD example definitions and tests =&gt; now have to use <code>(make-name (args))</code>
<ul>
<li>include the data types here and intervals if using Naturals or Numbers</li>
</ul>
</li>
<li>need to add interpretation for data types with the <code>;; Name is ...</code> comment</li>
<li>add interpretation for each field in HtDD interpretation comment</li>
<li>HtDD <code>(fn-for-name)</code> now includes each of the fields used in the args</li>
<li>include number of fields with the compound keyword when listing template rules used</li>
<li>when using HtDF =&gt; add constraints and notes in the tests =&gt; clarity of examples and behaviour</li>
</ul>
</li>
<li><code>(on-mouse)</code> and the <code>(on-key)</code> events are handled with an overall cond
<ul>
<li>will take mouse event / key event as argument</li>
<li>need to check the state / key with <code>string=?</code> or <code>key=?</code></li>
</ul>
</li>
<li>use helper functions where possible to ensure function does one thing</li>
</ul>
<h2 id="notes---week-4">Notes - Week 4</h2>
<p>In Week 4, Kiczales discusses arbitrarily sized data, which is basically a convoluted way of working with lists. This week also has to deal a lot with recursion, which is something I&rsquo;ve sort of avoided as much as possible in the past. However, it&rsquo;s been pretty interesting to see how to solve problems recursively, which I think will come in handy down the line.</p>
<ul>
<li>we use recursive data definitions to model arbitrarily sized data =&gt; compound data
<ul>
<li>set a base case (empty, or false), as well as <code>(cons)</code>&lsquo;ing it with an element and then the original data definition
<ul>
<li>this element can be atomic non-distinct data, not just another data definition (reference)</li>
</ul>
</li>
<li>an example of self-reference, where the data definition involves itself</li>
<li>new primitives: <code>(first list)</code> returns the first element, and <code>(rest list)</code> returns everything but the first element</li>
</ul>
</li>
<li>with HtDF, several things have changed to accomodate new branches
<ul>
<li>refer to the type comment and how it refers to itself =&gt; preserve that in the function templates</li>
<li>template now needs to apply a <code>(fn-for-element)</code> for the first element
<ul>
<li>this should be another helper function generally, want the function to do one thing at a time</li>
</ul>
</li>
<li>template applies the <code>(fn-for-list)</code> for the rest of the list</li>
<li>generally use a <code>(cond)</code> to check if the list is empty (base case handling)</li>
<li>examples can help clarify the behaviour of the function first, and show where you might need helpers
<ul>
<li>also insert tests for base cases themselves</li>
</ul>
</li>
</ul>
</li>
<li>positions in list templates matter and have their own functions
<ul>
<li>base =&gt; when the function exits and &lsquo;bottoms out&rsquo;</li>
<li>contribution of first =&gt; the first element (type checking generally goes here)</li>
<li>combination =&gt; check other cases or perform operations on the value of the rest of the list</li>
</ul>
</li>
<li>when the recursive data definition handles another data definition =&gt; reference rule
<ul>
<li>produces a natural helper =&gt; abstract this to another function</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>As I write this, I&rsquo;m actually halfway through week 5, but it&rsquo;ll take me a good while to write up that double module&rsquo;s notes properly, and I&rsquo;d rather not extend this post too much. I&rsquo;m also almost at the halfway mark of the whole course (yay me!), but I&rsquo;ve noticed that most of the next modules are broken up into a and b sections, so I expect it&rsquo;ll probably be more work than the first couple weeks. I&rsquo;ve heard that the later weeks heavily build on the beginning weeks, so I might come back and update my notes posts every so often. I hope I&rsquo;ll be able to at least go through another couple weeks before spring break ends, but I also want to take enough time to relax and recharge<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>I have no big plans with regards to projects at the moment - I&rsquo;m just trying to keep everything stable before I graduate, and continue to explore opportunities I might like to take after I enter university. It&rsquo;s rather scary that I&rsquo;ll be an actual university student in a couple months, and that my quintessential &lsquo;high school experience&rsquo; is nearly over. A post about Racket is probably not the best place to digress into all the amazing experiences that&rsquo;ve filled the last couple years, but I will say it feels a bit strange to consider that I&rsquo;ll be one of &lsquo;them&rsquo; (an actual student) in the fall, and that I have no idea what I have time for left in the last three (well, two and a half, if we&rsquo;re going to be precise) months. Well, we&rsquo;ll figure it out eventually (and finish CPSC 110 somewhere in the process too).</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I suppose you can start laughing now, but I&rsquo;m trying, alright? <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Towards Web Monetization</title>
      <link>https://kewbi.sh/blog/posts/210307/</link>
      <pubDate>07 Mar 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On speculations about the future of WM.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>It&rsquo;s funny how scholarship essays can prompt thinking on topics you thought you&rsquo;ve forgotten, and spark new thoughts even after you&rsquo;ve penned your profile and sent it off to the selection committee. I applied to something recently, in which I had to go through the usual drivel of describing far-off plans for my future. I talked a bit about open source and a bit about leadership, but the part that&rsquo;s stuck with me was a part about impacting the future of the web. &lsquo;Reinventing the web&rsquo; seemed a bit lofty and grandiose, so I chose to focus a bit about my experience with Web Monetization.</p>
<p><a href="https://webmonetization.org/">Web Monetization</a> is something that&rsquo;s been on my mind&rsquo;s back burner since the hackathon <a href="https://dev.to/devteam/announcing-the-grant-for-the-web-x-dev-hackathon-winners-1nl4">Dev.to</a> hosted. (I&rsquo;ve written a post about the hackathon over <a href="https://kewbi.sh/blog/posts/200531/">here</a>, if you&rsquo;re interested.) If you&rsquo;re not familiar with Web Monetization, I highly recommend checking their website out, and looking at some of the projects and discussion that&rsquo;s sprung up around it. A four-way partnership between Mozilla, Creative Commons, Dev.to, and Coil, the hackathon encouraged people to build new toolkits to implement WM to work with and extend web environments. I&rsquo;d initially gone into it purely for the technical challenge <del>and for a chance at merch</del>, and had approached my second project, a GitHub revenue sharing Chrome extension also based on WM, with a similar perspective.</p>
<p>However, as I&rsquo;ve continued to see articles pop up every now and again about WM, I&rsquo;ve started to think a bit more about the monetization models of the web today, and how WM can potentially augment, extend, and change them. For example, there&rsquo;s these big tech giants who are <em>stealing all our data</em> and <em>greedily injecting ads wherever they can</em> and generally not doing very privacy-, or even human-friendly things. There&rsquo;s the counter-argument and justification that content has to be paid for in some way in order to produce it with any acceptable quality. There&rsquo;re perfectly rational people who would really rather not have to pay for anything, but have gotten roped into a couple larger publications and subscription instead of smaller, indie ones because bigger sources provide a higher sheer volume of content to consume - and hey, that technically equates to better money spent, right? There&rsquo;s the Substack revolution, and the rise of the independent web while people espouse the benefits and inherent aesthetic qualities of a more open web. There&rsquo;ve been ad-blockers, ad-blocker blockers, and ad-blocker blocker blockers, and who knows how long the war between corporation and Chrome extension will go on.</p>
<p>Web Monetization, to me, is a better fit for the &lsquo;indie web&rsquo;, as they call it, rather than larger, more clunky companies. With clear examples of hiding ads for paying users (a model that exists already), adding new content for paying consumers (augmenting the private subscription model), and sharing revenue (simplifying a model), they&rsquo;ve come up with an alternate pathway for monetization besides slapping ads between a couple paragraphs. Most of the sites I can see potentially adding this are the types of sites that don&rsquo;t even have ads in the first place, and it&rsquo;s an interesting possibility to investigate this more passive stream of revenue.</p>
<p>I&rsquo;ve been thinking about Web Monetization and the opportunities it presents ever since I wrote the essay. It&rsquo;s an interesting way to add new monetization streams on the web and rework existing ones - however, like most things, I think there&rsquo;s still some steps to be taken before we can see how WM will evolve and adapt<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<h2 id="project-check-ins">Project Check-ins</h2>
<p>Before I step into some of the issues and future possibilities I see in WM, I&rsquo;d like to check in on the state of some of my own projects in the WM area, and see how they&rsquo;re doing as WM evolves.</p>
<p>Let&rsquo;s start with <a href="https://github.com/kewbish/revshare">kewbish/revshare</a>. Long story short, it&rsquo;s a Javascript library with a couple custom web components to split payment. Instead of sending everything through to a central payment pointer and letting whoever&rsquo;s in charge of accounts to share revenue, all users need is a single JSON object linked to a rather janky component. This would update the monetization tag that&rsquo;s required to stream micropayments, and therefore change the stream of revenue. (Imagine an editor, writer, and photographer working together on an article - this way, they can split money according to their agreed-upon percentages, without having to deal with doling out the cash themselves.) People seem to still be using the project somewhere (or perhaps the NPM statistics are simply lying to me) - as of the writing of this post, I have something like 6 downloads this week. It&rsquo;s a small number, but it&rsquo;s infinitely more than what I&rsquo;d expected, and it&rsquo;s nice to know people are out there somewhere in the world using it.</p>
<p>Interestingly, as I was checking up on the general state of Web Monetization earlier this year, I noticed that WM had linked their own <a href="https://webmonetization.org/prob-revshare">revshare generator</a>, which does the same thing as Revshare, but in a probably easier-to-use format. While I&rsquo;m slightly miffed (no, I&rsquo;m really not, no one much was using the revshare project anyway, and I&rsquo;m happy that there&rsquo;s an easier way to split payments than loading in a JSON object and using scuffed custom web components), it&rsquo;s good to see that they&rsquo;ve started coming up with some of their own tools to facilitate solving some of the issues I&rsquo;d been having when I started out.</p>
<p>The second project I&rsquo;ve worked on involving WM is <a href="https://github.com/kewbish/revshare-gh">kewbish/revshare-gh</a><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, which is Revshare, but with GitHub Sponsors payment pointers and a little dependency kickback. GitHub Sponsors has a custom field or two in which project maintainers can fill in a WM payment pointer from whatever provider, which then gets added to the monetization tag, feeding creators a bit of revenue while people browse the repo. It also splits about 50% to whatever dependencies the project uses, if a WM payment pointer is present in the dependency repo&rsquo;s GH Sponsors tag. The idea was that open source maintainers could make a bit of cash off people browsing their repos, and also give some back to the projects that helped build it up.</p>
<p>As I&rsquo;ve continued to think over this idea, I&rsquo;ve realized that there&rsquo;s two main issues. One, there&rsquo;s a bit too much friction between the user (not the owner of the GH repo, but the user who&rsquo;ll be paying). Revshare-GH was built in the form of a Chrome extension, and I&rsquo;m not sure people would be willing to take the time to install and add their GH token to provide more support to maintainers. Even if you&rsquo;re paying, there&rsquo;s not any value added to the repo, and I don&rsquo;t think any fancy special content can be loaded, since Markdown doesn&rsquo;t have access to Javascript. Yes, I could rig up an external service to connect exclusive content locations to people who choose to donate, but I think that&rsquo;s best handled on the GH side of things. If GitHub itself includes WM tags as a repo option, this friction would be gone, and I&rsquo;d be inclined to think that people would be more enthusiastic about the project. Two, the amount of revenue kicked back to the creator would be minimal, and I&rsquo;m not sure if people would bother to include their payment pointer and ask their consumers to set something like this up for a couple cents a week (more on this a bit later). From my own browsing habits, I tend to only check repos out for a couple minutes, skimming the README and perhaps looking into a bit of the code if I&rsquo;d like to borrow a technique. If I&rsquo;m looking at the documentation, I&rsquo;ll stay for a bit longer, but oftentimes docs are hosted elsewhere from GitHub, meaning that the standard method of WM would likely work better there anyway.</p>
<p>Regardless of the problems I&rsquo;ve found, I&rsquo;m still happy with these two projects. They solved problems back when they were being created, which was the entire point of the exercise of working on them anyway.</p>
<h2 id="we-need-more-providers">We Need More Providers</h2>
<p>Coming back to WM itself, I think one of the more glaring issues seems to be adoption, specifically with WM providers. There are only a couple wallet providers, one or two search engines and browsers, a handful (though a healthy one at that) of platform integrations, and only one payment provider, Coil. That seems to be a bit sparse.</p>
<p>Part of this seems to be the feedback loop where companies don&rsquo;t see the benefits of investing in creating a payment processor for a niche area of monetization when there isn&rsquo;t widespread adoption and low profits to be made. In turn, because there&rsquo;s low adoption among existing companies, users perhaps don&rsquo;t see the point of creating a whole new account and subscribing to yet another service. Developers see that few people have accounts, and without a wallet at one of the few providers, might decide that the possible revenue would be too low to bother spending valuable time on it. And without high-profile companies integrating WM into their products, competing companies wouldn&rsquo;t bother to use WM, and so the cycle continues.</p>
<p>When I was participating in the Dev.to hackathon, I&rsquo;d honestly not have bothered to make a Coil account if they weren&rsquo;t giving a couple months of it away for free. (I&rsquo;m also not legally allowed to reap any of the benefits yet, which is part of the reason I haven&rsquo;t bothered to WM any of my sites or posts, but perhaps I will sweet talk my parents into something if I ever feel like it.)</p>
<p>Perhaps another part of this is that the <a href="https://webmonetization.org/specification.html">spec itself</a> hasn&rsquo;t been finished yet, and hasn&rsquo;t gone through whatever magic goes on at Google and Mozilla and all the tech giants before something gets integrated into major browsers, if at all. There still seems to be a good amount of activity on the spec and the GitHub, so I&rsquo;m excited to see how WM will spread and be adopted if something like Chrome adds it as an API. With it as a default option available in the browser, the potential audience of WM work is opened up from just tech-nerds with niche browsers (no shade), to a more general audience<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Developers, payment processors, wallet providers, and content creators will be more inclined to start WM&rsquo;ing their content - instead of a couple cents here and there, perhaps WM can start augmenting and eventually acting as a proper stream of revenue.</p>
<h2 id="for-the-consumer">For The Consumer</h2>
<p>Articles on WM generally center around the possibilities of revolutionizing the monetization models prevalent on today&rsquo;s web by shifting away from ads and towards user-initiated micropayments. While WM certainly has the capabilities to prompt a move away from ads (it even has a handy example on its docs detailing exactly how to do so), I think it&rsquo;ll take a lot of time and promotion before WM starts growing to something that even a decent fraction of an app or content creator&rsquo;s userbase will readily have.</p>
<p>With the ads-based models that seem to be the standard on the web, users don&rsquo;t have to physically (well, digitally) fork over any payment. The money creators make is not <em>directly</em> from you, but is still from you - your data, your analytics, and your preferences. The important thing, though, to note, is that the consumer never sees any of this, and even though the news has hopefully blasted the fact that companies are building scarily accurate profiles about you without your knowledge, it&rsquo;s taken for granted that things are &lsquo;free&rsquo; on the web. I&rsquo;ve asked my parents about this before, and they seem pretty nonplussed (&lsquo;I have nothing to hide - try to make me buy whatever you want&rsquo;).</p>
<p>Even if people pay, things seem to be easier and seem to be more &lsquo;worth it&rsquo; by supporting existing, larger organizations. A subscription to an online newspaper gives a reader access to exclusive breaking news, and hundreds of stories. A Patreon subscription might only give access to a couple of posts - and same goes for some of the new custom platforms creators are using to sell early access, special, or otherwise gatekept content. In order for WM to gain a wider adoption, I think it&rsquo;s necessary to shift people more towards indie sites, or towards sources of monetized content, so people feel comfortable with the process. Besides the technical limitations today (I don&rsquo;t think managing ILP wallets is something that most people would bother with to get started - I&rsquo;d think twice), it&rsquo;ll take time for the internet to shift to accept these models of monetization, and to trust in paid content. An interesting thing to note about the Substack revolution (is that what they&rsquo;re calling it?) is that it&rsquo;s hopefully prompting people to ask where they get their content from, and to contemplate the value of what they consume - is it worth a couple dollars a month? Hopefully, this, and other micro-monetization movements will pave the way for WM, and get people more comfortable with the idea of having to pay for things.</p>
<h2 id="conclusion">Conclusion</h2>
<p>WM is genuinely pretty cool. I think it&rsquo;s a possible stepping stone in the long pathway towards a more indie web community, and in the meantime, a nice way to get a couple cents where you otherwise might not have. It might also be a step to get people to more actively seek ways to control who&rsquo;s taking their data and money, but at the cost of having to knowingly give away money. It&rsquo;s interesting to ponder how WM can potentially rework monetization models that are now the norm, but it&rsquo;ll take a lot of adoption and investment into spreading the API first.</p>
<p>There are a lot of &lsquo;but&rsquo;s in the thoughts I&rsquo;ve been having about WM, but (haha, another one) I think it&rsquo;ll come with time. The recent uproar around NFTs (hey, even the local news aired a segment) proved that people are interested in this whirlwind of new money coming into cryptoart, and who&rsquo;s to say the same attention won&rsquo;t eventually turn to micropayments and other methods to monetization? Hopefully, widespread adoption and user comfort will increase with time, and we&rsquo;ll get to see WM as a cornerstone of a new age of the web.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Also, in an interesting turn of events, another article about Web Monetization popped up on <a href="https://news.ycombinator.com/item?id=26375857">HackerNews</a> just as I was going to write this, and there&rsquo;s some interesting discussion happening in the comments. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I have a vague feeling that if I don&rsquo;t mention Aadi for giving me the idea (thanks buddy), he&rsquo;ll be at least somewhat annoyed, so I&rsquo;ll add this here. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>They say RSS died away because it was never integrated directly into the browser, with explicit features to follow and interact with feeds. I&rsquo;m not entirely sure of the truth behind that, but I think that by increasing the size of the WM userbase, people will be more incentivized to use it, especially if it&rsquo;s built into a popular browser in an easy-to-understand way. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>CPSC 110: Week 2</title>
      <link>https://kewbi.sh/blog/posts/210221/</link>
      <pubDate>21 Feb 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On designing data in Racket.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Somehow through the whirlwind couple months it&rsquo;s been, I&rsquo;ve neglected to touch CPSC 110 at all. I&rsquo;ve been mostly focused with fixing <a href="https://github.com/kewbish/matter">Matter</a> up and adding all the quality-of-life features I&rsquo;d want in order to designate it a main information source. But that&rsquo;s besides the point: I&rsquo;ve decided I want to finish as much of CPSC 110 as I can before spring break, or at least during it. At the latest, I&rsquo;d like to sort everything out by summer, and see if I can finagle myself a spot in the summer session (fingers crossed).</p>
<p>I&rsquo;ve made myself a proper CPSC 110 repo and even bothered to figure out how to convert GUI DrRacket files into ones Vim can handle, so hopefully I&rsquo;ll be more motivated to solve the problem sets properly. Before I dove into this week&rsquo;s material, I had to rewatch most of week 1 to relearn the function recipes again, but I&rsquo;ve made more notes this time round (and referred to the ones on my blog - I told y&rsquo;all it would come in handy). Going into the data definitions section wasn&rsquo;t actually much of a challenge once I went through and watched the videos again.</p>
<p>The design recipes, as Kiczales mentions, are becoming ingrained into my memory now. It&rsquo;s very intuitive how they all slot together, and though sometimes it feels extremely repetitive to keep making examples and stubs, I can see why it helps when debugging more complex parts on top of the recipe. This week, I&rsquo;d gotten ahead of myself and briefly tried to do things with structs, but that really wasn&rsquo;t the point of this week yet (I&rsquo;m told it&rsquo;s part of week 3.). It&rsquo;s rather surprising to see how each recipe and definition builds on the others, though sometimes I&rsquo;m left wondering if all these conventions are really all that useful.</p>
<p>If you&rsquo;re uninterested in wrangling with data definition recipes, this might not be very fascinating, but I think keeping this as a record of what I&rsquo;ve been doing with Racket will be helpful for later revision.</p>
<h2 id="notes">Notes</h2>
<p>Week 2 deals with designing data, and how to create data definitions that work with the function definition recipe.</p>
<ul>
<li>cond expressions are if statements with multiple branches
<ul>
<li>use square brackets to test the question =&gt; <code>[(Q) A]</code></li>
<li>if only else body =&gt; the then block is evaluated instead</li>
<li>evaluation steps: evaluate the first expression&rsquo;s Q block
<ul>
<li>if it&rsquo;s false, it gets removed from evaluation</li>
<li>keep evaluating and removing until you meet a true block, then return the answer</li>
</ul>
</li>
</ul>
</li>
<li>data definitions =&gt; information represented in problem domain, and restricts what is allowed
<ul>
<li>type signature comment, what it is</li>
<li>interpretation of what the data is supposed to represent</li>
<li>examples of the data =&gt; &lsquo;one of&rsquo; comments</li>
</ul>
</li>
<li>atomic non-distinct =&gt; can&rsquo;t break into meaningfully smaller pieces
<ul>
<li>now have a data driven template =&gt; <code>fn-for-x</code>, then have a body from the table
<ul>
<li>never actually use it, so keep it commented</li>
</ul>
</li>
<li>when atomic non-distinct =&gt; <code>(... x)</code>, if distinct, then just <code>(...)</code>
<ul>
<li>write a comment detailing the data driven template body type</li>
</ul>
</li>
</ul>
</li>
<li>following the HtDF recipe is easier to understand + already learned metadesign
<ul>
<li>function recipe is independent to data definitions, so don&rsquo;t need to learn a new one</li>
</ul>
</li>
<li>interval data definition =&gt; numbers within a certain range
<ul>
<li>when giving type comment, use range =&gt; use proper interval notation</li>
</ul>
</li>
<li>enumeration =&gt; two or more distinct values
<ul>
<li>for rules used, add &lsquo;one of&rsquo;, and the number of cases / subclasses</li>
<li>use a cond to represent each case in body</li>
<li>don&rsquo;t need to use examples =&gt; add comment to explain redundancy</li>
</ul>
</li>
<li>itemization =&gt; two or more categories, but one or more of which isn&rsquo;t distinct
<ul>
<li>for example, a preflight, postflight, and inflight altitude</li>
<li>type guard required for each case if mixed data types</li>
<li>last condition will be an else, because we know that by process of elimination it must be that value
<ul>
<li>if all remaining data types are same data type, no guard needed</li>
</ul>
</li>
</ul>
</li>
<li>amount of tests will differ based on the data
<ul>
<li>with an interval =&gt; closed boundaries and midpoints (~3)</li>
</ul>
</li>
<li>when using HtDF with own data definitions =&gt; can reuse template
<ul>
<li>function recipe and prompt gives information about tests, etc</li>
<li>design behaviour of function while designing tests</li>
</ul>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>I actually managed to work my way through the lab and problem set while trying to learn the material at the same time (not very fun, do not recommend because you&rsquo;ll be very confused at the conventions that the example solution assumes), so I developed my own way of doing things the first time. It was interesting to contrast how I took shortcuts the first way round: not putting down enough <code>check-expect</code>s or ignoring the stub parts of recipes. Again, sometimes it really does feel like a chore to have to repeat the steps over and over again, but maybe that&rsquo;s part of how you learn things<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>Spending a month and a bit away from Racket, then suddenly returning was a bit disorienting at first - I had to familiarize myself with the syntax again, and the various builtins. The way I write Racket has been tinted a lot by the procedural way of doing things that&rsquo;s been prescribed by the course, so it was an experience to go from writing essentially whatever fit without much proper testing (Matter), to having to make testing an integral part of the programs.</p>
<p>I&rsquo;d forgotten how much fun listening to 2x lectures was - I suppose it&rsquo;s just part of the natural recursion<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. I&rsquo;ve been trying to make CPSC a priority in my free time (of which I have very little - oh, the woes of senior year), so hopefully I&rsquo;ll be back next week with either more notes or a proper post. I have ideas for both, but we&rsquo;ll see.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>No matter how many times Kiczales repeats the fact that whatever semicolons is a comment and whatever semicolons is for a stub or purpose, I cannot remember. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I don&rsquo;t think I&rsquo;ve gotten far enough in for Kiczales to have made the joke yet, but I&rsquo;m still somehow aware of this. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>After Code-in</title>
      <link>https://kewbi.sh/blog/posts/210214/</link>
      <pubDate>14 Feb 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On GCI&#39;s impacts over the last year.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Yes, today is Valentine&rsquo;s, and today is three days before something is due, but today is also exactly one year after I wrote the first post on Yours, Kewbish. (I think I thought the date would be funny, but that&rsquo;s besides the point.) I know absolutely everyone says this, but it&rsquo;s hard to believe it&rsquo;s been a year already since then. The span of time between last February and now feels like ages ago, but it also feels extremely short. Quarantine and the endless routines of work have morphed time into some non-Newtonian fluid, and I can&rsquo;t make sense of how it&rsquo;s been an entire year since then.</p>
<p>In this past year, I genuinely feel like I&rsquo;ve gained so much (yes, I know everyone says this as well): in terms of friendships, experiences, and skills, even though it&rsquo;s mostly been behind a screen. Essentially living online has its challenges, but I honestly wouldn&rsquo;t regret the past year. I never did a proper year in review, so maybe this might be a nice place to catalogue my progress over the last three hundred something days.</p>
<h2 id="gci">GCI</h2>
<p>GCI stands for Google Code-in, one of Google&rsquo;s sadly now terminated competitions, and the subject of <a href="https://kewbi.sh/blog/posts/200214/">my first YK post</a>. In short, several thousand teenagers from across the world slaved away day and night for two months to make at least somewhat useful contributions to open source. It&rsquo;s aimed to introduce the grand world of open source to a larger teen audience, and in that respect, I think it&rsquo;s accomplished its goal excellently. Despite the slight dip in my grades and general impact to my mental health, I wouldn&rsquo;t have gotten to where I am without the competition. Though I would hesitate to repeat the experience, I&rsquo;m glad I participated: it&rsquo;s served as an accelerator for my development in, well, development.</p>
<p>In retrospect, GCI may not have been the best at encouraging people to go in-depth into technologies, but it&rsquo;s an excellent opportunity to explore a large amount of areas in open source. (It leans heavily on breadth, though to succeed, you&rsquo;ve also got to balance in depth with more difficult tasks.) The list of areas GCI introduced me to includes, but is not limited to: bash scripting, Linux, VMs and trying to get those to network, KML + other Google Earth-specific features, Arduino, and a bunch of different languages and scripts. I&rsquo;ve probably already forgot all the tasks and problems I puzzled through in my spare time those seven weeks, but I&rsquo;m sure there&rsquo;s much more that I&rsquo;ve learned.</p>
<h2 id="experiences">Experiences</h2>
<p>Besides inspiring me to investigate these areas, GCI also prompted me to go discover a host of development opportunities and companies that offered internships and programs. I&rsquo;ve had decent successes, and I can&rsquo;t help but trace their inspirations and origins back to GCI.</p>
<p>I think one story particularly stands out: after GCI, through some mostly unrelated posts, I learned about Dev.to, another technical community, which was running a hackathon at the time. Originally, I had planned to participate just for the participation prizes, but I ended up <a href="https://github.com/kewbish/revshare">surprisingly winning</a>. I was in physics class when they announced the winners, and it took me approximately the duration of one practise problem to actually realize I was on the list. With the work from this hackathon, I continued to work on <a href="https://github.com/kewbish/revshare-gh">another smaller project</a>, which became my CS50 project. I&rsquo;m still regularly checking in on the Web Monetization proposal every so often, and I&rsquo;m excited to see how the implementation and adoption of other WM ideas go in the future. I can see so many connections between the programs I&rsquo;ve participated in in the past, and despite COVID, I&rsquo;m grateful for where I&rsquo;ve come to with these projects.</p>
<p>I genuinely credit GCI with rapidly accelerating my skills, as well as with letting me meet a bunch of amazing mentors, developers, and friends. There are too many to list and link (and I&rsquo;d feel rather bad about missing people), so I&rsquo;ll just leave this in as a very appreciative acknowledgement of everyone in the community - y&rsquo;all know who you are. Without GCI, I don&rsquo;t think I&rsquo;d have applied to various fellowships, participated in a myriad of hackathons, started writing this very blog, or even switched to Linux<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. It&rsquo;s truly unfortunate that the program&rsquo;s shut down - I would have had so much fun mentoring in later years. Oh well.</p>
<h2 id="writing">Writing</h2>
<p>I also want to touch briefly on writing, and this blog in general. I started writing more frequently because of Dev.to (they had a badge for streaks that I may or may not have wanted as a cosmetic). I built a rhythm there, but continued it even as I drifted away from crossposting there. Though I cringe when I look back on older posts, I think Yours, Kewbish has still been a valuable way to keep track of what was in my mind and when last year. It&rsquo;s only been a year, but keeping memories alive on my blog will be a fun way to look back when I&rsquo;m a bit older.</p>
<p>Maybe it&rsquo;s just my subjective opinion, but I also think my writing style and skills have slightly improved throughout this experience. I think that writing so often led me to begin to understand what my voice is, and I look forward to continuing to develop it as I grow. Part of it&rsquo;ll come with time, I hope, but having regular posts to write also made me realize what ideas I had that I wanted to share with <del>the, what, four people who read my blog</del> the world. I&rsquo;d like to continue writing here as frequently as I can - I&rsquo;ve plotted out a bunch of ideas I have for things I&rsquo;d like to share, if I have the time.</p>
<h2 id="conclusion">Conclusion</h2>
<p>A lot has happened this year. I think 2020, while it was perhaps not the best year in other regards, was the first year I became more involved in programming, furthering not only my technical skills, but also introducing me to many experiences and opportunities. I&rsquo;ve made a lot of friends, a lot of memories, and had a lot of fun this year despite everything that&rsquo;s been going on in the world, and I&rsquo;m grateful for that. There won&rsquo;t be a GCI in 2021, but there&rsquo;ll be other opportunities for me to have a go at. I don&rsquo;t know what my GCI, or my yearly accelerator, will be this year, but I have a feeling it might be university.</p>
<p>I suppose this wouldn&rsquo;t be complete without thanking whoever&rsquo;s reading this: thank you for tolerating my overly nerdy, sometimes long and windy, very quirky writing, and thank you for following along as I try to figure out what I&rsquo;m developing. I&rsquo;d be writing this regardless, even if it were to an audience of none, but thanks for getting all the way here<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I also suppose GCI is therefore responsible for me being called &lsquo;Linux kid&rsquo;, but it&rsquo;s tolerable and endearing enough. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Unless you&rsquo;re reading this in voice, and I&rsquo;m deafened in the corner, in which case I will rescind my thanks. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>A Month of Articles</title>
      <link>https://kewbi.sh/blog/posts/210207/</link>
      <pubDate>07 Feb 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On tracking every single article I read in January.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I&rsquo;ve been thinking more about the things I read: content, perspective, and contribution to my mindset in some form. As of now, content-wise, I prefer a mix of technology, meta-productivity, or knowledge-building. I don&rsquo;t have a preference as to perspectives, but contrasting thoughts from very passionate and very noncommital points of view can be interesting. Recently, I&rsquo;ve been mostly focusing on thinking about how what I read fits in, contribution-to-knowledge-wise.</p>
<p>This series of thoughts started with my self-study of maths, physics, and some CS over the summer. I was reading a lot of drier information each day, but most of it was material I needed to cover (well, not needed, but wanted to, for the sake of preparation) and properly remember. Trying to take clear and concise notes to build a library of reference material I could look back to later was not the most innovative summer project, but at least it helped me build a sense of what I liked in content, and what role I wanted consuming that information to play in my daily life.</p>
<p>While trying to teach myself, I started to notice that there were certain information &lsquo;aesthetics&rsquo; that I tended towards. I have a thing both for older, pre-&lsquo;CSS is important&rsquo; era university sites, where profs simply share their knowledge without any ulterior motive; and newer sites that perhaps contained intriguing interactives, or more casual information sharing. My article aesthetic now is similar - I tend towards indie personal sites, rather than &lsquo;popular&rsquo; blogs with share buttons plastered all over. However, finding those articles and websites is pretty difficult - how do I search for &lsquo;small blogs that write generally about programming but in a easy-to-understand way&rsquo;?</p>
<p><a href="https://findka.com">Findka</a>, so far, has been eerily good at recommending things that I&rsquo;m actually interested in - I suppose the closer and more active user base has something to do with that<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Despite not having the popularity of other forums like r/programming and dev.to, it strikes a nice balance of articles both aligning with and outside my interests. It&rsquo;s become much easier to find a couple articles to read a day to satisfy my productive procrastination needs, rather than having to scroll through other sites with a much higher noise to signal ratio.</p>
<p>However, I still found that I was trying to skim through a bit too much each day. I was still alt-tabbing to go off on blog post tangents when I&rsquo;d set out to do something completely different, and I wanted to try to curtail that as much as possible. With the new year, and all the vague self-improvement energy that saturates the internet, I decided to track every article I read for the month of January (spoiler: I have somehow trained myself to subconsciously continue this, well into February). I was looking to see what insights I could gain, and observe if consciously tracking content would make a difference in what and why I was reading.</p>
<h2 id="the-rules">The Rules</h2>
<p>I&rsquo;ll go into how I tracked and counted these articles exactly in a bit, but I&rsquo;d like to explain my materials and methods first. (I will try my best not to turn this into a giant lab report, but as I edit this, I can see that I&rsquo;ve somewhat failed.) I imposed a couple of rules on what counted as an article to track or not, mainly to keep statistics more consistent.</p>
<ul>
<li>I&rsquo;d keep forum-like sites out of the article count - things like Reddit, Lobste.rs discussions, Twitter threads and StackOverflow pages wouldn&rsquo;t count.</li>
<li>Speaking of StackOverflow, programming tutorials and other technical references also weren&rsquo;t included. Documentation for libraries, looking up commands, or following some walkthrough to set something up, for example, fall into this category.</li>
<li>Content required for schoolwork was not included as well - the point of this experiment was to track what I was reading outside of school, not how much I was studying.</li>
<li>I allowed myself to skim the first paragraph-ish to determine if I&rsquo;d like to read the article fully or not without tracking the article, and then log the page. I was definitely also allowed to stop reading the post at any time, but by any point after the first hundred-ish words, the article would already be tracked.</li>
<li>Every single article besides that would be counted - blog posts, Reddit and Twitter links, Findka recommendations would all count towards the day&rsquo;s total.</li>
</ul>
<h2 id="the-graphs">The Graphs</h2>
<p>So we&rsquo;ve come to the graphs, of which there are only two - I think they encapsulate the data well enough. One shows a total of articles read per day, with a three day rolling average, and the other shows a distribution of the times I read any article each day.</p>
<figure>
    <img src="https://i.imgur.com/0ChbUQV.png"
         alt="Figure 1. A graph showing articles read per day"/> <figcaption>
            <p><em>Figure 1. Articles read per day.</em></p>
        </figcaption>
</figure>

<p>You can see a large spike in the beginning of the experiment - I&rsquo;ve coloured those bars a darker grey because I don&rsquo;t think they represent what I was actually reading at the time. If I go back through the Google Sheet (more about technical implementations in the appendix) that houses all my responses, there&rsquo;s a lot of repeated links clustered very close together, so I&rsquo;m going to assume I was trying to figure out how to make the technical bits and pieces work together.</p>
<p>There&rsquo;s also a pretty significant dip in the middle of the experiment - it was already coming to the end of term, and there was a steady influx of homework, leaving less time for reading. It&rsquo;s interesting to see how homework has such a significant impact on what I can consume content-wise, but that&rsquo;s sort of expected anyhow.</p>
<p>I&rsquo;d also like to mention that I went from 5 Findka articles a day, to 3, somewhere in that second week, which ended up increasing back to 4 in the third. I&rsquo;ve been increasingly turning to Matter and Findka (on Matter, yay RSS feeds!) more instead of scrolling through aggregators, so a fluctuation in articles there generally correlates with changes in reading.</p>
<figure>
    <img src="https://i.imgur.com/CAnUol8.png"
         alt="Figure 2. A graph showing time distribution for article readings per day."/> <figcaption>
            <p><em>Figure 2. Time distribution for article readings per day.</em></p>
        </figcaption>
</figure>

<p>This figure shows the timestamps of each log. There are two main bands around morning and afternoon - more on that later.</p>
<p>If you&rsquo;d like some raw numbers:</p>
<ul>
<li>I read 174 articles over 26 days - short and long form are included</li>
<li>That averages to around 6.69 articles a day over the entire range</li>
<li>Each week, I averaged a different number of articles:
<ul>
<li>The first week (I was doing a lot of testing with my Shortcuts and things), I averaged 9.5 per day</li>
<li>The second week, I averaged 4.6 articles a day</li>
<li>The third week, I averaged 4.4 articles per day</li>
<li>For the last week of the experiment, I averaged 5.5 a day</li>
</ul>
</li>
</ul>
<h2 id="the-findings">The Findings</h2>
<p>I suppose that this would be the discussion part of this pseudo-lab report, so let&rsquo;s get into some expectations, findings and takeaways.</p>
<p>My hypothesis going into this entire tracking experiment was that by being more conscious about what and when I was reading, I&rsquo;d manage to self-regulate more impulsive reading sprees, and check the productive procrastination that sometimes ticks in. Before I started this, I had a bit of a reflex to just Ctrl-T, open up a new tab, and sort of spam whatever into the omnibox before my brain consciously processed what I was doing, and then close the tab. (Oddly enough, I ended up not going down those rabbit holes most of the time anyway, but it was a bit annoying to accidentally keep opening and searching around for things to procrastinate with.) I suppose the hypothesis was very well supported - I took more notes and tried to limit myself to a couple reading sessions a day.</p>
<p>In the rules, I explicitly stated that I wouldn&rsquo;t include Reddit, Twitter, or discussion threads in the totals for each day. I thought that this would lead me to spend proportionally more time there, but I don&rsquo;t think it&rsquo;s made a significant difference. I think that having to explicitly log what I was reading while giving myself planned time to read reduced the urge to go look for something to read well enough. At the moment, I go through my Findka, Matter, and Nitter in the morning, and I&rsquo;ve realized that there&rsquo;s really no point in checking much more frequently - people don&rsquo;t create meaningful content in 15 minute intervals. It feels more satisfying to go through a larger chunk of content anyways, though I can&rsquo;t measure how much of this was due to the tracking in any quantifiable numbers. Creating a regular schedule for reading through things, and trying to keep myself accountable with the log, was surprisingly useful.</p>
<p>Speaking of surprises, tracking every single link I&rsquo;d read over the past month has built up sort of a library effect. While retention of article content isn&rsquo;t something I&rsquo;ve explored in my data at all, I have less of an issue finding really great posts and then losing them in my browser history. I know that everything I&rsquo;ve read is in a central location, and it&rsquo;s much easier to find things in one place than to search for that place, and then for the article I&rsquo;m looking for<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. (It&rsquo;s also probably useful to mention that I do generate summaries of what I&rsquo;ve read each week to review and see what I&rsquo;d like to take away from the content I&rsquo;ve been consuming.) I find that I can at least vaguely remember what I&rsquo;ve read better - especially since I try to consciously choose better articles to &lsquo;commit&rsquo; to when I track them.</p>
<p>Going back to the raw data, and the charts I put in the section above, it&rsquo;s interesting to see how the amount of schoolwork (a non-tracked item, but something I can very clearly remember) has an impact on my reading. It&rsquo;s probably just because of how I organize my days - if I really have homework to catch up on, I&rsquo;ll work in the time that I have scheduled out for checking various social media, which pushes the reading to the next available block of time (which, if I&rsquo;m busy, would be in a while). It&rsquo;s also interesting to see that, even with heavy workloads, I kept up with most of my recommendations and reading, never going a day without reading at least something. I think it&rsquo;s valuable to set aside time to see what others have written about, so that&rsquo;s a habit I think I&rsquo;d like to continue.</p>
<p>If I scan the time logged for each article logged, I can see two main blocks - morning and night. (Disregarding the first couple days - those longer series are probably from when I was testing out my system.) It&rsquo;s interesting that I read very consistently at night, and a bit less, though still very consistently, in the mornings. (Let&rsquo;s pretend the ones in the middle are me during breaks and not me █████ █████████████ in █████.)</p>
<p>I have no other data to check my totals against (I can&rsquo;t exactly just search up blog post total articles spent), so I also have absolutely no idea how my consumption compares to the average population. Maybe I spend a lot more time compared to other people, maybe I don&rsquo;t. I&rsquo;d be interested to see how others perform this experiment and how it changes their views, but it&rsquo;s also not a data comparison I&rsquo;m entirely that interested in.</p>
<p>In terms of sources of error (always a fun section to write in labs), I can&rsquo;t think of much besides a) not balancing for word counts and b) mixing the testing / development data in with the actual end data. I don&rsquo;t think it makes too much of a difference for point a if you consider ideas absorbed instead of purely articles read, or their length. In terms of point b, I think it&rsquo;s fine to just ignore days 6 through 8, and pretend I started the entire experiment a little later.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In lab reports, this is the part where I try to convince you how relevant this research is, and how it can be applied. In terms of relevance and application, there&rsquo;s not much else besides being a bit more aware of what content you consume. That, and keeping extremely detailed data on your reading habits, which might appeal to some. I wouldn&rsquo;t recommend this to someone, nor would I advise against it - it&rsquo;s pretty fun to do, and an interesting dataset to analyze later.</p>
<p>There was an interesting article <a href="https://junglegym.substack.com/p/the-t-shaped-information-diet">about the T-shaped approach to content</a> that I read recently, which discusses the types of information that you choose to consume. That was something I tried to keep in mind throughout the experiment, and I think that, considering my findings and my managing to train myself not to unconsciously alt-tab away to be unproductive when I work, the experiment can be considered a success.</p>
<p>In the future, I might like to take a look at how I use forum sites: an area that I specifically left out of this post. That, combined with more productivity-oriented research, might be an interesting area of self-experimentation. I can&rsquo;t figure out a way to analyze the subject matter or word count of each post, but I&rsquo;m pretty happy with the data I&rsquo;ve managed to collect so far. I&rsquo;m still continuing this experiment - I&rsquo;ll probably continue to track everything this year. Because of how I designed the Chrome extension and the Shortcut (see appendix A for other relevant technical magic), the friction of adding a new article is close to none, meaning I&rsquo;ll be more likely to continue using it anyway. It&rsquo;s become a new reflex anyway, and I think having this big of a dataset and these new trends to analyze at the end of the year will provide additional interesting insights.</p>
<p>P.S. I&rsquo;ve found another person who does a similar tracking - <a href="https://twitter.com/fortysevenfx/status/1343587407799738368">link to their thread here</a>.</p>
<h2 id="appendix-a-technical-digressions">Appendix A: Technical Digressions</h2>
<p>This is the part that fellow nerds might find interesting, but that you should feel free to skip. Some of the work I did with the tracking inspired the <a href="https://kewbi.sh/blog/posts/210124/">hyperpersonalization</a> post I wrote earlier, while I was continuing this experiment on my own. I&rsquo;ll try to briefly explain how everything gets logged, and leave some trails for interested parties to pursue.</p>
<p>I knew right off the bat that I wanted the process of logging to be as friction-free as possible - that meant a maximum of one click away on my laptop, and from the share sheet on my phone. Instead of trying to rig up some complicated API and spin up a Heroku server to host my app, I decided to go a simpler route: a simple Google Form, linked directly to a Google Sheet. The form has a field for the URL of the post and notes (I didn&rsquo;t end up writing too many notes as I read, but rather later at the end of my week during my review), and automatically fills in the exact time the form was submitted.</p>
<p>However, I obviously wouldn&rsquo;t <em>fill in a form manually</em> - we have automation to overengineer! Google Forms have a great link function, where you can autofill and submit a form from just a link. From the form link, something like:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">https://docs.google.com/forms/d/e/{id}/viewform/
</code></pre></div><p>you can get to something like</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">https://docs.google.com/forms/d/e/{id}/formResponse?usp=pp_url&amp;{key}={val}&amp;{key}={val}&amp;submit=Submit
</code></pre></div><p>You can get this from getting a prefilled link within Google Forms itself.</p>
<p>I managed to bodge together a Chrome extension with this fetch (and a couple lines to display a badge), which I then bound to a keyboard shortcut. I also slapped this fetch into a iOS Shortcut by enabling share sheet for the shortcut, and getting the URL from the input to put into a &lsquo;Get Contents of URL&rsquo; block. I can then log articles from my phone and my laptop super easily, which was a major reason the experiment went so well. I expect there&rsquo;s a similar shortcut-maker for Android, but iOS Shortcuts feel so snappy to make. You might also want to reference <a href="https://www.reddit.com/r/shortcuts/comments/bp735g/how_to_add_rows_to_google_sheets_from_a_shortcut/">this brilliant guide</a>, and adapt it for whatever platform you&rsquo;re planning to track on.</p>
<p>I then wrote a simple Python script to persist a &lsquo;row last read&rsquo; count of the Sheet in a file, and parsed the CSV values since the last pull with <code>csv</code> and <code>requests</code>. That all gets sent into a Markdown file for me to process and read through at the end of the week. I can also download a full CSV file to process the data in an external app directly from Sheets.</p>
<p>None of the above is open source at the moment, but I trust the guide and the Internet can get you to what I&rsquo;ve managed to do in much shorter time than it took me to even try to figure out how to do it.</p>
<p>In terms of <a href="#the-graphs">the graphs</a>, those were generated with a little bit of pivot table magic in LibreOffice Calc. The first required summing each day together, and the other was created by just inserting a normal chart and editing the major gridlines to fit with the whole times-as-decimals that LO does. It took much more time than I&rsquo;m willing to admit, but all in the name of science, right?</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I can&rsquo;t figure out if it&rsquo;s just a relatively small number of users, or really similar tastes, but it&rsquo;s got to the point that my friend(s?) have made a game out of trying to figure out which articles I submit, with scary accuracy. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>This is part of the reason why I also built Matter - it&rsquo;s one place to look for things, as opposed to over several different aggregators. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Hyperpersonalization</title>
      <link>https://kewbi.sh/blog/posts/210124/</link>
      <pubDate>24 Jan 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On extending and making personal tools.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>A few months ago, I applied for an internship somewhere. It was a pretty standard application for a pretty standard development position. List your specialties, why you wish to apply, what makes you a good candidate. Have a 250 word input to cram your life&rsquo;s goals and achievements. Upload your resume, mindlessly fill demographic information, do you wish to forward a copy of your responses to your email, click send. A cookie-cutter application, nothing special.</p>
<p>One of the main parts of the application was to upload a major project, and write a little bit about it. They&rsquo;d consider the size, purpose, application, and several other characteristics of the given code sample, apparently, and this was a key point of evaluation for the position. What I submitted is irrelevant to the point, but I remember submitting the application with a worrying thought in the back of my mind.</p>
<p>As I was going through past participant&rsquo;s blog posts and collecting any shreds of insider information, I realized that there was a clear divide between &lsquo;their projects&rsquo;, and &lsquo;my projects&rsquo;. Theirs were so much more complex, integrating many technologies, and actually had an obvious industry or consumer application. My science fair project<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> - certainly not &lsquo;clean code&rsquo; by any regards - seemed very small in comparison.</p>
<p>Through this application, I realized that I really didn&rsquo;t have any &lsquo;big&rsquo; projects. My largest project was not my most complex, or anything that&rsquo;d I&rsquo;d deem representative of my skill. My more &lsquo;complicated&rsquo; projects were more components to be mishmashed to extend or work with other software, not individual applications.</p>
<p>I&rsquo;ve been thinking about my work recently over the New Year, and I&rsquo;ve come to conclusion that I&rsquo;ve preferred to write small tools for myself. No one else (well, okay, maybe <em>very</em> small amounts of people) will probably use them, and that&rsquo;s okay for now. I&rsquo;d eventually like to work on bigger projects, but I&rsquo;d also like to make sure that those projects are something I&rsquo;m personally invested in, and not something I&rsquo;m developing for the sake of my resume or something. At the moment, I haven&rsquo;t found an idea or something that I&rsquo;d want to work on - plus, senior year and the associated heavy workload.</p>
<p>However, I still think there&rsquo;s an interesting area to be explored with &lsquo;small software&rsquo;. In this post, I&rsquo;d like to highlight two (and a half) toolkits I&rsquo;ve used to make the aforementioned personalized software. Consider this a combination of thoughts regarding making extremely customized software for a small user base, and a year (± three years) in review.</p>
<h2 id="prelude---roblox">Prelude - Roblox</h2>
<p>Roblox has been described as both a highly addicting platform, and a highly creative engine. (If you don&rsquo;t know what Roblox is, go look it up - the development and monetization side of things is especially interesting.) I don&rsquo;t think I&rsquo;ve seen a community that&rsquo;s been more inspired to share games (barring perhaps Minecraft, which shares similar traits). Even though I was maybe ten, I still managed to wrangle a couple small obbies (essentially 3D platformers) and story adventures out. The Roblox community, as I remember it, was a hivemind of kids teaching other kids how to program. I&rsquo;m sure that there were a good chunk of competent adult programmers, but as a kid (maybe it was just selection bias), I remember looking up to those channels churning out Lua tutorials each week.</p>
<p>Roblox was my &lsquo;in&rsquo; to game development. It&rsquo;s nowhere as complicated as Unity, and it&rsquo;s a great example of something that&rsquo;s literally child-proof yet has an ample system for expansion. I had no experience with proper programming or game design, yet the system of prefabricated assets and drag-and-drop configurability made it super easy to get started. Lua was too complicated for me to understand, but with assets, I managed to bodge together a CTF game for me and my classmates. It was only for us, and was, looking back at the previews I can see on the Roblox site, absolutely horrible. It was just a tiny map with several biomes and &lsquo;hidden&rsquo; flags (the concept of randomization and terrain generation was still several years to come) - but it was something. Something that I&rsquo;d made, and proudly showed off, climbing up several rungs in the 5th-grade social hierarchy as <em>the</em> Roblox dev.</p>
<p>While Roblox is a proper standalone platform, I included it here because it has a sort of whimsy that I find mirrored in the other two (eco)systems that I want to touch on today. That first spark of ownership is something that&rsquo;s sort of addicting to the right people, and probably a good explanation to the infinite server forks my friends had. Roblox gave budding devs a platform, and held their hand until they stepped into the infinite world of Lua and &lsquo;proper&rsquo; scripting. I think that&rsquo;s kind of fun - not just because it&rsquo;s so easy to use, but also because it actually makes game development open, and encourages little kids towards creation, and little bit away from mindless consumption<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<h2 id="chrome-extensions">Chrome Extensions</h2>
<p>An interesting approach to building hyperpersonalized tools is by extending yet another tool. One of the best examples of this is browser extensions - what better to customize than the very tool you&rsquo;re spending most of your online life in? I already use my browser to consume most of my content, and to keep in touch with people, so I personally think investing some time into making the browser exactly what I&rsquo;d like it to be is a worthwhile investment.</p>
<p>If you&rsquo;re a developer, or have any experience with JS, Chrome extensions are relatively easy to get started with - a manifest.json and a couple small HTML / JS files later, and you&rsquo;ve got a working extension. Because they&rsquo;re so easy to use, they&rsquo;re what I generally turn to in order to facilitate and automate basic actions that I do often. I&rsquo;ve made ones recently for <a href="https://github.com/kewbish/revshare-gh">Revshare for GH</a>, and one that I&rsquo;m using at the moment for tracking some interesting experimental data (blog postmortem of self-research to come in a couple weeks). Both took relatively short times to build - one was a CS50 project, which took a month-ish, and one was done in literally an hour. The difference? Whether I chose to make it a &lsquo;proper project&rsquo; - more on this later.</p>
<p>There&rsquo;s something very fun in playing with and manipulating what&rsquo;s shown on a page, especially when it&rsquo;s something just you&rsquo;ll use.With the way Chrome makes it relatively easy to add and iterate on your own extensions by loading unpacked folders somewhere, I can justify taking a couple hours to slap something together to fix a &lsquo;minor problem&rsquo;. Of course, there&rsquo;ll be &lsquo;minor problems&rsquo; that a lot of people share, or that you&rsquo;d like to make aware to others - this is when publishing an extension might come in handy. But for the majority of my &lsquo;minor problems&rsquo;, it seems that no one else has them, so for now, I&rsquo;m content to continue hacking away with &lsquo;hyperpersonalized&rsquo; things.</p>
<h2 id="shortcuts">Shortcuts</h2>
<p>Shortcuts (on iOS, though I&rsquo;m sure there&rsquo;ll be an Android equivalent <em>somewhere</em>) is another example of extending an ecosystem to personalize it. As with Chrome extensions, people have made amazing things - I&rsquo;ve seen <a href="https://www.jacksondame.com/vestigory/get-started">entire life management and tracker apps</a> made in it, as well as very slick widget apps and integrations<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. It&rsquo;s sort of like a hybrid automation and Siri extension system, but I use it mainly for its automation capabilities and integrations. I don&rsquo;t think I&rsquo;ll ever get into iOS development, but Shortcuts lets me make what is essentially a proper app - I can enable it in the Share Sheet (the little popup when you&rsquo;d like to share something) and I can make it do rather complicated things with APIs and files. It&rsquo;s an interesting attempt by Apple to finally give people some much-appreciated customization and a way to make apps without shelling out for a license and diving into learning Swift.</p>
<p>Using the right tool for the right job is something that I often ignore, but I&rsquo;ve recently been trying to decomplicate most of the things I make (which, historically, have been very overcomplicated). A couple weeks ago, I was trying to make a little form for a tracker, and was toying with the idea of making a PWA of some sort, connecting it to some GitHub repository issue<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>. In short, it would be very complicated, but good fun to code. However, I resisted the urge to immediately go create a new repo - I&rsquo;d rediscovered Shortcuts earlier that week. It was surprisingly pain-free to drag and drop a bunch of blocks together to POST data to a Google Sheet (probably a better way of storing information as opposed to an issue thread), as well as make it available to interact with from the browser bar.</p>
<p>Another interesting thing with Shortcuts is that it&rsquo;s the very embodiment of the entire &lsquo;no-code&rsquo; thing that&rsquo;s supposed to become popular enough to take over my job right about when I graduate university (/s. Maybe.). I don&rsquo;t have a lot of Shortcuts rigged up at the moment, but I&rsquo;d agree with <a href="https://www.reddit.com/r/shortcuts/">r/Shortcuts</a> that the entire process of making one is very <em>satisfying</em>. Sometimes the smaller screen size of my phone makes it a bit difficult to drag things to the right places, and sometimes copy-pasting things around can be a hassle. Still, I think there&rsquo;s a sort of whimsy in building your own &lsquo;app&rsquo; that even non-technical people can take advantage of. Again, there&rsquo;s that hyperpersonalization people can get. Instead of waiting for someone to solve your problems for you with a proper app, you can slap something else together in Shortcuts.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Returning to the internship application: my GitHub has a significant population of these tiny creations - be it extensions, small scripts, and personal utilities. Microapps, as I&rsquo;ve decided to call these small little one-user extensions and automations, are something that I&rsquo;d like to continue to explore. I keep returning to the word whimsy to describe these microapps, and that&rsquo;s because whimsicalness is exactly what I see in making these. The ease of iteration and production is sort of a fascinating idea, and one that I&rsquo;ll always keep an eye out for. I realize there&rsquo;s something sort of ironic in actively sharing microapps, but hey - maybe I&rsquo;ll help one person who has the very specific problem that I do, and that&rsquo;s more than enough.</p>
<p>By taking the pressure off to make something that&rsquo;s useful for other people, or that&rsquo;s polished enough that you&rsquo;d be willing to shamelessly promote it everywhere, I feel like I have the freedom to focus on having ideas that&rsquo;d benefit me first. I&rsquo;d have that freedom anyway, but by plastering &lsquo;this is hyperpersonalized, don&rsquo;t attack me if it&rsquo;s broken in one of these edge cases&rsquo; over the project mentally, it feels like I have more room to figure things out. While I&rsquo;m happy to, and do, share most of my work, I&rsquo;d rather not add more stress to maintain something I don&rsquo;t believe in anymore, or that I&rsquo;m forcing myself to do for no good reason.</p>
<p>I think this can serve as an effective sieve of ideas - a bunch of ideas flow in, and you filter them in or out depending on whether you yourself are emotionally drawn to the idea. Ideally, you&rsquo;d find a happy medium of &lsquo;helps people&rsquo; and &lsquo;helps me&rsquo;, but that might not be the case all the time. I&rsquo;m still very young - I have a vague idea of what I&rsquo;d like to do, and what I&rsquo;d like to work on in the meantime to get myself to that end direction. For now, I&rsquo;m leaning on the side of &lsquo;helps me&rsquo; - there&rsquo;s something very satisfactory in building smaller tools that benefit my own workflow.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I don&rsquo;t know why I need to preface this, but no, I did not <code>import random</code>. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I also find it really amazing that Roblox actually has a system to properly pay their developers. I&rsquo;m pretty sure if I&rsquo;d known as a kid that I could have saved up a couple Robux, I&rsquo;d have put much more time and effort into trying to monetize my hobby - I was a very entrepreneurial type of kid. I remember seeing <a href="https://www.cnbc.com/2019/09/23/college-student-video-game-creator-made-millions-from-jailbreak.html">an article (might have been this one)</a> about the creators of Jailbreak, a game I&rsquo;m pretty sure all my classmates were fairly addicted to. (I wasn&rsquo;t good enough at the game, and stuck to obbies, but those are in themselves extremely lucrative.) You&rsquo;d expect most people would&rsquo;t pay for cosmetics, but I suppose the in-game (and in-class) clout people who had Roblox Premium or whatever was enough of an incentive. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Somewhat ironically, I still haven&rsquo;t bothered to customize my home screen. I&rsquo;d like to get larger widget grid icons for some of my Shortcuts and apps that I&rsquo;d like to encourage myself to use more, but I&rsquo;ve not found the time to do that yet. Someday. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>GitHubDB, as they say. I don&rsquo;t want to talk about how called out I feel by this. <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
