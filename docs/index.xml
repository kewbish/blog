<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Yours, Kewbish - a collection of </title>
    <link>https://kewbi.sh/blog/</link>
    <description>Latest Yours, Kewbish posts</description>
    <managingEditor>(Emilie Ma ◦ Kewbish)</managingEditor>
    <lastBuildDate>Mon, 14 Feb 2022 19:15:42 -0800</lastBuildDate>
    
	<atom:link href="https://kewbi.sh/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Post Code-in: Yours, Kewbish</title>
      <link>https://kewbi.sh/blog/posts/220214/</link>
      <pubDate>14 Feb 2022</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On running this blog for the past two years.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>On this day, two years ago, I started this blog. The purpose? Nothing, other than to flex that I&rsquo;d just won <a href="https://g.co/gci">Google Code-in 2019</a>, and humblebrag about my tribulations along the way. I really didn&rsquo;t have anything to say back then, other than highlighting projects I&rsquo;d started, or sharing new announcements about cool things that I&rsquo;d participated in. I did a couple series early on about <a href="https://kewbi.sh/blog/posts/200621/">CS50 (Harvard&rsquo;s introductory CS course)</a> and later, <a href="https://kewbi.sh/blog/posts/201213/">CPSC110 (UBC&rsquo;s introductory CS course)</a>. I wrote in a very direct yet rambly and overly verbose tone. I wasn&rsquo;t sure what my voice was, and neither did I know what I really had to communicate.</p>
<p>I&rsquo;m not sure whether I&rsquo;ve figured out what I have to communicate now either, but I do know that I&rsquo;ve been thinking a lot about tools for thought and meta-writing, if that&rsquo;s a word, for the last couple months<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This trajectory&rsquo;s focused my writing on topics that interest me more, and are more sustainable to write and share about than &lsquo;what I&rsquo;ve been up to this last week&rsquo;. Early last year, I started this phase of Yours, Kewbish with a post on <a href="https://kewbi.sh/blog/posts/210124/">hyperpersonalization</a>, which I still think might be one of my best posts. More recently, I&rsquo;ve written about <a href="https://kewbi.sh/blog/posts/210905/">the intellectual process</a>, <a href="https://kewbi.sh/blog/posts/211114/">metadata</a>, and <a href="https://kewbi.sh/blog/posts/211219/">a software culture of atomicization</a>. This sort of thing is genuinely a lot more fun to write, and encourages me to dig deep on my thoughts on where technology&rsquo;s taking this world.</p>
<p>Even at the beginning of last year, and when I wrote my <a href="https://kewbi.sh/blog/posts/210214/">last recap post</a>, I was still in a mindset of trying to pump out content and build a habit of writing. Now, it really feels like sitting down every so often just to chill and spill out some thoughts. This marks an evolution in my thinking process as well - I&rsquo;m drawing more on recurring themes that come up in my notes and general thoughts, instead of events and personal news to recap. Reading back, my posts over the past year read like one-sided nerdy soliloquies to a friend, or a transcription of me rambling to myself. I think, at least, I sound a bit more like me.</p>
<p>This post is the first half of a series about the past year of Yours, Kewbish, and of me on the internet. While the second post will touch on my personal development in the last year, this article is a combination of some raw analytics and some heartfelt reflection on the past year of blogging here. I&rsquo;m excited to consider how my thoughts have changed, and how the role of Yours, Kewbish has evolved.</p>
<h2 id="raw-content-analysis">Raw Content Analysis</h2>
<p>I wrote 26 posts in 2021, between my last recap post and today&rsquo;s. I think I unintentionally stuck quite regularly to a bi-weekly writing pattern. When I stopped forcing myself to post weekly last year, I told myself I&rsquo;d take more time to edit each post, but still take time to write each week. However, I&rsquo;ve found that I ended up in a recurring pattern of one week of scribbling down thoughts into articles and one week of stewing over other ideas. This cadence worked out well - it gave me time to let thoughts take shape while also maintaining some sort of writing habit. This tally of 26 posts is a slight decrease from 2020&rsquo;s of 40 posts, but I&rsquo;d say I&rsquo;m definitely prouder of the writing I shared last year than in 2020.</p>
<p>Diving into each individual article, I&rsquo;ve found that I&rsquo;ve solidified the structure I set out near the beginning of this blog. I&rsquo;ve since expanded the average word count from 1378 words per post to 2116 words (and for the three articles I&rsquo;ve written in 2022, 2652 words). This reflects the slower timing of my writing cycles, the fact that I now have more to say for each post, and that each article has more substance and solid thought in it. This is a welcome change from me trying to crank out a thousand words of, quite frankly, nothing every Sunday in 2020.</p>
<p>Here&rsquo;s a graph showing the average word count per article from 2021 til now:</p>
<figure><img src="https://i.imgur.com/52Dp5z7.png"
         alt="Figure 1. Raw Word Count Per Article"/><figcaption>
            <p><em>Figure 1. Raw Word Count Per Article.</em></p>
        </figcaption>
</figure>

<p>The solid grey dots are the word counts per article, with the dotted white line representing a 3-post rolling average. There&rsquo;s a couple high-word-count posts in the beginning of the year, then levelling down as my last term of senior year started up again. In the summer, I tended to have more time and thoughts to write about, so average word count went up. Since September of 2021, however, I see a stable trend in word count - it&rsquo;s rising so far, but I think that overall this is a plateau in word count. Though there&rsquo;s a lot of scatter in this data, especially as my sample size is small, I think the insights from this graph sum up the last year of Yours, Kewbish pretty well.</p>
<p>In the last year, I think I&rsquo;ve also changed my content topics pretty thoroughly - I&rsquo;ve picked up on some new tools for thought influences, and started engaging with a larger body of interesting reading in adjacent fields. For one, I&rsquo;ve started actually following people I find interesting and reading their posts, as well as checking in on their work. I expect that there&rsquo;ll be a lot of thinking about tools for thought, as well as more generally about software and the culture around technology.</p>
<p>To analyze this, I did a bit of poking around with my good friend Uzay&rsquo;s hot new tool <a href="https://github.com/Uzay-G/espial">Espial</a>, which analyzes your knowledge base for semantic links between concepts. It&rsquo;s a pretty cool tool, so I&rsquo;d suggest you give it a go yourself. I&rsquo;ve also recently done a bit of prototyping with Espial - I built <a href="https://github.com/kewbish/whimsy/tree/master/poke">Poke</a>. Poke uses Espial and file metadata to extract insights about what you haven&rsquo;t thought about recently. More about Poke on the GitHub, but here&rsquo;s a highlight of some of the topics I found:</p>
<ul>
<li>supply (and demand, of software)</li>
<li>zettelkasten (and its associated paradigms)</li>
<li>religion (and general cult-like behaviour around tools for thought)</li>
<li>boxing (and categorization in general)</li>
<li>anki (and spaced repetition)</li>
<li>school (and how it&rsquo;s impacted me)</li>
<li>principle (and software development practices)</li>
<li>list (and outlining as a tool for thought)</li>
<li>and, quite simply, thing (no idea)</li>
</ul>
<p>I&rsquo;d say this list lines up quite well with what I&rsquo;ve written about recently, though there is some bias against niche topics with things that I&rsquo;ve mentioned broadly many times. I also think this is an alright spread of ideas, and one that I intend to keep pursuing and thinking about this year<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Somewhat of a tangent, but it&rsquo;s also interesting to see how my voice and writing style has changed over the last year. I still have a very wordy style, but I&rsquo;d say I sound less formal and stiff. Friends that&rsquo;ve read through articles keep telling me that my writing <em>really</em> sounds like me - something I&rsquo;ll take as a compliment. Part of this probably comes from the fact that I&rsquo;m more used to writing for a (very small) audience now. I also think that this is because I&rsquo;m growing more confident in sharing my ideas. I&rsquo;ve started to be able to understand what my ideas are and what I want to say about them better. In general, I&rsquo;d think that I can communicate a bit better now, and that what I have to share is more impactful and valid.</p>
<h2 id="writing-habits">Writing Habits</h2>
<p>Besides just the content, I have a few thoughts and reflections on how I&rsquo;ve written over the past year: what I think worked well, and what I want to change. For one, I think this less frantic pace of publishing, and writing at my own pace instead of frantically trying to force ideas out, has been useful for letting more meaningful ideas come up. Having ideas that I&rsquo;m passionate about also makes me more proud of what I&rsquo;ve written, and helps make the writing process a treat, instead of a chore. I think I&rsquo;ve also done well in keeping a decent variety of influences in my work - I&rsquo;ve written about a diverse set of ideas (well, somewhat constrained by &lsquo;tools for thought&rsquo; and technology in general), and that&rsquo;s something I&rsquo;d like to continue this year. As well, last year, I wrote up a couple full series: on <a href="https://kewbi.sh/blog/posts/201213/">CPSC110</a>, on <a href="https://kewbi.sh/blog/posts/210523/">indie games</a>, and on giving my first talk at <a href="https://kewbi.sh/blog/posts/210801/">Augment Minds</a>. While I don&rsquo;t see myself connecting all my writing to a couple series, I liked the form factor of getting to explore different aspects of a topic in self-contained articles. I&rsquo;d like to do at least a couple more series this year - I already have one in the works about the idealization of tools for thought. I see that project as being a bit big in scope, so maybe I&rsquo;ll stick to just the one. Overall, however, I do like the motivation writing series gives me to finish writing pieces and think through things with different perspectives, and in seeing my ideas linked together.</p>
<p>On the other hand, I don&rsquo;t have too much I&rsquo;d like to change. I&rsquo;d mainly just like to keep up writing as a habit, and even if I don&rsquo;t publish or come up with a full piece every weekend, I&rsquo;d like to enforce a chunk of time set aside for maintaining my knowledge base and at least writing down a few new thoughts. I did really well with this during winter break earlier this year, where I&rsquo;d sit down almost every day to journal about a quirky new idea I had. With the onset of school and midterm season, however, I&rsquo;ve really let this slide. There&rsquo;s not much use beating myself up about this - my priorities, at the end of the day, are still with school. Going forward, I&rsquo;ll just try to be more accountable with myself and encourage myself to write a bit more. In addition, there&rsquo;s also stuff like exploring more literature-response or idea-response articles, where I take insights from others' work and write about how I see them applied to what I&rsquo;m interested in. I have a couple essays-in-progress in this style, and I&rsquo;ll see how they turn out and if they&rsquo;re any good for fleshing out further.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Overall, I&rsquo;m really happy I sat down that February day two years ago to start this blog. Over the past couple years, and in the last year in particular, Yours, Kewbish has been a place where I can share my stream of consciousness. It&rsquo;s helped to spark conversations with friends, to learn how to articulate my thoughts, to gain confidence, and to let me grow as a person and developer. I find having this platform to share - no matter how half-baked my thoughts and what they&rsquo;re centering around - really valuable. Recently, I&rsquo;ve really realized the value of sharing with people, and even if no one really reads this blog, I think the act of preparing some idea to share is a big part of journey.</p>
<p>No promises, but I aim to keep writing just as much as last year for this year as well. I know school&rsquo;s going to get rough soon (midterms week is this week!), but reflecting on this blog&rsquo;s made me also realize how therapeutic it is. Among a sea of assignments where I don&rsquo;t really have entire creative license, this blog is one of the few places I can think through things in words that&rsquo;s not constrained by some rubric, implicit or explicit. That sense of creativity and, in a way, quirkiness is something that I feel that&rsquo;s gotten drained out of me throughout the last term at school. I have a couple post ideas planned, and reading week&rsquo;s coming up, so hopefully then, and each week after that as well, I&rsquo;ll find time to keep this blog simmering.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I&rsquo;ve only recently started making any prototypes to follow up with these ideas, so maybe I fall under the label of &lsquo;theory for thought&rsquo; instead of concrete tools.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>As an aside, Espial and Poke were incredibly useful for this type of overall, big-picture, general topic analysis. It was super interesting to see laid out in front of me what I&rsquo;d been thinking about extensively in the last year. It was also cool to see the differences between the topics that immediately came to mind for me that I thought I wrote about, and what the computer&rsquo;s telling me that I&rsquo;ve actually written about. Maybe the NLP isn&rsquo;t entirely accurate, and maybe I&rsquo;m subject to a recency bias, but working together, I found this to be an inspiring thought exercise.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>The Secret Garden</title>
      <link>https://kewbi.sh/blog/posts/220130/</link>
      <pubDate>30 Jan 2022</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On public and private thought cultivation.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>In the field of personal knowledge management, a popular term&rsquo;s popped up to describe knowledge bases: digital gardens. It&rsquo;s cute and endearly quaint - perhaps it reflects a sort of <a href="https://en.wikipedia.org/wiki/Walden">Walden-esque</a> desire to step away from the hustle of grind culture and bustle of digital life and returning to a humbler life of tending one&rsquo;s knowledge garden. There&rsquo;s a growing trend of publishing your personal wikis online, often complete with little Sprout / Sapling / Tree / Evergreen labels to denote the state of thoughts. The quintessential example I see linked the most is <a href="https://notes.andymatuschak.org/About_these_notes">Andy Matuschak&rsquo;s notes</a>. My good friend <a href="https://knowledge.uzpg.me/">Uzay Girit&rsquo;s</a> started one with his tool <a href="https://github.com/archivy/archivy">Archivy</a>. And many, many more - <a href="https://maggieappleton.com/garden">Maggie Appleton&rsquo;s</a>, <a href="https://www.mentalnodes.com/">Anne-Laure Le Cunff&rsquo;s</a>, and <a href="https://jzhao.xyz/thoughts/">Jacky Zhao&rsquo;s</a>, just to name a few.</p>
<p>These public gardens of thought fill a liminal space between a messy notebook, and more polished blog posts. It&rsquo;s part of the larger trend to work in public, ship in public, and now, think in public - gardens like this spark thoughts and conversations, and can open up room for more experimentation and play. Some blogs can feel corporate and stale, and lack the freshness of digital gardens that are updated weekly, or even daily. Digital gardens take away the pressure to perfect every last word - the phrase &lsquo;garden&rsquo; itself comes with connotations of a certain type of dirtiness, but good dirtiness. They come with the expectation that not everything will be perfect, but that eventually, every little thought and insight will grow, and provide joy and beauty and inspiration.</p>
<p>I could go on about the benefits of digital gardening, but I think plenty of people can do that better than I can<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Instead, I&rsquo;ll discuss some of to preserve your knowledge only for yourself, and garden in private, not public. It sounds selfish and counterintuitive at first - after all, I&rsquo;m sure everyone&rsquo;s had at least one solid insight that&rsquo;d be of use to someone else. And even notwithstanding the value of thoughts and of publishing, there&rsquo;s a certain merit in encouraging people to expand their thinking habits. I know some of the course notes I took likely would be very useful to incoming students; and maybe some of my longer musings on tech culture could be interesting. But with all the practicality and advantages of digital gardens, I think there&rsquo;s a case for walled, secret gardens as well.</p>
<p>There&rsquo;s a novel I used to love as a kid - <a href="https://en.wikipedia.org/wiki/The_Secret_Garden">The Secret Garden</a> by Frances Hodgson Burnett. The main character begins as a spoilt little girl, forced to live with her uncle in a dreary corner of England. She hates her new home, and the people she&rsquo;s made to interact with. The rest of the story isn&rsquo;t really relevant, but the major finding and focal point of the story later becomes a secret garden she finds, tucked away into a corner of the manor. It&rsquo;s locked, but she somehow finds the key. From then on, the main character gradually becomes more carefree and joyous, spending her hours playing in the beautiful garden and having little escapades with the animals there. It&rsquo;s a cute story, but I think it&rsquo;s an apt metaphor for the maintenance and wonders of private knowledge.</p>
<p>This article is a collection of some of my thoughts on private and public memory, thought, and ideation. For the rest of this post, &lsquo;walled garden&rsquo;, or &lsquo;secret garden&rsquo; will refer to private wikis and knowledge bases whose primary intent isn&rsquo;t to be shared, or plainly isn&rsquo;t shared. I&rsquo;ll discuss the tending of these gardens, their benefits, and how they can work together with public digital gardens as well.</p>
<h2 id="pre-emptive-curation">Pre-emptive Curation</h2>
<p>I don&rsquo;t know if it&rsquo;s just me, but I feel that when I write for an audience, and for any person that isn&rsquo;t myself, my tone and my content and my voice changes. When I&rsquo;m writing these articles, I do feel like I&rsquo;m talking to a friend, but it&rsquo;s different than writing my own notes or scribbling away in my personal journal. I worry that if I&rsquo;d start a public garden, I&rsquo;d end up curating for others - imposing structures and optimizing for someone else&rsquo;s experience, not mine. And it&rsquo;s easy to say, &ldquo;Oh, just don&rsquo;t do that! Write as if you&rsquo;re writing for yourself, and no one else!&rdquo;, but to me, putting something out there in the world, even if it&rsquo;s something as small as a post here, is associated with a certain level of polish. That level of polish doesn&rsquo;t have to be very high - read some of my first couple blog posts for a great example of &lsquo;literally only spellchecked&rsquo;. But I&rsquo;d like to think that I do things now with a bit more intention, and that implicit drive to fulfill that resolution shapes how I write.</p>
<p>Having an audience shapes how you write, and how you take notes. At least for me, I felt that when I was working through my <a href="https://kewbi.sh/blog/posts/200629/">CS50</a> or <a href="https://kewbi.sh/blog/posts/201213/">CPSC 110</a> posts, I was writing actively with helping someone in mind. I was including basic things that were glossed over in lectures, and things that I myself already understood. This is good - if I&rsquo;d returned to my notes at any point in time, I&rsquo;d be able to get a bit more of an overview and brush up on the basics. But that&rsquo;s a small example, at least, of my perception of how my own writing changes with more technical explanations that are aimed at people, instead of just for myself. I found myself embedding lots more context - I did this a lot too when I started writing about my notetaking system. Almost every post would include a &lsquo;if you haven&rsquo;t heard of the Zettelkasten system&rsquo;, with the same links and the same references to Ahren&rsquo;s book and Luhmann himself.</p>
<p>In one of his tweets, Linus Lee said <a href="https://twitter.com/thesephist/status/1480274175545724928">that it seems like digital gardens and note dumps are moving to replace longer-form blog writing</a>. I agree - I feel like a good portion of the value of ideas comes from the context they occupy, and the potential they hold to spark future thoughts and ideas. I feel that public gardens tend to shift this focus from the context to the content itself, where often the context surrounding certain ideas is left out of notes entirely, and we&rsquo;re focusing just on the raw ideas. I was introduced to the concept of <a href="https://en.wikipedia.org/wiki/The_Death_of_the_Author">the death of the author</a> in English class last term, and I can see how that concept applies here. Notes in digital gardens can sometimes feel detached from the contexts they came out of, and because they&rsquo;re just published as-is by the author, who&rsquo;s retained all the implicit context but perhaps hasn&rsquo;t written it explicitly, it feels like they&rsquo;re being viewed solely as detached points.</p>
<p>One of the ways digital and secret gardens can work in concert is a sort of mixed publication method. People usually set it up so that they have some public folder in their knowledge base that gets published, leaving their own personal notes with potentially private information unpublicized. This unfortunately means that everything needs to be processed manually before you set up your notes to publish - this leads to more friction, and more time that someone could&rsquo;ve spent tending their own secret garden. However, it&rsquo;s also a good opportunity to revisit notes and think from others' perspectives, allowing for opportunities to revise based on new contexts, or based on what others. While it&rsquo;s important to be careful not to overthink the review too much, I think it can also be a useful step of knowledge management regardless.</p>
<h2 id="into-your-mind">Into Your Mind</h2>
<p>Besides the privacy of the content, with publishing anything on the internet, I feel a slight moral obligation to at least double check what I&rsquo;ve written for major factual issues. I feel that, in that case, where I&rsquo;m reviewing even just for editorial errors and the like, I may as well polish things a bit more and turn it into more refined posts that can stand on their own. There&rsquo;s always going to be tacit judgement (? evaluation? there&rsquo;s probably a better word for it) of what you put out there on the internet. I personally feel that it&rsquo;s nicer to put more intention into things like that - I&rsquo;m sharing my voice, after all, and I&rsquo;d like to communicate it as clearly and truthfully as possible.</p>
<p>I tend to feel uncomfortable with taking responsibility for my unfinished work - I remember when I was working on projects last summer, I was loathe to share with friends. When I did, it was always after a caveat or two that &lsquo;this wasn&rsquo;t the final product!&rsquo;, just in case. This is something I&rsquo;m working on - as I mentioned in my <a href="https://kewbi.sh/blog/posts/220102/">2022 goals post</a>, I&rsquo;d like to share what I&rsquo;m doing more often, and gather more perspectives while my work is in progress. Right now, I&rsquo;m still working with this sense of uneasiness - I used to hate it when my friends would read my blog posts. It took me a long time, and I still cringe when they decide to link my posts in chat, but I&rsquo;m starting to feel more comfortable with that type of sharing.</p>
<p>Most of my articles here are works that are at least somewhat finished, and done with having a reader in mind. However, with digital gardens, notes are often a step or two under finished articles or coherent thoughts. If I felt this disconcerted by sharing work that I was already decently proud of, I don&rsquo;t think I&rsquo;d be alright with dumping all my thoughts out into the big, bad Web<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. Maybe this is an issue with my personal mindset, but I tend to not like presenting ideas, or versions of things that I don&rsquo;t see as complete. I like having things I share be working at some minimial-viable-thought level at all times - maybe that&rsquo;s just me. For some people, digital gardens allowing them to share incomplete thoughts might inspire them to write more and post more often, but I don&rsquo;t feel that way. Digital gardens offer a window into the running state of consciousness of someone - into how they take notes, and into their mind. Some folks might find this liberating and empowering, but I find that this forces my ideas into certain streams of thinking over and over again. Especially with more personal views or unfinished, brewing thoughts, I think it&rsquo;s alright to leave those in private, secret gardens.</p>
<h2 id="conclusion">Conclusion</h2>
<p>All this lends a sense of responsibility, and of weight, to the task of tending one&rsquo;s digital garden. As an extension of your online identity, you&rsquo;re now in charge of maintaining your wiki. Sure, you could slap a giant notice that this is all to be taken at face value, and that you&rsquo;re not responsible for any errors or liability or whatever, but I still feel that it&rsquo;s too much pressure. I know plenty of people have their own views on this, and their own workflows where they just publish whatever and don&rsquo;t feel like they have to shape their thoughts to fit a specific voice. But for now, setting up a digital garden just isn&rsquo;t for me - perhaps that&rsquo;ll change in the future, I don&rsquo;t know. I think I prefer the quiet tending of a secret garden - one that I can, like in the novel, lock away, yet return to, and find joy in, whenever I like. I like writing for an audience of none (or, well, one) because it gives me freedom to leave thoughts tangled up, in the contexts they came from, and in the phrasing that they first occurred in. It takes away the pressure of having to polish each thought as I write it: I can leave that for another stage of tending my garden.</p>
<p>On one hand of the spectrum, digital gardens that are straight stream-of-consciousness, and true extensions of their landscaper&rsquo;s mind, suffer from high noise : signal ratios. By diluting core thoughts with a network of unfinished, work-in-progress thoughts that haven&rsquo;t fully bloomed yet, it&rsquo;s harder to make information useful, both to the author and to readers. More formal writing can feel distant, and repetitive at times, especially as you&rsquo;ll have to integrate context and evidence and properly support arguments. In short, public digital gardens can feel a bit brain-dumpy, and long-form content can be a bit stifling and formal. Secret gardens, and gardens that are a mix of private and public all across this spectrum, embrace thought&rsquo;s inherent lifecycle well. Secret gardens welcome the inherent stages of thought - because not all thoughts are immediately ready to share. They&rsquo;re a bit more informal and casual, as the primary audience is still just the author. But they allow room for thoughts to grow, take root, become hardy, and eventually be able to be transplanted gently into public gardens.</p>
<p>I see the larger movement towards digital gardens as a sort of reverse &lsquo;tragedy of the commons&rsquo;. Whereas it&rsquo;s usually that people neglect a shared resource for the sake of their own personal gains, assuming that others will take care of it, with digital gardens, I find that there&rsquo;s a lot more room for thought if you assume that you need to help no others, and that you should put writing for yourself at the forefront. There&rsquo;s a fine balance here, between oversharing and undersharing - between not tending a digital garden with the same care as longer, more formal writing, and putting too much thought into the publishing and overthinking it. I&rsquo;m still working on this, but with this blog, I think I&rsquo;ve found that good balance. Most of my articles come from well-connected thoughts that I&rsquo;ve chained together, and almost all of my more complex notes are derivatives of my posts. This way, I can still share the thoughts that I&rsquo;ve worked on the most, and tended the most, but leave the messier, less coherent work in my own secret garden.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Just Google &lsquo;digital gardens&rsquo;, click around a few links, and you&rsquo;ll be greeted with examples of people who are truly experts of thought horticulture.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>There&rsquo;s also something to say about this sense of resistance. Maybe that fact that I&rsquo;m scared, in a way, of sharing like this is a reason to finally start doing so more often.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Time in Writing</title>
      <link>https://kewbi.sh/blog/posts/220116/</link>
      <pubDate>16 Jan 2022</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On the role of time in iterative writing.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Over my break between my fall and spring terms of university, I&rsquo;d been writing a lot - mostly thinking of new article ideas for this blog. I&rsquo;d finally had more time to read through the huge backlog of interesting articles I&rsquo;d found for myself, so I spent some time riffing off of concepts that I&rsquo;d encountered and wanted to discuss. It was very peaceful to be able to sit down, unencumbered by the prospect of having to grind through endless maths problems, and just write. I honestly felt like I did a lot of good thinking over that break - it was like all the noise finally quieted down, and my brain decided to overcompensate for not doing much concrete work by coming up with a lot of thoughts. I decided to transform some of those thoughtchains into articles, and some into personal notes for myself. Bottom line - I spent a lot of time reading, writing, and musing this break: it was very enjoyable, and a good mental rest before I was thrown back into term two.</p>
<p>One of the things that was on my mind near the start of break was, as usual, still schoolwork. After classes let out for exam period, I still had one assignment left: my English paper<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. This was something I&rsquo;d been working on for almost half the term, and was worth a rather significant 25% of our grade. Needless to say, I was stressed about it, even after I&rsquo;d finally sent it off and started studying for other things. But after the chaos of exams faded away, I was still thinking about some of the pain points I&rsquo;d experienced while writing that essay, and specifically about the role of time on my writing. I don&rsquo;t mean time as in the time crunch, though that was certainly fun - I mean how time impacted my the contents of my writing, how my essay went from an outline to an actual paper, and how it changed over that period of time. There were other English assignments for the same class where I followed a similar process - with each piece, I realized just how drastically they&rsquo;d changed with editing; how they&rsquo;d changed over time.</p>
<p>There&rsquo;s a lot of buzzwords surrounding tools for thought, especially those referencing software that claim to bring new mediums for thought, elevating the human consciousness to unlock some magical thinking powers that we didn&rsquo;t see possible. I&rsquo;m only joking, but I think there&rsquo;s opportunities to explore how time is a significant effect on writing and on thought. Building software to be more &lsquo;aware&rsquo;, in a sense, of time has the potential to drive new innovations in tools for thought.</p>
<p>This post is a collection of a few ideas that I came up with while reflecting on writing my essay, particularly focusing on the role of time, history, and perspective on content and expression.</p>
<h2 id="semantic-version-control">Semantic Version Control</h2>
<p>With writing, I usually like having some way to access the history of my files. With Word, I used to be able to enable some option to be able to access the version history - I think a friend recently mentioned this is somehow built directly into the Office 365 product now. However, I currently use Vim for most of my personal notetaking, and LibreOffice for more formal schoolwork. Both of these softwares have ways that I&rsquo;m aware of that could enable me to &lsquo;step through&rsquo; these files in time, sort of like a literary debugger. Within Vim, I could enable the infinite undo tree and be able to track changes that way. LibreOffice, on the other hand, there&rsquo;s a single backup that&rsquo;s on by default, but also a Versions feature that&rsquo;s somewhat reminiscent of source control like Git. Both of these methods are a bit overkill for me at this point - for my Vim writing, it&rsquo;s backed up to a Git repo that syncs automatically each day, and I usually don&rsquo;t update more frequently than that. For my formal schoolwork that I have to write up, I generally just copy paste my main points below any new drafts, or litter my editing with comments that refer back to older versions of the document.</p>
<p>An interesting use case that I found myself thinking about recently is what I&rsquo;d term semantic version control. Maybe &lsquo;semantic&rsquo; isn&rsquo;t a great description for it, but you&rsquo;ll see. My guiding question for this whole thing was &lsquo;why isn&rsquo;t it possible to keep file chunks separated, so I can Ctrl-Z changes in one part of my writing, but not others?&rsquo;.</p>
<p>My reference model of the typical version control software is the ubiquitous Git. As far as I can tell, it operates on line-based diffs, essentially comparing individual lines within files to see where new chunks have been added or removed<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. This works well for most (almost all?) software development, where it&rsquo;s not logical to have files represent any intermediate states in between code changes. If something is committed, we want it to reflect that update. But for writing, and projects with more semantic nuance, it&rsquo;s hard to preserve these &lsquo;in-between&rsquo; states. For example, let&rsquo;s say I have three paragraphs, and I&rsquo;m editing each one. Before I start working, I commit my changes, and when I&rsquo;m done, I also commit my changes. At the end of my revisions, maybe I&rsquo;ve decided that I don&rsquo;t like my changes in paragraph one. Fine - I can revert incremental changes, even in typical VCS like Git (with <code>git checkout -p</code>), but this process is a bit complicated. I&rsquo;ve only tried this once (with a non-binary file), and managing merge conflicts was a nightmare. Perhaps I did the entire thing completely wrong: we&rsquo;ll give it the benefit of the doubt. However, where Git starts breaking apart, or at least being very complicated for this workflow, is when you&rsquo;d be pulling parts of commits all over the commit tree. Maybe you even want to fast-forward a paragraph or two down in the tree and start working off those changes, but how can you apply commits from the future? That&rsquo;s a rhetorical question - I think with enough <code>git checkout</code>ing and <code>git rebase -i</code>ing, a system like this&rsquo;d be possible.</p>
<p>But think of a semantic version control system, where each little atomic piece of writing could be individually manipulated, with its own version history. One way to implement this would be a system where each paragraph (or each sentence, each word, each character, even!) was a unique document, in Git terms. While you could edit the entire thing in one piece, each sub-document, with some arbitrary level of smallest unit, would be able to have its own history and own undo tree. I&rsquo;m reminded of software like Roam and other block-based note-taking systems, which could ostensibly integrate individual history systems for each block. If I understand their system correctly, <a href="https://remnote.com/">RemNote</a> could also do something similar with its &lsquo;everything is a Rem&rsquo; model.</p>
<p>This ties into the post I previously wrote about <a href="https://kewbi.sh/blog/posts/211114/">metadata</a> - here, the aspect of metadata I&rsquo;d be looking to enrich is time. As it stands, the most time-related metadata available for most notetaking systems is the date created, and date last updated. History, another facet of metadata involved in the above system, is also usually not very <em>rich</em>. It can&rsquo;t be manipulated very easily, nor is it intended usually as anything more than a simple worst-case-scenario-only backup system. But in writing, time usually plays a pretty big role, at least in my thought processes. I felt this a lot this past term, especially in some of my writing classes, as I mentioned in the introduction. Sometimes I need to step away from an essay for a couple days, or to keep writing page after page of useless drivel to finally hone down my actual point. With current systems, I&rsquo;m not able to cherry-pick paragraphs from a couple paper versions ago, or use time, in a way, as best as I could be.</p>
<p>There are trade-offs for this model - a major one would be the insane amount of data storage needed to keep infinite undo trees. Even if the scope was limited to the last couple edits, having each individual atomic block have its own history would add many orders of magnitude of both code complexity and storage required. Power users likely have tens of thousands of blocks - storing diffs that may never be used for each of those is likely unfeasible. But I can dream, and I can come up with slightly shoddy systems to replicate behaviour like this with my current systems. As I mentioned, with LibreOffice, I first work on an outline, then copy that entire outline above itself, and work on drafting that into coherent language. Then, when I edit, I either use Track Changes, or if that gets too messy, just make notes of old sentences that might be useful with comments. It gets a bit messy sometimes<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, but it works, and it&rsquo;s pretty satisfying to finally delete everything right before I hand in an essay.</p>
<h2 id="recency-bias">Recency Bias</h2>
<p>In terms of what I write about, one thing I&rsquo;ve noticed about the role of time is that whenever I write, there&rsquo;s a strong influence of wanting to write about what&rsquo;s currently on the top of my head. Over the past few blog posts, I think this&rsquo;s really manifested - I connect to recent conversations I&rsquo;ve had with friends more frequently than, let&rsquo;s say, something I read in a tech book a couple months ago. Maybe that&rsquo;s to say that the books weren&rsquo;t as interesting or as memorable as discussing with friends. Regardless, that memorability, or lack thereof, lends itself to a recency bias that tends to show up in what I write about, and what I draw on to support it.</p>
<p>One example of this, bringing it back to the English essay, was the way I chose the angle from which I decided to study it. We&rsquo;d read several books throughout the term, and I was starting to think about the essay somewhere through finishing the third. That third book happened to be a <a href="https://en.wikipedia.org/wiki/The_Curious_Incident_of_the_Dog_in_the_Night-Time_(play)">play adaptation</a> of <a href="https://en.wikipedia.org/wiki/The_Curious_Incident_of_the_Dog_in_the_Night-Time">Mark Haddon&rsquo;s <em>A Curious Incident of the Dog in the Night-Time</em></a>. I remember feeling like I really wanted to analyze this play - especially as I&rsquo;d read it before for other purposes. I think that was the recency bias kicking in, because I eventually settled on a different work, <a href="https://en.wikipedia.org/wiki/The_Best_We_Could_Do">Thi Bui&rsquo;s <em>The Best We Could Do</em>.</a>. Even though I&rsquo;d initially planned to study the role of memory in <em>TBWCD</em>, I ended up focusing on the themes of family, which happened to be what we were discussing while reading <em>A Curious Incident</em>. Perhaps this is just a coincidence, and maybe I really did end up analyzing Bui&rsquo;s depiction of family simply because that was what I found to be the most interesting and held the most potential for a unique reading. I can&rsquo;t help, however, noticing examples of this throughout the rest of my writing, and wondering if this is one of the strongest effects of time in sharing ideas.</p>
<p>This focus on fresher topics isn&rsquo;t a problem per se, but I&rsquo;ve realized one way to combat this recency would be to have a resurfacing mechanism that brought up old thoughts for you to process again. I think this is why systems like the original Zettelkasten, then workflows like Roam&rsquo;s or Notion&rsquo;s, hold so much promise and are so frequently used. With bidirectional backlinks and endless possibilities for you to stumble onto an old idea that you&rsquo;ll see anew, there&rsquo;s more serendipity at play here to rediscover thoughts. As well, the danger of forgetting ideas that weren&rsquo;t fleshed out as much is diminished with systems like this. Users can be gently reminded of them in due time, when they explore adjacent subjects. I think this is why so many people feel so attached to their personal knowledge management systems - they offer an assurance that their ideas won&rsquo;t be relegated to the bottom of the proverbial bucket. Write up a quick synopsis on this or that, link it and/or tag it up, and forget about it until you magically need it again. For me, I don&rsquo;t use typical PKM software, so I have to do this a bit more manually, but there&rsquo;s a certain sense of happy chance that happens when I go through old folders in search of something. With my system, I suppose this resurfacing is a lot more active rather than passive, but who knows - maybe that strengthens the ideas' connections in my own brain.</p>
<h2 id="editing-is-writing">Editing is Writing</h2>
<p>On the other hand, I can also definitely see how time plays a role in editing of my writing as well. Of course, the point of editing is that you can take the literal time to improve your work, and see how it changes over time, but I think time also works to hone your ideas. I&rsquo;ve talked about my <a href="https://kewbi.sh/blog/posts/210516/">outlining system</a> before, but again, going back to the English essay, I&rsquo;ve noticed how my ideas significantly changed over time and through editing. At first, I had ideas all over the place - tying in memory, identity, race, culture, second-hand experiences through a very wobbly thesis. When I first tried to edit things down, I blindly picked the subcategory that had the most sub-points and that I thought would be most relevant (second-hand memory) and chopped up my essay to deal with only that. My thesis got no stronger, and my writing was frankly even more messy - there just weren&rsquo;t that many examples that I could tie into a single overarching statement. But as time went on, as I edited more and pulled in different examples, I somehow had several eureka moments, and I finally realized what it was that I was trying to say.</p>
<p>Part of this comes down to the feeling that sometimes I have an idea, but I can&rsquo;t express it, and I don&rsquo;t even know what it is. It took time (a lot of it, might I add) to distill my analysis down to one line of argument. The thing is, all of my examples <em>had</em> been connected by a central theme (family and identity), but without taking loads of time to write and rewrite, I couldn&rsquo;t come up with the words to put it down, nor the realization of what I actually wanted to write about. When there&rsquo;s a lot of ideas swirling around in my head, it takes time for me to compartmentalize and learn to actually communicate them. In Ahren&rsquo;s famous <a href="https://takesmartnotes.com/"><em>Take Smart Notes</em></a>, he writes that &lsquo;writing is the thinking&rsquo;. My version, I guess, is &lsquo;editing is the writing&rsquo;. My point is that throughout coming up with an idea, and refining that idea, there&rsquo;s always a role of time: of iteration and of interconnection.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I&rsquo;m happy to say, I did much better on the English essay than I expected, and hey, writing it even sparked a long chain of thoughts about the role of time in writing, which turned into yet more writing! Even as I edit this article, I&rsquo;m realizing it is itself a result of the recency bias, and that I went through much the same process of turning a messy brain dump into something slightly more coherent while writing it. I think exploring how time shapes ideas, and how it lets them mull and grow and change completely, is an interesting aspect of thought to consider with regards to the whole tools for thought phenomenon.</p>
<p>While, as I mentioned in the arrangement section, most Zettelkasten-like software already brings some backlinking feature, I&rsquo;d like to see software that plays better with time, history, and resurfacing context. For the semantic version control system I proposed, this might be possible with a very deeply-nested Git-like model. There&rsquo;re possible applications of NLP in doing better backlinking and idea retrieval, in a more serendipitous way. As well, there might be other possibilities in NLP in summarizing thoughts and suggesting potential &lsquo;what was it that you really wanted to say&rsquo;, to help users distill their messages. Those are just a few of the posible ways more time-sensitive tools for thought could be built - and I might start looking into proofs-of-concepts for some of these.</p>
<p>I wrote this post while procrastinating on all the work that&rsquo;s hit with the start of Term 2 here at UBC. It&rsquo;s been kind of crazy the last week - I feel like through the past 5 days of classes I&rsquo;ve done the equivalent of 10+ days of break-time work. It&rsquo;s felt slightly overwhelming - there&rsquo;s been a lot of information and syllabi and course structures thrown at me at once, but we&rsquo;ll get through it. I&rsquo;m enjoying all my classes so far, and all my professors have been super wholesome. We&rsquo;ll see what this new term brings, but my goal is to reach out more - to friends, to professors, to peers. We&rsquo;ll see how that goes.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Interestingly enough, all the parts that I thought my TA would criticize for weak analysis were the parts that they liked, and the introduction, something I was pretty happy with, ended up being the main point of commentary.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Binary files notwithstanding, which according to the <a href="https://git-scm.com/docs/git-diff">git-diff documentation</a> use something like 64-byte chunks.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Cue the <a href="https://www.reddit.com/r/UBC/comments/rpxyo1/essayfinalnomoreeditsv2/">essayfinalnomoreeditsv2.docx</a> memes.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Buzzwords To Come</title>
      <link>https://kewbi.sh/blog/posts/220102/</link>
      <pubDate>02 Jan 2022</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On my far-fetched plans for 2022.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I was speaking with some friends who&rsquo;d read a <a href="https://kewbi.sh/blog/posts/211219/">previous blog post</a> earlier - we were talking about the balance of trying new things out to learn and explore versus continuing down paths that we were already on. He mentioned that this was how reinforcement learning works, which was a very interesting analogy that I hadn&rsquo;t thought of. Generally most of the time, the model / agent does whatever it thinks will result in the best outcome, but for some <code>x%</code> of the time, it takes a random action that&rsquo;s not in the set of &lsquo;possibly beneficial paths&rsquo;. That <code>x%</code> is how it discovers new opportunities for potentially good paths, perhaps finding shorter or more efficient routes to solve a problem.</p>
<p>I think this year, I&rsquo;d like to increase my <code>x%</code>. While I want to keep tinkering on some of the projects I have going on right now, I&rsquo;m looking at a couple areas in SWE and tech that seem either interesting, inspiring, or very applicable to my current interests. For the short-term future, at least, I think I&rsquo;ve mostly worked out what my &lsquo;best paths&rsquo; that I&rsquo;d be default be taking, so one of my goals for 2022 is to take steps off those paths and figure out what intriguing areas of development there are outside of my development &lsquo;comfort zone&rsquo;. Throughout the last couple months, I&rsquo;ve been meaning to take a look at a couple of areas of tech: Web3, NLP / AI, and diving deeper into the technical details of web dev.</p>
<h2 id="web3">Web3</h2>
<p>For the uninitiated (like myself), Web3 is a term used to refer to the concept of a new Internet paradigm focusing not on walled gardens and mass social media interactions, as in Web2, but on ideas of decentralization and historicity preserved through blockchain models. I&rsquo;m really interested in where Web3 seems to be going - it seems like many people from all corners of tech are experimenting and getting involved in it, and I still feel that I don&rsquo;t know much about it. I&rsquo;d like to get to understand the basics, at least, to make my own opinions on Web3 for myself (because boy, Web3 is a very polarized and opinionated topic).</p>
<p>This budding interest is likely because I&rsquo;ve been spending a lot of time on Twitter recently. I follow quite a few people adjacent to, or involved in, the Web3 space, so I&rsquo;ve been seeing a lot of Web3 and crypto-related<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> activity on my timeline. So may people seem to be getting involved in the community that I can&rsquo;t help but wonder what it&rsquo;s all about. Seeing the development of the <a href="https://www.constitutiondao.com/">Constitution DAO</a>, watching the wonderful creators I personally follow getting involved, observing the power of Web3 to unite and bring people together - those experiences were pretty amazing. I&rsquo;m also inspired by the viral nature of these Web3-based communities, where almost everyone&rsquo;s in some DAO or has some cute .eth tag in their Twitter bio. Maybe it&rsquo;s just because I want to surround myself with all these bright tech minds and crypto folks, but I do want into their passionate circles of tech and fun and Web3.</p>
<p>An interesting side effect of my way of stumbling into Web3 is that I wasn&rsquo;t really exposed to any of the negatives of Web3 until I started looking elsewhere for information on crypto. I first heard of Web3 through generative artist <a href="https://mattdesl.com">Matt DesLauriers</a>, and I saw how creators like him were using crypto to eplore new streams of revenue and share their work in new ways. Recently, however, especially on HN and other tech communities, I&rsquo;ve started to find a decent amount of crypto criticism as well. I&rsquo;ve personally enjoyed reading pieces like Stephen Diehl&rsquo;s <a href="https://www.stephendiehl.com/blog/nothing-burger.html">&lsquo;The Handwavy Technobabble Nothingburger&rsquo;</a> and Jay Pinho&rsquo;s cleverly named <a href="https://networked.substack.com/p/web3-i-have-my-daots">&lsquo;Web3? I have my DAOts&rsquo;</a>. I know it&rsquo;s easy, and I&rsquo;ve been logically reasoned into agreeing multiple times, to hate on the Bored Apes or whatever up-and-coming CryptoPunk movement, but I can&rsquo;t help but think I&rsquo;m missing their side of the story as well. My friends were joking that I&rsquo;d become a &lsquo;Web3 shill&rsquo; after I&rsquo;d ironically used the phrase &lsquo;WAGMI&rsquo;<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. It&rsquo;s interesting to me that these little Web3 nods are so strongly associated with their community. I want to see the whole picture - I think my current sources of information lie too far on either side of the &lsquo;is web3 beneficial?&rsquo; spectrum. I&rsquo;m not sure which &lsquo;side&rsquo; (I guess there&rsquo;s a false dichotomy here) I lean more towards myself, but I think exploring crypto a bit for myself would let me solidify my thoughts.</p>
<p>Some resources I&rsquo;ve found are the <a href="https://cryptozombies.io">CryptoZombies</a> page, and fellow Google Code-in GPW <a href="https://smsunarto.com/">Scott Sunarto&rsquo;s</a> <a href="https://web3.smsunarto.com/">handbook for Working in Web3</a>. I&rsquo;ve skimmed both pages, and I think they&rsquo;d be a solid start for my journey. I especially like how Sunarto&rsquo;s page is laid out sequentially in order of exploring Web3 with cute little checklists and curated resources, so I&rsquo;ll see how far I can get with that. I&rsquo;d like to get started in exploring Solidity (the language of smart contracts associated with ETH chains) on testnets, because I quite frankly don&rsquo;t want to burn actual money on this yet. I also have a very random idea for a proof-of-concept Discord-based blockchain that I might want to work on, but we&rsquo;ll see what that&rsquo;d look like.</p>
<p>Current barriers for entry mostly hinge on the fact that I&rsquo;m not quite 18 yet, and as such can&rsquo;t use many (or any, really) exchanges to convert fiat into crypto. This is fine - I don&rsquo;t think I need to hold any actual coins yet and I think I can get by fine with testcoins from faucets. If it comes time to actually fund my projects, I&rsquo;ll probably just wheedle my friends who are of age and into crypto to buy some for me. As of now, I also don&rsquo;t have any wallets yet, but I think that&rsquo;s quite easy to remedy.</p>
<h2 id="nlp-and-ai-for-semantics">NLP and AI for Semantics</h2>
<p>Something else I&rsquo;m interested in exploring is NLP, specifically in AI applied towards semantics and tools for thought. I&rsquo;ve seen a lot of amazing work surrounding things like semantic resurfacing, decentralized article recommender systems, and tonnes more, and I think there&rsquo;s a lot of cool applications possible, particularly in HCI and computer interfaces. It also helps, though this is a lesser reason, that AI&rsquo;s pretty in demand, and is favourably seen as a valuable base skill - but the HCI reasons still come first. One friend in particular&rsquo;s doing some really interesting work with NLP and recommender systems, and while I don&rsquo;t think that it&rsquo;s out by the time this post is up, it was very inspiring to go play around with a system that was able to capture and link my ideas together that well.</p>
<p>One of the things about AI is that it&rsquo;s become one of those CS buzzwords - a &lsquo;slap this onto x and you&rsquo;ll get a winning product&rsquo; sort of thing. It&rsquo;s so ubiquitous in today&rsquo;s technologies that it&rsquo;s taken almost as a default, or as something that should be implemented as a key selling point for everything. Alternatively, because it&rsquo;s not very well understood beyond the field of CS or science in general, I find that people revere it as if it were a dangerous deity with scary whims and magic powers. When I first started getting into development, I remember that was when AI for data science was starting to ingrain itself in popular media. Now, it&rsquo;s almost a de-facto area of study for CS students - I can&rsquo;t count the number of times my parents have said something along the lines of &lsquo;ooh, <em>AI</em>. You should get into that, it&rsquo;s really hot in the job market&rsquo;. I see their point, which is one of the reasons I&rsquo;ve decided to try to explore it this year. However, saying all this, I also want to be careful that I don&rsquo;t personally skew my projects and forays into AI with the idea that I want to apply it for commercial or clout purposes. I don&rsquo;t really think making another face recognition hackathon project&rsquo;ll be all that useful to the world (though perhaps I&rsquo;ll take a stab at one while learning, who knows), but tackling applications meaningful to me, like tools for thought and knowledge management, would be interesting.</p>
<p>Luckily, AI in general has very low barriers to entry, and there&rsquo;s plenty of resources that I&rsquo;ve been either recommended, or found in the past. Compared to Web3, which is still a budding field, AI at least seems to have more systematic guides and paths for specialization. There are tonnes of resources and things for learning AI (I think I&rsquo;ve gone through that &lsquo;build your own AI from scratch&rsquo; one-layer neural network series before), but I think I&rsquo;ve found an interesting resource specifically applied to semantics. Pinecone&rsquo;s (a company I hadn&rsquo;t heard of before finding this course) released an <a href="https://www.pinecone.io/learn/nlp/">ebook / MOOC-like course</a> applying NLP for semantic search. I guess it also wouldn&rsquo;t hurt to start playing around with Tensorflow and Keras and whatever fancy NLP/AI people work with nowadays, but I really&rsquo;d like to at least learn enough to build a small MVP for my own notetaking system. A couple ideas I have at the moment are for article condensation / prioritization scorers, and maybe something that can analyze the common aspects of articles I enjoy, but to be honest, I don&rsquo;t really know enough about NLP to even know what projects I can work on.</p>
<h2 id="how-i-build">How I Build</h2>
<p>Another core tenet I&rsquo;d like to set for this year is changing the way I build. Not in a particularly revolutionary way, but if you spend any time at all on Twitter, you&rsquo;ll see the #BuildInPublic trends and the communities of developers sharing what they&rsquo;re working on each day. Yesterday, one of my friends requested that I share what I was working on more frequently, and ping people who I thought would find whatever projects I was tinkering with cool. I quickly rebutted with a &lsquo;but I don&rsquo;t really work on anything&rsquo;, but they have a point. I find that I tend to do the whole &lsquo;dev in secret until I have something that&rsquo;s reasonably done, then release, and repeat cycle&rsquo;, and I think maybe getting more feedback on my ideas and showing off things I&rsquo;m passionate about to my friends would help me expand my points of view<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<p>I don&rsquo;t have a goal for the projects I&rsquo;d like to build this year yet, or a set number of things I want to ship, but to keep me aligned with my two steering goals for this year, I&rsquo;ll tentatively set myself the goal of making something Web3 and crypto related, as well as making something NLP / AI related. &lsquo;Something&rsquo; is purposefully a loose definition here: I don&rsquo;t think a single 30-line smart contract or cookie-cutter Tensorflow file&rsquo;d count, but I don&rsquo;t want to put any explicit quantifiers on what I must build either. I&rsquo;ll see how it goes, but I think I&rsquo;ll evaluate whatever I&rsquo;ve done with respect to a decent level of polish and how happy I am with the project.</p>
<p>Speaking of projects, I feel that my work is usully really self-contained and atomic. They&rsquo;re embodiements, I suppose, of the <a href="https://kewbi.sh/blog/posts/211219/">least common denominator</a> principle I discussed a couple blog posts back. Look at my GitHub - there&rsquo;s lots of tinkered-through projects, doing one little thing with a pretty clear scope and somewhat obvious start / end criteria. I experiment a lot with different technologies or purposes, but there&rsquo;s no real big projects - at least, not ones I&rsquo;ve built a concrete user base around or seem impressive enough to feature on my LinkedIn or resume. As much as I&rsquo;d like to pretend to be okay with being a software artisan and not having to worry about project maintenance or anything, I do slightly crave having an actual impact too. Hopefully, I can get some of this with the internship I&rsquo;m starting this summer, but I&rsquo;d maybe like to think of useful side projects that I can work on that not only benefit my very niche workflows, but could work for other people too.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I have a bunch of personal and non-tech related goals for this year, but as for the rest of my miscellaneous technical goals: I want to finish up the <a href="https://fullstackopen.com">FullStackOpen</a> course to properly learn React, I want to keep up my Anki habits when I get back to school, and I want to keep this blog up and running, with posts at least every month, while I work through my second term at university. This, combined with the aforementioned Web3 and NLP/AI, should prove to produce a very interesting and technically challenging year. I don&rsquo;t know how productive it is to sit here at the end of 2021 and romanticize finally getting into these areas of tech - I realistically know that I probably won&rsquo;t be able to tackle all of these projects this year. But it&rsquo;s nice to have goals and to have a backlog of things to explore and work on, so let&rsquo;s hope I do manage to increase my <code>x%</code>.Something that&rsquo;ll likely help me stay accountable with all this is that my friends and I are starting to talk through potentially making study groups to work through resources at our own pace but together, so we can leverage the community we already have to enrich our personal knowledge. It&rsquo;ll likely be a model similar to <a href="https://azlen.me/learn/">Azlen Elza&rsquo;s learning groups</a>, but we&rsquo;ll see how that goes.</p>
<p>It&rsquo;s super early in 2022, but I guess I&rsquo;ve already started slightly increasing my <code>x%</code>. I&rsquo;ve just accepted an internship offer at a very spicy company (no, not FAANG, but I like their culture and their product), and I&rsquo;m very excited to have the opportunity to work on actual products that have real impacts across so many millions of users. Everyone I&rsquo;ve met so far at the company&rsquo;s been amazing - I hope this isn&rsquo;t me being starstruck, but I&rsquo;m really looking forward to starting to work with them in May. I&rsquo;m surprised that I even got an offer and landed an internships seeing as I&rsquo;m still an unexperienced, slightly confused first year, and as I started applying super late, but hey, miracles happen. This&rsquo;ll be my first &lsquo;real&rsquo; job, and while I&rsquo;m a bit nervous about having actual deadlines and responsibilities, I think it&rsquo;ll be a great opportunity to grow and develop my skills, and again, I&rsquo;m extremely excited - 2022&rsquo;s been off to a great start so far.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Hereafter, the abbreviation &lsquo;crypto&rsquo; will refer to cryptocurrency of the Bitcoin sort; cryptography folks kindly avoid getting triggered at me kthxbye.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Which stands for &lsquo;we&rsquo;re all going to make it&rsquo;, a common Web3 phrase often followed by some combination of the rocket, diamond, hands, and starstruck emojis.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>A slight aside: I was looking through some of the project ideas I&rsquo;d come up with at the very beginning of 2020, and I thought I&rsquo;d share some of them here. They&rsquo;re very obviously <em>me</em>, and all rather niche and quirky:</p>
<ul>
<li>Python + Flask - Stable matching algorithm for students to rank the topics they&rsquo;d like to do the most, and arranges groups and matches topics to students. (I just wanted first pick at project topics)</li>
<li>Python - XORcise - socket &lsquo;chat&rsquo; where people compete to XOR / AND / whatever (the networking would be interesting)</li>
<li>Tensorflow + Kaggle - How likely are you to survive the Titanic? (still a half-solid idea)</li>
<li>Vue - LinkTree generator (except LinkTree is already a thing)</li>
<li>Python - Blackmail converter (? what blackmail did I even have)</li>
<li>C, Python - Keyspam - Brainfrick [sic] transpiler</li>
<li>Python - Regex - Carbon alkane naming CLI (I think I wanted extra biology points)</li>
<li>Tensorflow - Facial recognition and social / physical distance detector (why was the facial recognition a thing?)</li>
</ul>
<p>I have no idea how I came up with any of these, but hey - I was nothing if not rather creative back then.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>A Year of Articles</title>
      <link>https://kewbi.sh/blog/posts/211226/</link>
      <pubDate>26 Dec 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On tracking (almost) every article I read this year.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Early in January this year, I had a bit of a realization I was spending too much time reading blog posts. That, combined with a typical New-Year&rsquo;s resolution-y mood, resulted in me <a href="https://kewbi.sh/blog/posts/210207/">tracking every single article I read that month</a>. I&rsquo;d been reading a bit about the whole <a href="https://reddit.com/r/QuantifiedSelf">Quantified Self</a> community, and thought that while I wouldn&rsquo;t go as hardcore with collecting data on myself, I&rsquo;d take a stab at recording and rationalizing my leisure content consumption. Armed with a shabbily-patched-together Chrome extension and a hacky Google Form, I sorted out a system where I&rsquo;d hit a keybind to record the URL and timestamp of any post I was reading. This experiment mostly aimed to give me a sense of what my reading habits were like, and give me a fun data visualization at the end. Well, I guess my muscle memory of hitting Alt-T every time I stumbled across anything interesting on Twitter persisted, because I ended up continuing this experiment for the whole year.</p>
<p>I wrote out a more comprehensive list of &lsquo;rules&rsquo; in the January blog post, but the gist of it was that: I wouldn&rsquo;t include forum sites, programming help, quick Googles for one-off topics. I would, on the other hand, include the jumping-off points of deeper rabbit holes, any long and short form articles, and a new addition to the criteria - sometimes also lengthy / interesting Twitter feeds. Data was collected with my custom Chrome extension (source not available, but it just programmatically pushes to a central Google Forms - more about this was in the January post). For today&rsquo;s analysis, I pulled all the article information I had from the very beginning of this year (~6 January) to about the 20th of December. I&rsquo;d say that&rsquo;s a pretty good spread of data, and I think we&rsquo;ll be able to capture some interesting trends that I already expect. Last year, I talked a lot about information aesthetics, and I think that applied even more so this year. I know I had less time to read starting in the fall, so I gravitated more heavily towards existing sources of cool writing and avoided more exploration.</p>
<p>So, without further ado - I present to you, A Year Of Articles; or, as I like to call it, Kewbish Wrapped.</p>
<h2 id="the-hypotheses">The Hypotheses</h2>
<p>As all good experiments do, I started by considering some of my hypotheses. In January, I&rsquo;d found that towards the end of the month, I ended up reading less (which was sort of my goal back then - I wanted to reduce mindless clicking and content consumption). With regards to time, I usually had a couple big spikes in reading during the very beginning and ends of my day. I also found that I tended to read more on weekends - reasonable, as I usually had lots more time to scroll HN or Lobste.rs on the weekends. I liked that I was able to build up a notetaking system and a library around what content I&rsquo;d read, and also that I&rsquo;d be able to find interesting articles that I&rsquo;d picked up over the last month.</p>
<p>Over the past year&rsquo;s data, I expected I&rsquo;d keep finding most of these trends. Most of the above findings, I reasoned, would apply until at least summer, which was when I kind of both fell off tracking and started reading more casual articles (i.e. ones I didn&rsquo;t track) a bit more. Around September, I started really dialling in instead on optimizing my learning workflow for university, and really didn&rsquo;t have the time to read much anymore. My Matter<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> backlog started growing quite a bit, which I suppose would speak to the fact that it&rsquo;s easy to use, and became my consumption &lsquo;source of truth&rsquo;. That&rsquo;s good, and what I intended. However, I just wasn&rsquo;t finding the time to regularly process it, and I remember that starting a bit of a feedback loop of intimidation of going through it. As such, I probably expect that around the beginning of the school year - when I remember my backlog starting to pile up - there&rsquo;d be a sharp decrease in reading.</p>
<p>I won&rsquo;t be discussing each and every URL I read the past year here, but in terms of more meta-analysis, I expect to see a bunch more articles about tools for thought, planning, and meta-productivity in general. I still expect that my content &lsquo;diet&rsquo;, as people apparently put it, will be largely composed of the same Twitter-adjacent people I follow: tools for thought leaders, indie makers, and a rather niche subset of the larger SWE industry.</p>
<h2 id="the-data">The Data</h2>
<p>In total, in 2021 (minus a week or so in December), I read <em>535</em> articles. (174 of these were from the initial January experiment). That averages out to 1.54 articles a day - a rather reasonable number, and roughly what I expected given my binge-reading during the beginning of the year and my lack of reading towards the latter half. This graph shows the spread of the articles over the day of the year, with a rolling three-day average:</p>
<figure><img src="https://i.imgur.com/B993l2F.png?1"
         alt="Figure 1. A graph showing articles read per day"/><figcaption>
            <p><em>Figure 1. Articles read per day.</em></p>
        </figcaption>
</figure>

<p>You can see a very sharp spike near the beginning of the experiment in January - my running average then was about 6.69 articles per day, according to my previous writeup. The reading activity sort of bottoms out around around June and July, where the articles read a day became more consistent (when averaged). As I expected, and as I observed in January, there&rsquo;s still obvious spikes within each month, which I expect are from my weekend reading sprees. I&rsquo;m sort of surprised that come August and September, I tended to read <em>more</em> articles than in the early summer, even though I&rsquo;d have expected that I was spending more time adapting to university work. This &lsquo;second spike&rsquo; might have lined up when I started to write brief summary notes again on the articles I&rsquo;d read - a habit that didn&rsquo;t quite continue through to October or November.</p>
<p>I also crunched the time data for each article read and came up with a graph showing the most frequent times I&rsquo;d read articles:</p>
<figure><img src="https://i.imgur.com/CCK9hvP.png?1"
         alt="Figure 2. A graph showing time distribution for article readings per day."/><figcaption>
            <p><em>Figure 2. Time distribution for article readings per day.</em></p>
        </figcaption>
</figure>

<p>In the beginning of the graph, you can see a very heavy trend of morning reading sometime between 0800-0900. This persisted, though to a lessening extent, throughout the year. There&rsquo;s also a decently frequent trend of night-time reading around 2000-2100, which stopped somewhere in mid-March, according to the graph. I think this graph shows some of the changes in my reading habits well: during the beginning of the year, after the initial January spike, I was quite systematic and rigorous about what I was reading and when. Through the summer and into the school year, however, I ended up fitting articles in during my breaks and other in-between time, so there&rsquo;s not as clear of a trend later in the year.</p>
<p>I also thought it&rsquo;d be interesting to briefly look at the most frequent websites that I read from. The most frequently read URLs and their number of occurences were:</p>
<ul>
<li><a href="https://thesephist.com">thesephist.com</a>, at 16 articles</li>
<li><a href="https://paulgraham.com">paulgraham.com</a>, at 13 articles</li>
<li><a href="https://every.to">every.to</a>, at 11 articles</li>
<li><a href="https://lesswrong.com">lesswrong.com</a>, at 8 articles</li>
<li><a href="https://ben-evans.com">ben-evans.com</a>, at 7 articles</li>
<li><a href="https://bulletjournal.com">bulletjournal.com</a>, at 5 articles</li>
<li><a href="https://nesslabs.com">nesslabs.com</a>, at 5 articles</li>
<li><a href="https://evantravers.com">evantravers.com</a>, at 4 articles</li>
</ul>
<p>Medium and Nitter links weren&rsquo;t included in the above, though they rounded out to 8 articles each. I also did a bit of manual checking to get rid of the unique-URL problem with Paul Graham&rsquo;s blog, where I was somehow tracking both <code>www</code> and non-<code>www</code> versions of the URL. There were lots of other creators in the list with 2-3 posts each as well, but those were my top 10 URLs. I&rsquo;m pretty unsurprised with this list: I would have likely been able to name at least the larger blogs in this list. It&rsquo;s actually interesting to note that the majority of the list (not listed) has only 1-2 posts, reflecting a more indie / niche posting streak that I didn&rsquo;t return to as frequently.</p>
<h2 id="the-findings">The Findings</h2>
<p>I think the trend that I overall spent much less time reading throughout the year is very obvious, but I&rsquo;d like to dive into a couple possibilities besides &lsquo;school stress; no time&rsquo; that could have contributed to that. One, Findka, a now defunct service that worked to automatically crowdsource recommendations for essays and articles to read, shut down sometime early this year. I shouldn&rsquo;t say shut down - just pivoted to their new work with email newsletters instead (more about that later). Previously, before using Findka, I&rsquo;d relied on the front page of HN or CS Reddits or Twitter communities. With Findka, I was able to pretty consistently find interesting new content, without doing much searching myself. As Findka&rsquo;s recommendations died down, I simply didn&rsquo;t have many recommendations for articles to read, and the friction of going to find new ones just to satisfy my article cravings was too much. Two, I started shifting the time that I&rsquo;d previously allocated to reading long or short-form articles towards exploring communities and individuals on Twitter. I started using Nitter much more, and I think that this new stream of information somewhat replaced what I was getting from Findka. As a result, I ended up consuming more short-form tweets and exploring thoughts there. Of course, I didn&rsquo;t track individual tweets, just occasionally long threads that I&rsquo;d come across, but this is what I&rsquo;d suspect from what I remember over the past year.</p>
<p>I don&rsquo;t feel like there&rsquo;s anything really to change about these reading habits. I&rsquo;d like to perhaps dedicate more time in the coming year to read long-form articles and tackle some of the backlog that&rsquo;s built up over finals season again. One of my main blockers was that I didn&rsquo;t have easy access to my backlog while on my phone or anywhere not on my laptop: Matter tracks everything through a GitHub issue system, and I&rsquo;m usually not logged in on mobile. Maybe a feature I&rsquo;ll start working on is a custom URL just for me that links to my GitHub token and would let me access my backlog through Matter when on mobile, but there&rsquo;re some security things that I&rsquo;d probably want to iron out better before I go live with that. Being able to spend too much more time on reading is probably wishful thinking, but hopefully since I&rsquo;ll keep it mind more I&rsquo;ll also end up doing it more.</p>
<p>Some other changes I&rsquo;d like to consider next year are expanding my content sources a bit, with regards to both creators and in topic. Right now, as you can see with my top few URLs, I end up returning to the same couple creators and the same few areas of content: productivity, HCI, and theoretical CS if I feel intellectual. It might be nice to move away from overall content aggregators like HN or Lobste.rs, and revisit Findka&rsquo;s new offering of a newsletter forwarder called <a href="https://thesample.ai/">The Sample</a>. I found that Findka gave me a decently nice breadth of articles that were all tailored to my general preferences for voice, tone, and topic. One of my friends is working on something really cool in this recommendation / discovery space as well, and I&rsquo;ve been pestering them every so often to see what their work&rsquo;s looking like. Another system I&rsquo;m following is Paul Bricman&rsquo;s <a href="https://paulbricman.com/thoughtware/lexiscore">Lexiscore</a>, which aims to combat information overload and tweak your digital content &lsquo;diet&rsquo;. Tools like that provide content that&rsquo;s more immediately interesting to me, and I end up spending less time scrolling endlessly looking for interesting things. I&rsquo;m cognizant of possible echo chamber effects if I rely too heavily on recommenders that are tuned directly to my liking, but if I only have so much time for reading, I may as well enjoy it.</p>
<p>And lastly, I had a system early in the year where I&rsquo;d pull all the articles from my reading tracker at the end of each week and briefly summarize it. I&rsquo;d built up a list til about the middle of the year of annotated links - noting anything interesting about the post, specific quotes or lines that I thought were interesting, or keywords that I might be able to link to when chatting with friends about similar topics. I ended up not doing that over the latter half of the year, mainly due to time constraints again. If possible, I think that annotation process made my reading a lot more active and meaningful, so I&rsquo;d like to get back into it. I liked looking back over a week&rsquo;s worth of reading and seeing what I tended towards and what interesting ideas others had around me, so perhaps I&rsquo;ll pick this up again in the New Year.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I think this was a pretty fun self-experiment to run over the past year, so I&rsquo;ll likely refresh my spreadsheet and form architecture and run it again next year as well. It&rsquo;s like a Year In Review retrospective that some developers do crossed with the data analysis and whimsy of Spotify Wrapped. I personally like meta-analysis content like this, so look forward to the possibility of a Kewbish Wrapped 2022 late next year. And while today, I mostly discussed the consumption of content, I&rsquo;ll be writing up a post about my content creation processes and how those have changed sometime in February<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>I&rsquo;m writing this late on Christmas Day, so happy holidays, for those of you who are reading. I&rsquo;m excited to finally have a break from formal, structured school, and some time for myself to tinker around with some dev stuff as well as pre-read for the next term. I&rsquo;m still waiting for some of my grades to come out, which isn&rsquo;t particularly fun, but I think I&rsquo;ve mentally disengaged with my grades, at least for this term. What&rsquo;s done is done, and I may as well focus on how I can make the next term as efficient and satisfying as possible instead. I&rsquo;ve finally finished up <a href="https://adventofcode.com">AOC</a> earlier today, so I plan to use that chunk of time that I&rsquo;d previously dedicated to bodging my way through solutions each morning to maybe doing some more writing. I enjoy sitting here and brain-dumping all of the musings I have sometimes, so hopefully I&rsquo;ll have some more articles and thoughts to share in the New Year.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The tool I use to track all my &lsquo;to-reads&rsquo; and RSS feeds, more about it <a href="https://kewbi.sh/blog/posts/210207/">here</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>The first blog post ever on YK was published on Valentine&rsquo;s Day around two years ago - this was mostly a personal joke à la &lsquo;haha look at me I&rsquo;m so lonely and nerdy that I wrote about my open source instead of touching grass and having fun what a cs kid&rsquo;. But I think that time of year&rsquo;s actually a bit better for retrospective / new-year&rsquo;s content, since by then any resolutions you&rsquo;ve stuck to have had enough time to sink in and develop, and any that you haven&rsquo;t managed to keep up have long been ditched.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Least Common Denominators</title>
      <link>https://kewbi.sh/blog/posts/211219/</link>
      <pubDate>19 Dec 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On an atomicized software culture.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>A while ago, I finally bit the bullet and picked up a copy of <a href="https://www.calnewport.com/books/digital-minimalism/"><em>Digital Minimalism</em></a> at the library. It&rsquo;s a hugely famous book by Cal Newport, a popular (and for decently good reason) productivity author and CS professor. If you haven&rsquo;t heard of his philosophies surrounding technology usage and mindful technologism, you might want to go take a look at his work yourself. <em>Digital Minimalism</em> specifically focuses about social media and connecting with others virtually. A quick summary of <em>Digital Minimalism</em>: social media is often used for things that aren&rsquo;t useful, but &lsquo;could be&rsquo; - and that &lsquo;could&rsquo; is what hooks us to our devices in spite of ostensibly more productive and meaningful activities. The book centers around how to be more intentional about your digital footprint, media consumption, and online interactions with others.</p>
<p>At a very high level of abstraction, Newport discusses how we can make the tools we use less noisy, and to adapt them to work for us, not the other way around. You might recognize this phrasing, for good reason - it&rsquo;s often used when discussing tools for thought. That&rsquo;s what I wish to think about in this article. His philosophy is applicable not only to online connections and the <a href="https://kewbi.sh/blog/posts/201108/">endless maze of pings</a>, but with software as a whole as well. I&rsquo;ve discussed <a href="https://kewbi.sh/blog/posts/210124/">hyperpersonalized</a> software quite a few times on this blog, but Newport distills many of the ideas that orbit around that sort of artisan-created, artisan-facilitating software. However, while his advice centers around the <em>use</em> of social media and tools, I think there&rsquo;s a lot to be said about how we can <em>create</em> software in a way that pushes more worthwhile consumption and creation.</p>
<h2 id="but-what-if">But What If?</h2>
<p>In the book, Newport discusses a sort of &lsquo;but what if?&rsquo; logic that people tried to apply in order to push him towards getting on social media (which he had not, and has not done). He recalls that people often told him that he should consider joining social platforms, and when he asked why, they sort of universally came up with a &lsquo;but what if it&rsquo;s useful?&rsquo;, and a &lsquo;I&rsquo;m sure you&rsquo;ll discover something on [XYZ] that you&rsquo;ll find really meaningful&rsquo;.</p>
<p>I&rsquo;ve felt this way a lot myself. Two big examples of this that come to mind are Twitter and Notion / Roam / Obsidian. With Twitter, a lot of people in my friend circle&rsquo;ve hinted at the magical wonders of Twitter, and let me know that I&rsquo;d likely like it there. This is a bit tricky to unpack, because I know I would find it useful. I really do want to immerse myself in communities of people who are doing things much cooler than what I&rsquo;m working on, and be inspired<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. On Twitter, there&rsquo;s a sense of having a space to share my thoughts and ideas with a further group of people that I&rsquo;d really value. But on the other hand, I have a feeling I&rsquo;ll be constantly pulled into the discussion there. Right now, I do consume a decent bit of Twitter material with my <a href="https://kewbi.sh/blog/posts/210110/">Nitter</a> setup. It&rsquo;s sort of like having write lock - I can &lsquo;read&rsquo; from these systems fine for now, so I&rsquo;m trying to wean myself off the feeling I want to contribute directly there too yet. As Newport points out, I don&rsquo;t know what I&rsquo;d like to get out of Twitter. There&rsquo;s a bit of a circular dependency: without having been on the platform, I can&rsquo;t gauge what value it&rsquo;d return for me, and so I don&rsquo;t use it.</p>
<p>The same goes for Notion or other notetaking software. Each system has its own benefits: Notion, its centralizability; Roam, its database and linking model; Obsidian, its file-based focus. With notetaking tools, I feel less of what Newport describes, less of the &lsquo;what-if&rsquo; effect. I think it&rsquo;s because I&rsquo;ve felt the inertia of wanting to stay with my own systems, and because I&rsquo;m passionate about and know what I&rsquo;m doing with my knowledge management workflows, at least for now. Notion, for examples, brings a lot of maintenance and workaround effort - sure, I&rsquo;ve seen people organize their whole lives in it, but for their aesthetic setups they have to bring in custom icons and lots of layered filters. Could the same thing not be accomplished with separate notetaking, calendar, finance management, and habit apps? This isn&rsquo;t to say I don&rsquo;t have the same issues in the terminal, but I feel like I&rsquo;ve learned to cut down on it and recognize when there are better tools, cutting down on my &lsquo;what-if&rsquo; effect.</p>
<p>I recently had a conversation with a friend about <a href="https://github.com/Eeems/oxide">Remarkable launchers</a> or something - he was discussing with another friend why they&rsquo;d want to add a launcher to their tablet. Someone asked him what the point of the launcher was, and what he&rsquo;d personally used it for. He couldn&rsquo;t come up with any concrete examples (which is fine), but I jumped in and pointed this out. He was recommending a software without having an actual real use case for it, with the same &lsquo;but what-if&rsquo; thinking that seems to be so pervasive when working with software workflows.</p>
<h2 id="least-common-denominators">Least Common Denominators</h2>
<p>All this is to say that these recommendations are definitely valid, but in a different way. In <em>Digital Minimalism</em>, Newport specifically advocates for digging deeper into why you want to use a specific social media platform - for example, he notes a discussion he had with a client who realized he wanted to use Instagram to keep connections going with his childhood friends and see visually what they were up to. But Newport pushed him further, and asked if Instagram was the most productive and efficient way to engender that connection. Text messages and SMS photos would accomplish virtually the same thing, cutting out the distractions and even encouraging more meaningful discussion over thoughtless &lsquo;like&rsquo; interactions. And though messages were good, an in-person visit would add even more! Newport guided the client to go from what they wanted (connection) to a less distracting and more personable way to achieve the same thing (visits and text messages). This isn&rsquo;t applicable to all uses of social media and software, but there&rsquo;s an interesting idea I want to pull out in there.</p>
<p>What if we created software in a way such that we could get to exactly wanted, without all the other distraction and features that aren&rsquo;t useful to us. I thought of the term least-common-denominator software for this, trying to capture the idea of having the least possible component to do what you wanted while being composable and not having other features that you weren&rsquo;t interested in. Users can then select the exact feature set that matters to them, instead of having to settle for something that does too many things without optimizing for their own use-case. This form of software would break components and systems down into their least common denominator bits - atomic scripts that can do their job and just that. In my Twitter example, I&rsquo;d retain some ability to interact with people that I Twitter-simp over, without the noise and addiction and spam that&rsquo;s also on there. With Notion, I&rsquo;d be able to have a centralized source of truth database while having multiple views for everything, but also avoiding the performance issues and annoying workarounds people often have to use. There&rsquo;s got to be some reasonable limit for this granularity and control, but beyond that, why can&rsquo;t we have more composable systems?</p>
<p>For the developers among you, this&rsquo;d sort of reflect an extended view of the Unix philosophy applied to modern-day software systems. Do one thing, and do it well: so the Unix philosophy reads. Currently, most software is focused on doing multiple things, and doing them all decently. I hate to rag on Notion so often, but it&rsquo;s the perfect example - infinite capabilities, but each complicated system requiring many workarounds and hours of setup. Least-common-denominator software would optimize for its one use case and for sending its output to other tools. What I envision is something like the complicated multi-command pipes in bash, with commands passing data back and forth, only with a much better user interface.</p>
<p>Another idea that I&rsquo;d like to touch on is that least-common-denominator software wouldn&rsquo;t be like SaaSes or the constantly updating tools we use today. Of course, they&rsquo;d be maintained, and bug-fixes would pop up when needed, but I think having more atomicized software incentivizes it to be <em>done</em> much more quickly. Nowadays, if a product or tool or library is declared <em>done</em>, with work remaining only for issues and such, people tend to mentally mark it as deprecated and move onto the next shiny thing. But because these atomicized components wouldn&rsquo;t have a lot of interaction to do, there wouldn&rsquo;t be an endless backlog of features to work through, nor an increased surface area for bugs to pop up - again, they&rsquo;d do one thing, and do it well.</p>
<p>I won&rsquo;t go too far into what this sort of software system would look like, mostly because I haven&rsquo;t really figured that out. As to what technologies might be used: I&rsquo;ve mentioned <a href="https://www.inkandswitch.com/cambria/">Cambria</a> in a previous post about moving metadata around and translating data between sources. Tools like this to automate and facilitate data manipulation&rsquo;d likely be a central factor of this type of system, as well as open-source and transparent ways to organize and host data.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Though we can dream, I also don&rsquo;t realistically think a large-scale shift to this sort of minimal yet composable software&rsquo;ll get very far. For one, companies will certainly not stick to their core products - each big tech company:tm: has its countless failed / attempted / halfhearted ventures out into side businesses. Why wouldn&rsquo;t they want to monopolize user&rsquo;s time, and find new ways to appeal to their software / tool inertia to keep them with their existing software? In Newport&rsquo;s book, he writes that it&rsquo;s not very profitable for businesses to reduce their distractions. In this case, it&rsquo;s not very profitable to keep things minimalist and stop mashing new features into the app. As I&rsquo;ve mentioned before, standardization and the data processing aspects of these components would also get pretty complicated, and it&rsquo;s not clear what such a distributed model of software would look like without having a more open culture of software usage, where people can control their own tools and information.</p>
<p>I used to laugh at my friends when they&rsquo;d talk about whatever apps or whatever aspect of their systems being &ldquo;bloat&rdquo;<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, but I&rsquo;ve started to appreciate why they&rsquo;re pointing it out. It&rsquo;s a pattern (I won&rsquo;t say problem) that&rsquo;s pretty widespread across software as we use it today, and I&rsquo;d like to think that reinventing how we work with tools and software could help change that.</p>
<p>I&rsquo;m writing this during finals season, in between studying for separate exams and cramming practice papers. (Well, now that I&rsquo;m editing this conclusion, I&rsquo;ve got through nearly all of my exams already, but oh well.) I had a weird realization a month and a half before the end of term that it was <em>a month and a half before the end of term</em>, and I started trying to work on my study guides and come up with a plan of attack. I&rsquo;m glad I started early - I don&rsquo;t think I properly realized just how much there was to do, nor how much time it&rsquo;d take to get through all the practice materials I&rsquo;d want to tackle. I backloaded things weirdly, having a lot of my review and study sessions planned just before finals week started, and now I&rsquo;m slightly suffering my way through all of it. But lessons learned for next time, and I got through most things fine.</p>
<p>I also recently had my first couple of software engineering intern interviews ever, which was both really exciting and incredibly nerve-wracking. (If anyone working at a company I&rsquo;m interviewing at right now reads this, I assure you that I&rsquo;m probably overly enthuastic about the possibilities of working there! I assure you I&rsquo;m not normally this&hellip;rambly about software.) It&rsquo;s kind of scary that an actual company is considering taking me on to do work for them, and that I could potentially be making a very real impact to products. Things seem to be going well, but the sunk-cost is kind of kicking in, and with every round, I keep getting more and more nervous that they&rsquo;ll just decide I&rsquo;m not a good fit and not consider me. But such is life, and I&rsquo;m looking forward to my next couple rounds. Fingers crossed!</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>One friend in particular describes it as an online <a href="https://kk.org/thetechnium/scenius-or-comm/">scenius</a>. We&rsquo;ve (me and this particular group of friends) talked a decent bit about finding IRL sceniuses (ironically on an online chat). I guess this pull towards online groups stems from the fact that I don&rsquo;t really have that experience in-person right now. Oh well, perhaps I&rsquo;ll stumble into some quirky CS friend groups soon, but for now, I do have my digital scenius influences (you know who you are).&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>If you know, you know. I can literally hear the person I&rsquo;m thinking of saying this as I write it.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Metadata and You</title>
      <link>https://kewbi.sh/blog/posts/211114/</link>
      <pubDate>14 Nov 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On metadata, its dimensions, and its impacts.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Recently, I&rsquo;ve started pondering the tools-for-thought phenomena again, but perhaps in a more meta way. From what I&rsquo;ve noticed on Twitter (at least for the short amount of time that I&rsquo;ve been checking content from it), there&rsquo;s been a trend over the past couple years with the explosion of popularity of apps like <a href="https://roamresearch.com/">Roam Research</a>, <a href="https://obsidian.md/">Obsidian</a>, <a href="https://logseq.com/">Logseq</a>, <a href="https://www.notion.so/">Notion</a>, <a href="https://workflowy.com/b/">Workflowy</a>, <a href="https://ankiweb.net/">Anki</a>, or the myriad of other apps that solve a major pain point for a lot of people: the management, and meta-management of knowledge. Here, I&rsquo;d like to focus on the meta-management aspect of this a bit. I&rsquo;ve noticed a lot of the tools rapidly gaining popularity and (appear to be) pushing the forefront of human-computing interfaces have a shared trait in common: they&rsquo;re all in essence ways to manipulate metadata.</p>
<p>Metadata and knowledge can sometimes blend together, likely a result of metadata-deficient systems where a majority of the knowledge was spent on cross-labelling itself in lieu of proper metadata. When I reference metadata, I&rsquo;m talking about not the juicy knowledge itself, but the trail of breadcrumbs leading to it - the labels, the categorizations, and the aliases. Things like &lsquo;time last modified&rsquo;, &lsquo;time created&rsquo;<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, and other custom labels all fall under the umbrella of metadata. There&rsquo;re also actions associated with that metadata, like advanced regex-based searching, filtering by tag or label, alternate &lsquo;slices&rsquo; of data. The apps I&rsquo;ve mentioned above all extend or have significantly innovated and built features connected to metadata. Roam, likely one of the more popular examples, has their famous tag and linking system. Click on a little hashtagged bit of context, and you&rsquo;re teleported to a page full of other mentions of the same topic - the very alternate &lsquo;slicing&rsquo; of data I&rsquo;ve just mentioned.</p>
<p>Metadata is the apparent solution to the categorization problem, and what appeals so powerfully to the part of the human brain that craves neat little boxes. The issue with software is that it&rsquo;s generally not <a href="https://kewbi.sh/blog/posts/210124/">hyperpersonalizable</a>. Settings can&rsquo;t be tweaked in every single little way that all the different workflows and people using the app demand - core feature development would stall to a standstill, and devs would spend more time implementing personalizations than concrete tools. But people still want to create their own little classifications, and make the app <em>theirs</em>. Metadata here is the fix - at least, for most people. Some users might feel overwhelmed (look at the hours of &lsquo;get started with Notion&rsquo; videos and the pages of questions about certain tweaks), but on average, I&rsquo;d say that most people generally approve of this ability. Less personalization-focused people can simply overlook the metadata, or implement just the core basics. Power users, on the other hand, can use custom fields and metadata to their heart&rsquo;s content - just look at the magic people pull off with Notion databases.</p>
<p>I&rsquo;ve been thinking a lot recently about tools for thought, and their first principles. What are the majority of lauded apps rooted in? What trends and tendances is society looking for in popular apps? In this post, I&rsquo;d like to share some of my realizations (well, that&rsquo;s a strong word) about the space and the role metadata plays in our knowledge interactions.</p>
<h2 id="manipulating-the-meta">Manipulating the Meta</h2>
<p>Apps do some combination of three key things with metadata: write it, connect it, and allow it to be synthesized and searched for and molded. For example, take something like <a href="http://trello.com/">Trello</a>. You can tag and label your to-dos (writing metadata), link them to one another across boards (connecting it), and have high level overviews and statistics about your project (synthesis). This last bit about super-synthesis is important, as it creates a new level of meta. With that, there&rsquo;s a possibility to invest in linking up metadata about the metadata, and that&rsquo;s where the potentials for new tools and new innovations lies.</p>
<p>In a sense, the true innovation factor of these popular apps lies in the meta-levels that they provide. Roam and Notion and whatnot aren&rsquo;t the power tools they are because of some revolutionary new way to interact with data itself: it&rsquo;s the refreshing levels of interactions they offer with the metadata instead that boosts the quality of life when working with the knowledge and data itself. Most tools offer a good baseline of data management, and some level of interconnectedness and tagging and such, but when software offers a new way to interact with the metadata, that&rsquo;s when you get interesting workflows and environments. Roam, Notion, and other apps with a block or bullet model appeal to people because of their fine-grained connections, something that was lacking in the common sterilized, document-driven approach.</p>
<p>A good example of this is what inspired me to write this whole blog post: the <a href="https://roamjs.com/extensions/discourse-graph">Discourse Graph</a> extension available in Roam. I don&rsquo;t use Roam, nor plan to daily drive it in the near future, but there&rsquo;s something about this extension in particular that really tempted me to switch. It works with your existing Roam graph to provide a formalized note model, composed of questions, evidence, claims, conclusions, and all the connections in between. It&rsquo;s suited well for a research ecosystem, with tools to denote that this note &lsquo;supports&rsquo; or &lsquo;refutes&rsquo; or &lsquo;weakly correlates&rsquo; with another. This in itself is a powerful metadata model - the codified structure takes away decision paralysis, and creates a very regimental and logical order of graphs. However, where this extension goes above and beyond is its playground feature, where you can query your model for &lsquo;all evidence that supports X and refutes Y&rsquo;, for example, and find &lsquo;all claims that connect to such and such question&rsquo;. That&rsquo;s a truly new model of interaction with metadata, and a great example of how having a structure and tools to manipulate metadata can lead to connecting together key insights in your knowledge.</p>
<h2 id="data-dimensions">Data Dimensions</h2>
<p>Besides having tools built into software to analyze metadata, it&rsquo;s also important to allow users to implement their metadata to fit their workflow. People&rsquo;ll always want more dimensions to categorize and subcategorize and fit all their data into - I remember when I was trying to implement Trello into my workflow, I was pretty frustrated at the lack of sub-bullets and sub-tasks, and had to make do with a very scuffed checklist model instead. The same goes with nesting - Workflowy&rsquo;s popular for a lot of reasons, but one is the infinite hierarchy that it provides. That infinity is also something interesting to note: as long as something&rsquo;s not unlimited (to a reasonable depth), a subset of users will feel like they&rsquo;re hitting a wall with what the software can help them do. Whatever depth of metadata is available, unless unlimited, will feel like some construct to at least some people, if not a significant portion. This creates essentially infinite &lsquo;axes of belonging&rsquo;, or categories with which to split data up. Axes of belonging are like possible views and queries into the data, and if the number of axes can be maximized, having all these new variables and possibilities makes software ostensibly more powerful for those power users.</p>
<p>But there&rsquo;s still a fine balance to walk between too complicated with too many dimensions and axes of data, and too few. Excel, arguably perhaps one of the original tools for thought and innovators in the metadata space, does this quite well. The spreadsheet and table interface is immediately intuitive for many, but hidden deep into menus and tabs that the average user will never explore, are the hidden gems that probably makes someone&rsquo;s workflow click. There are infinite ways to associate metadata to a cell through other cells or formatting or conditional formulas, and an infinite canvas full of columns and rows to stack all your data in. This is, I think, how people think connections work best - through categories, expressed here in table associations. Maybe it&rsquo;s not the best and most efficient way to work, because sometimes constraints are what you need, after all. But with its many metadata dimensions and built-in ways to explore data, Excel feels so open, and that&rsquo;s a trait in software that I think people are almost universally drawn to.</p>
<h2 id="standardizing-might-will-fail">Standardizing Might (Will?) Fail</h2>
<p>So far, I&rsquo;ve discussed the two main elements of what makes metadata integration so appealing. However, to get multiple people on the same page, all benefiting from the same metadata innovations, tools will need to have some shared standard, or some sort of schema. Schemas are inherently limiting though, unless they&rsquo;re explicitly <em>un</em>-limiting. But in that case, the point of standardization and extension is a bit moot. To some extent, I think you can get schemas to be flexible and agree, but there&rsquo;s a fine line between too much structure and the sort of spec that goes &lsquo;literally any field can be literally anything, go have fun&rsquo;. How are new features proposed and added across so many apps? Will a central standard have to be patched? How can we make it backwards compatible without &lsquo;de-dimensionalizing&rsquo; or flattening metadata?</p>
<p>There&rsquo;s a <a href="https://xkcd.com/927/">relevant XKCD</a>, as there always is, but there&rsquo;s also a couple relevant tools that might work to bridge the gap between different tools. <a href="https://www.inkandswitch.com/cambria/">Cambria</a> by Geoffrey Litt (and Peter Van Hardenberg and Orion Henry) is a tool to move data between schemas. In essence, it&rsquo;s a Google Translate for tools for thought, where &lsquo;lens&rsquo; can be defined to rename fields, convert between datatypes, and extract certain labels. It partially solves the issue of differing standards, as apps can define ways to translate and transmute metadata between each other. This does assume that software companies are willing to cooperate with each other (a stretch), or that there&rsquo;ll be dedicated users who drive this system forward (definitely more likely). Something like this doesn&rsquo;t solve the issue of how rich interactions and media based on metadata that&rsquo;s not quite supported should resolve, but it&rsquo;s a great step to linking all these tools and towards a more metadata-friendly future<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>For software being developed today, I think there are some decently clear trends in users becoming more tech-savvy, and in power users craving even more functionality. In the new field of knowledge work, maximum efficiency is glamorized and lauded. While that has its own caveats that I won&rsquo;t get into now, it&rsquo;s key to consider that, in general, people seem to be trending towards wanting more options and more connectivity through the meta. It&rsquo;s taken me this long to realize that I&rsquo;ve essentially written a SEO boost for the company-that-must-not-be-named, but oh well. We&rsquo;ll roll with it, because that appears to be what the zeitgeist is moving towards: a future of connectivity and linking<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Maybe in this case, I&rsquo;m thinking of it more in terms of knowledge management than magical VR metaverses, but the case in point holds.</p>
<p>In other news, I&rsquo;ve been up to more work with <a href="https://fullstackopen.com/">Full Stack Open</a>, and I&rsquo;ve also tried to start the <a href="https://cses.fi/problemset/">CSES problem set</a> while bodging my way through C++. It&rsquo;s been a while since I&rsquo;ve felt this beginner - it took me a solid hour and half to write a basic <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz sequence</a> simulator. Granted most of that was looking up syntax and tweaking a basic Vim setup, but it was certainly a knock to my Python tendencies. CSES is kind of one of those things that&rsquo;s good for you, and somewhat fun, but only in small doses, not when trying to grind certain amounts of problems per session or whatever. It&rsquo;s been a good brainteaser so far, so I think I might enjoy (very) small amounts of it in the future. I also feel like I&rsquo;m starting to spread myself too thin - I&rsquo;ve started doing some stuff at the <a href="https://ubccsss.org/">UBC CSSS</a> as well. I&rsquo;m halfway certain it&rsquo;s something to do with being immersed in an entirely new world of uni, and surrounding myself with people who all seem much more experienced and cooler than I am. It&rsquo;s a good ego check, but it&rsquo;s also been inspiring me to explore and look into a lot of new things. Halfway a good thing (exploring new areas of CS, doing fun things), halfway a not-so-great thing (occasionally self-overwhelm and loads of imposter syndrome), but I think I&rsquo;ll be able to manage, so we&rsquo;ll see what happens.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>There&rsquo;s also a lot to say about the fact that the most common, and most baseline metadata is often that of time. It&rsquo;s something that&rsquo;s easy to connect to a physical moment, a decently useful bit of information for most contexts, and straightforward to record in server logs. It&rsquo;s also an universal constant - people across different cultures can&rsquo;t interpret time differently, nor can users argue over the best way to tweak it. It&rsquo;s just time. (More on this maybe in another post soon - I&rsquo;ve got some ideas brewing that I&rsquo;d like to investigate further.)&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>It&rsquo;d be interesting if something like this got centralized / listed into some graph. It&rsquo;d then be a link full of linked ways to link (and manipulate) links in linking software! (Infinite metadata recursion, and it&rsquo;s turtles all the way down.)&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Besides the unintentional reference to Facebook, the title of this post is a cute nod to <a href="https://thesephist.com">Thesephist&rsquo;s</a> project <a href="https://thesephist.com/you/">&lsquo;a piano and you&rsquo;</a>.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>Starting Anki</title>
      <link>https://kewbi.sh/blog/posts/211031/</link>
      <pubDate>31 Oct 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On proper SRS, GTK hacks, and the Leitner system.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Something that I&rsquo;ve realized throughout my first month and a half at university, is the sheer volume of information and responsibility placed on a student&rsquo;s shoulders. I love it. Being able to manage myself and have full(-ish) control of my courses, my performance, and the rest of my life has been great. I like being immersed in content that I truly don&rsquo;t understand, and that challenges me a bit to actually understand and make sense of the material. However, there&rsquo;s a balance: I like that there&rsquo;s exciting and decently interesting information, but it&rsquo;s, of course, annoying that there&rsquo;s a lot of it. I&rsquo;ve had to, and am still in the process of, figure out how to get through all of this material, and get through it decently well. My courses are very spread out in terms of specialization, and some are quite memorization focused. Improving and optimizing my recall and comprehension are now starting to become interests and priorities of mine.</p>
<p>Well, it&rsquo;s Halloween, and I don&rsquo;t know how spooky flashcards and memory management are, but here I am to discuss <a href="https://en.wikipedia.org/wiki/Spaced_repetition">spaced repetition software</a> and <a href="https://apps.ankiweb.net/">Anki</a> in particular. (I won&rsquo;t go into what these are right now, but go ahead and take a look at those resources if you&rsquo;re interested.) I&rsquo;ve been dabbling with <a href="https://kewbi.sh/blog/posts/201025/">a variation of SRS</a> for a while now, and have recently even been working on a <a href="https://github.com/kewbish/liberty">free-response version of the philosophy</a>. I&rsquo;ve tried both <a href="https://quizlet.com">Quizlet</a> and terminal UI versions of flashcard apps, like <a href="https://github.com/proycon/vocage">vocage</a> and <a href="https://github.com/Yvee1/hascard">hascard</a>. I&rsquo;ve known about Anki for a long while now, but I&rsquo;ve never really looked into it. I&rsquo;d always discounted their SuperMemo2 algorithm, and thought its applications didn&rsquo;t overlap with my needs.</p>
<p>However, what finally pushed me over the edge was taking ATSC113 at UBC. It&rsquo;s a course about atmospheric sciences, and goes into the weather in relation to flying, snow sports, and sailing. It&rsquo;s a course with lots of vocabulary and concepts that I&rsquo;d never thought about or learned about before: plenty of memorization heavy work in areas that I&rsquo;m completely unfamiliar with. I&rsquo;d tried to review notes on a regular basis, and made my own flashcards in an attempt to test myself. However, I kept needing to schedule review sessions and assess my level of comprehension myself, which introduced a lot of mental friction. I knew that I was probably going to start looking for something new to try, so I decided to be proactive and take a look at Anki.</p>
<p>When I started looking into Anki, I was initially a bit turned away by the aesthetic. It&rsquo;s very utilitarian, and I hadn&rsquo;t really considered it as it looked so archaic and decidedly unaesthetic. Eventually, the power outweighed the cons. Anki abstracts away all the meta-work that I have to do, so I don&rsquo;t have to worry about balancing my cards, or about the Leitner system. I figured out how to theme and make Anki look pretty and shiny anyways, so that&rsquo;s fine. What matters is that I&rsquo;ve decided that Anki is a good experiment to try, at least for the time being, and that it&rsquo;s been quite comfortable and helpful to use.</p>
<p>In this post, I&rsquo;d like to talk about a couple SRS-related things I&rsquo;ve been thinking about at the moment. This might continue into a series as I continue to learn my way around Anki, but for now, here&rsquo;re my thoughts.</p>
<h2 id="the-glamourization-of-srs">The Glamourization of SRS</h2>
<p>I&rsquo;d like to inject a short interlude about SRS and the SRS community in general here - I think there&rsquo;s a lot of comparisons to be drawn here between Anki and #roamcult, and maybe the knowledge management community too. There&rsquo;s a lot of similarly passionate people, and people who&rsquo;ve kind of attached a large part of their identity to the app. There&rsquo;s absolutely nothing wrong with it - I guess people have an intrinsic desire to know and particularly magically know all the things they want to do. Anki is a bit of a stopgap to the be-all and end-all of understanding, and I think it has something to do with the idealization and romanticization of knowledge in general. Maybe this is because I&rsquo;ve been spending a decent amount of time in circles where discussing knowledge management is a normal and interesting thing to do, but I see that people keep trying to reinvent themselves and keep searching for the one silver bullet to their knowledge needs. And I suppose I&rsquo;ve succumbed to that a bit as well - look at my Zettelkasten series and the amount of time I spend tweaking my various configs in an attempt to become that student. However, I guess I&rsquo;ll just leave this in here - SRS is lightly glamourized. There&rsquo;s nothing wrong with that, but in my opinion, it is. Perhaps my opinion as to the magnitude of glorification will change as time goes on, and I, too, become An Anki User, but we&rsquo;ll see.</p>
<h2 id="a-diy-night-mode">A DIY Night Mode</h2>
<p>Something interesting I&rsquo;d like to also touch on is getting themes to work properly in Anki. One of the main issues I ran into when trying to set Anki up was getting my GTK theme to work with Anki night mode. I currently use <a href="https://github.com/ddnexus/equilux-theme">Equilux</a> as my GTK theme, which I really like for its flat grey design and nice integration with my boring, monochrome aesthetic. Anki, however, works on QT, which I&rsquo;m not entirely familiar with, but it&rsquo;s a different theming and development engine than GTK. Unfortunately, Anki night mode by default doesn&rsquo;t take the GTK theme as a QT theme, so I apparently had to do some <code>/etc/environment</code> magic to set <code>QT_QPA_PLATFORMTHEME</code> to <code>qt5ct</code> and within that, <code>gtk2</code>. Spoiler alert: Don&rsquo;t bother looking into that, because if your GTK theme is already a dark mode and you&rsquo;d prefer a night mode within Anki, it won&rsquo;t work out. It <em>does</em> work with light mode, but then the entire reviewing interface is by default light and blinding.</p>
<p>For example, below, that&rsquo;s Anki with night mode enabled, and with the ‘wrong’ theme. Interface elements are light on dark as desired.
<figure><img src="https://aws1.discourse-cdn.com/standard11/uploads/anki2/optimized/2X/5/53dcf9695c4f8ab399d2434d8b1c491f0e848dc6_2_690x197.png"
         alt="Figure 1. Anki: wrong GTK theme, right interface."/><figcaption>
            <p>Figure 1. Anki: wrong GTK theme, right interface.</p>
        </figcaption>
</figure>
</p>
<p>With night mode off (ignore that the Deck and New are white, I went and edited the CSS in /usr/lib/python3.9/site-packages/aqt/data/web/css/). Interface elements are dark on dark, but the correct theme applied.
<figure><img src="https://aws1.discourse-cdn.com/standard11/uploads/anki2/optimized/2X/0/05d87b1f60668003cb3c5d861dc3776c756ac58a_2_690x214.png"
         alt="Figure 2. Anki: right GTK theme, wrong interface."/><figcaption>
            <p>Figure 2. Anki: right GTK theme, wrong interface.</p>
        </figcaption>
</figure>
</p>
<p>What happens is that <a href="https://forums.ankiweb.net/t/toggling-night-mode-appears-to-change-qt-gtk-theme/14404">Anki uses their own QT theme</a> when night mode is toggled, since &ldquo;not all themes will work correctly with dark colors&rdquo;. Entirely fair, but that meant I had to do some serious CSS styling edits in order to simulate night mode within &lsquo;light mode&rsquo; Anki. To save you a lot of work, my edits to apply night mode colours (lightly edited to use Equilux colours where appropriate) to light mode Anki are available on my dotfiles, at <a href="https://github.com/kewbish/dotfiles">kewbish/dotfiles</a>. The key directories to look in are <code>/usr/lib/python3.9/site-packages/aqt/data/web/</code>, and <code>~/.local/share/Anki2/addons21</code>, if you want to edit any addons. This might differ due to installation method (I used <code>anki-bin</code> from the AUR), but this is what worked for me.</p>
<p>A more universal fix is creating an addon in the <code>~/.local/share/Anki2/addons21</code> directory, which is as easy as making a directory and creating an <code>__init__.py</code>. Alternatively, edit an existing addon. As long as you include:</p>
<pre tabindex="0"><code>from aqt import mw
from PyQt5.Qt import QStyleFactory

mw.app.setStyle(QStyleFactory.create(&quot;gtk2&quot;))
</code></pre><p>somewhere, you&rsquo;ll correctly force the GTK theme into any theme of Anki. This way, you can switch to dark mode within the Anki settings, as well as using a proper GTK theme that integrates with the rest of your desktop environment.</p>
<h2 id="my-settings">My Settings</h2>
<p>I don&rsquo;t think I really did much research as to what settings were idea for use with Anki - my config at the moment is some mix of <a href="https://chuff.wordpress.com/2018/01/08/article-how-to-use-anki-as-a-leitner-box-game/">this Anki Leitner setup</a> and the <a href="https://refold.la/roadmap/stage-1/a/anki-setup#Low-key-Anki">Lowkey Anki setup</a>. The two things I knew going into configuration was that I somewhat unconventionally wanted to partially integrate the <a href="https://ncase.me/remember/">Leitner system</a> in my learning steps, and that I wanted a Quizlet-like pass / fail option. Yes, people have gone on about how you should just trust the algorithm (à la the natural recursion), and how it&rsquo;s not really that much cognitive friction and that it really helps with the ease settings and how cards are tuned to your level of memory. But I don&rsquo;t like it - I now have to build a mental model of what differentiates hard from good cards, and likewise for good / easy, again / hard. This might be something I revisit later on in my SRS journey, but I&rsquo;d rather keep things simple and close to the softwares I&rsquo;ve used in the past for now.</p>
<p>I have my settings at 20 new cards a day - a bit much for now, but I&rsquo;d like to quickly get back up to pace with some of my class cards. I&rsquo;ve set my learning steps to <code>1d 2d 4d 8d 16d 32d</code>, which might seem inordinately long for the quick <code>5m 25m 1440m</code> people, but I&rsquo;ve found the Leitner system works quite well for me, so I kept it. My graduating and easy intervals are both at 32d, and my insertion order&rsquo;s random. Similarly to the &lsquo;harsh&rsquo; Leitner system, I have my lapses at 1d with a minimum interval of 1d. My leech threshold&rsquo;s at 8, and I&rsquo;ve set this to tag only. It&rsquo;ll be some time before I even get all my cards out of learning, but I hope that this&rsquo;ll work well enough for me. I bury related siblings and review siblings, which reduces redundant review time. My maximum interval&rsquo;s at 100 years, which is a bit long now that I think about it, but oh well. My starting ease is where it starts to get interesting - I&rsquo;ve set it to 2.50, with my easy bonus, interval modifier, and hard interval all at 1.00. This essentially disables the easy and hard buttons, which is nice, since I can&rsquo;t see them visually anyway.</p>
<p>Speaking of the pass / fail setup proposed by Refold&rsquo;s Lowkey Anki, I use this <a href="https://github.com/lambdadog/passfail2">Pass Fail addon</a>, updated for use with Anki 2.1. I resonate with the goals of the addon, and so far, I&rsquo;d say I definitely recommend it. Keep in mind that this all is just a snapshot for future reference, and that I&rsquo;m still very much tweaking everything around.</p>
<h2 id="conclusion">Conclusion</h2>
<p>With Anki, I&rsquo;m looking forward to learning more fluently, and taking away the friction of review. I like that I have one place to return to and one place to manage all the things I should review now, and that that one place is something I can turn to daily. I think this daily habit, while much less focused than specific sprints every other couple days, is more sustainable in maintaining and always brushing up on knowledge. I&rsquo;m still figuring out how to best use Anki to recall and more deeply learn new information. I&rsquo;d like to find, for example, a way to review cards in advance without them piling up in the future. I know I can custom study and toggle off the &rsquo;re-date cards' or whatever, but I think my purpose right now is trying to get ahead of reviews, so I don&rsquo;t think there&rsquo;s really a way to review without pushing more cards together in the future. As well, I&rsquo;d like to learn the card and note management windows better. As of now, I&rsquo;ve just figured out how to do what I need to do (which, prior to <a href="https://ankiweb.net/shared/info/385888438">Edit Field During Review (Cloze)</a> was just editing cards and tagging them), and haven&rsquo;t explored much else. Maybe that&rsquo;s alright - maybe I shouldn&rsquo;t overcomplicate things for myself before I&rsquo;ve even gotten started.</p>
<p>In other news, I&rsquo;m currently in the process of overly studying for midterm wave number two. I&rsquo;m glad that I made it through the first wave, and while I&rsquo;m not too ecstatic about some of what I&rsquo;ve been able to do, I&rsquo;ve learned a couple lessons that I&rsquo;ll try to apply in the future. It is what it is. As well, I&rsquo;ve been meaning to start looking into internships and applying to some, but I feel like I&rsquo;ve hit a wall. The imposter syndrome, particularly with the interview side of things, is definitely kicking in. I don&rsquo;t know how I feel describing myself as a &lsquo;web developer&rsquo; while looking at some of those DSA questions, or even web framework questions, and not really having a clue with how to approach them. But it&rsquo;s something that I&rsquo;ve also decided that I need to work on, so I&rsquo;m looking into that CS handbook<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> and trying to figure out a way to systematically learn and improve.</p>
<p>As well, I&rsquo;ve been working through <a href="https://fullstackopen.com/">Full Stack Open</a>, which is an open source course about web development, and React / Typescript / Express / MongoDB in particular. I&rsquo;ve realized that I&rsquo;ve kind of let my Vue experience go a bit, and that, looking through interviews and such, people tend to look for React more. I&rsquo;ve never really systematically learned any part of web development, and I think FSO has been a good introduction to this whole curriculum thing. It also helps that Typescript and the React design patterns are topics that I&rsquo;ve never really covered before. Part of what makes me demotivated and pushes me to stop working on something is that I feel that I know half of whatever a course is teaching, but I don&rsquo;t know the other half: I end up skimming most of the material, and retain not a lot of new information. I&rsquo;m on the third module at the moment, and while I don&rsquo;t have a lot of time to tackle their exercises, I do really enjoy the examples they&rsquo;ve set up and how the problems apply the material super well. I&rsquo;ve found working through the course really informative and honestly fun, and would recommend the course so far. I&rsquo;m excited to see what the rest of the course ends up being like, and hopefully, I&rsquo;ll report back with more progress soon.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Ironically, I very vividly remember making fun of my friends for printing out their own copy and putting it together into a binder and reading it every chance they got in class. At this point, <em>I&rsquo;ve</em> become that kid, but hey, maybe I should have listened to their CS fanboy ramblings the first time around.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>More Linux Tweaks</title>
      <link>https://kewbi.sh/blog/posts/211003/</link>
      <pubDate>03 Oct 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On troubleshooting many Linux-related issues.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>It&rsquo;s been a while since I had the time to write anything for YK - I&rsquo;ve been getting settled into the quintessential university freshman experience at UBC, and loving it so far. Every upper-year I meet keeps telling me about the rose-coloured glasses apparently all freshmen have, with something along the lines of &lsquo;well, I hope you can keep that mindset up!&rsquo;. It&rsquo;s not particularly encouraging, but to be fair, I&rsquo;ve only been here a month, and haven&rsquo;t had any major quizzes or midterms yet, so maybe I do still have my pink spectacles quite firmly on. More on this some other time: this isn&rsquo;t some university reflection, after all, it&rsquo;s a tech blog!</p>
<p>So, in other news, I got a new laptop, and have been juggling close readings and annotations with setting it up. I&rsquo;ve finally got everything installed and configured to my liking, however, so I thought I&rsquo;d write a bit about the process of getting everything together, similar to my <a href="https://kewbi.sh/blog/posts/210711/">previous one about my monitor and Bluetooth setup</a>. While I was able to follow my past notes for display and Bluetooth configuration, I encountered my fair share of struggles along the way. It&rsquo;s just mostly stuff I&rsquo;d set up on my old laptop but without writing notes about how I got myself through the messes in the first place, I had no idea where to go this time round. However, I managed to work things out, very slowly and steadily, and I&rsquo;m now writing this very post with my new setup.</p>
<p>Some specs:</p>
<ul>
<li>It&rsquo;s the Lenovo Yoga 7 14ITL5 - got it off Best Buy for a half decent deal.</li>
<li>It&rsquo;s got a 11th Gen Intel i7-1165G7, with 8 cores, Intel Iris Xe graphics, a very nice 16GB of RAM that I didn&rsquo;t even have to dismantle the chassis for, and 1TB of NVMe SSD. It&rsquo;s currently running 5.13.19-2MANJARO, and everything (minus fingerprint reader and sound) works really well.</li>
<li>One of the immediate improvements over my old laptop (well, besides weight) is how quickly it boots and runs things. My old laptop had to go for at least half a minute to boot up, which was certainly an annoyance when it&rsquo;d suddenly crash in the middle of Zoom class. Granted, it had to go through Grub and a shabbily patched together Windows dual boot configuration, but this laptop is so much quicker. It boots from completely shut down in what I can perceive to be a second or two, which is crazy fast compared to my past habits of staring blankly at a HP loading circle for ages.</li>
<li>Speaking of weight, the laptop&rsquo;s quite thin and light, something I appreciate when I have other binders and things to shove in my bag. It&rsquo;s about half a kg lighter than my old laptop, which isn&rsquo;t entirely much, but it makes a nice difference that I value.</li>
<li>The battery life&rsquo;s also pretty amazing - the first time I took this laptop to school, I hadn&rsquo;t yet ordered a second charger cable, and my packaged one was still at home. It managed to churn through three hours of Zoom meetings, and three hours of a physics lab, all while still having a good 30% left. It&rsquo;s amazing what this 71Wh battery can do - it can definitely hold tonnes more than my old 38Wh.</li>
<li>Something else I really like about the laptop so far is that I have one (1!) cable to plug in when I get home. I have my power, monitor, printer, webcam and various other little cables all hooked into a singular USB-C hub, which then plugs right into my laptop. I used to have to plug each individual cable in, and because each port was on different sides of my old HP, it was a bit of a mess, visually. This does present the problem of always having to be charging the laptop if I want to use my monitor, but it&rsquo;s somehow configured itself to only charge when not full, and then run off what I assume is AC after that.</li>
<li>And it looks amazingly cute - I&rsquo;m not usually one to fuss over the colour of laptops, but it&rsquo;s just such a <em>nice</em> slate grey.</li>
</ul>
<p>Overall, definitely a big improvement over my old HP, and very grateful I&rsquo;m able to have a better machine.</p>
<p>Similarly to my other Linux-setup-tweaks post, this article will cover a bunch of my troubleshooting, thought processes, and eventual solutions to my various issues: getting my printer drivers working, fixing screen tearing, duplicating Chrome history and passwords, tweaking fonts, and more. This is mostly to keep a record for myself of all the little problems that I&rsquo;ve had, just in case I have to reinstall or do this all over again for some other machine. I don&rsquo;t think this post&rsquo;ll be of much use if you don&rsquo;t have the exact same model of laptop, but maybe some of the more general tweaks, like for fonts and such, will help someone out there. Throughout this guide, I assume you&rsquo;ll be running Manjaro or some Arch relative, and have a basic knowledge of how to run commands and install packages - I&rsquo;ll only be going into what I did to fix my issues, so you&rsquo;ll have to look at more general advice elsewhere.</p>
<h2 id="cups-and-printing">CUPS and Printing</h2>
<p>I&rsquo;m going go start with CUPS troubleshooting first, because I went through a whole struggle to set up my printer. I specifically have the Brother-MFC7340 laser printer, which is a rather old black and white model that comes without any of the fancy modern QoL features like double sided printing or wireless connections. It even has a fax - that&rsquo;s how old it is. But Brother does a pretty decent job of keeping their drivers backward compatible and up to date, even for older models like mine, so I thought I&rsquo;d have a pretty easy time at it here. I installed <a href="https://github.com/OpenPrinting/cups">cups</a>, and trawled the internet a bit for the Brother driver I thought would work, which ended up being <a href="https://aur.archlinux.org/packages/brother-mfc7340/">this one (brother-mfc7340)</a> on the AUR. Spoiler alert: it doesn&rsquo;t work.</p>
<p>I tried uninstalling sane, disabling usblp, and manually editing PPD files, all things listed in the <a href="https://wiki.archlinux.org/title/CUPS">Arch Wiki</a> troubleshooting page. Long story short - the driver doesn&rsquo;t work, wasn&rsquo;t the one I thought I had installed on my old laptop, and you shouldn&rsquo;t bother trying any of the above. Instead, install <a href="https://github.com/pdewacht/brlaser">brlaser</a> from the AUR, and set up your printers to use that driver instead. I&rsquo;m not going to go into the specifics of how to set printers up, but know that you&rsquo;ll have to select something like &lsquo;Brother MFC7360N&rsquo; instead of MFC7340. It&rsquo;s not an exact model match, but it works perfectly fine for me, so I&rsquo;m not going to ask questions.</p>
<p>An aside: to configure scanning properly, you&rsquo;ll have to install <a href="https://aur.archlinux.org/packages/brscan3/">brscan3</a>, or install brother-mfc7340 as above. Then, install <code>simple-scan</code> or another scanning tool, which should automatically register your printer / scanner combo.</p>
<h2 id="screen-tearing">Screen Tearing</h2>
<p>When madly scrolling through tonnes of forum pages in an attempt to resolve the above CUPS issue, I also encountered a bunch of screen tearing issues. I&rsquo;m running Chrome<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, and found that without hardware acceleration on (which for some reason, didn&rsquo;t work properly in Chromium) and another fix I&rsquo;ll detail below, I had pretty significant screen tearing while scrolling. It wasn&rsquo;t anything too severe, but annoying to notice when trying to read pages and scroll nicely.</p>
<p>What got my screen to stop tearing was, for one, enabling hardware acceleration in Chrome settings (see chrome://settings), and messing around with Intel graphics files.
I created <code>/usr/share/X11/xorg.conf.d/20-intel.conf</code>, and put the following in it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">Section &#34;Device&#34;
  Identifier  &#34;Intel Graphics&#34;
  Driver      &#34;intel&#34;
  Option      &#34;AccelMethod&#34;  &#34;sna&#34;
  Option      &#34;TearFree&#34;     &#34;true&#34;
EndSection
</code></pre></div><p>When I rebooted, the boot was getting stuck at &lsquo;/dev/[something] clean, &hellip; files, &hellip; blocks&rsquo;, so I thought I&rsquo;d have to start over and reinstall my system again. But don&rsquo;t panic - hit <!-- raw HTML omitted -->CTRL<!-- raw HTML omitted -->-<!-- raw HTML omitted -->ALT<!-- raw HTML omitted -->-<!-- raw HTML omitted -->F2<!-- raw HTML omitted --> to get into a recovery terminal. From here, you can either <code>pacman -Syu</code> and see if that fixes it; or, as that didn&rsquo;t work in my case, run <code>sudo mhwd -f -i pci video-linux</code>, which did some scary things for a while and then popped me back into my login screen. The above command is the equivalent of <code>sudo mhwd -r pci video-linux</code> followed by <code>sudo mhwd -i pci video-linux</code>, if that helps.</p>
<h2 id="retracing-history">Retracing History</h2>
<p>It turns out Chrome conveniently stores all of its data in <code>~/.config/google-chrome/</code>. Most of what you&rsquo;ll want will be in the <code>~/.config/google-chrome/Default/</code> directory, which is home to the History, Cookies, Extension Cookies, and Shortcuts databases. I&rsquo;m going to be honest - I don&rsquo;t entirely know which have carryover effects and which don&rsquo;t, but I essentially copy-pasted all the databases I could find to my new laptop. This let me retain my history, but I still had to log into each website and refresh cookies where necessary on my own. Note that the Extensions directories don&rsquo;t appear to do anything - I thought that this would copy over all of my extensions, but alas, I had to do that manually as well, which is surprising, since the directory contains what appears to be the raw extension files.</p>
<p>Speaking of logins, I&rsquo;ve saved most of my passwords into the Chrome password manager (not very secure, I know), and wanted to transfer those over as well<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>. On my origin / old laptop, I went into <code>chrome://settings/passwords</code>, and clicked the hamburger menu near Saved Passwords. This let me export all my passwords into a very dangerous, unencrypted CSV. Try not to let anyone get access to that. On my new installation, I went to <code>chrome://flags</code>, and searched for and enabled Password Import. Navigate back to the <code>chrome://settings/passwords</code> page, and it&rsquo;ll let you import a whole bunch of passwords in the same menu.</p>
<p>Also, a cute tip if you, like me, enable login to Gmail without login to Chrome but still want a custom profile pic in Chrome: click on your profile, click edit, and select some other profile pic. This&rsquo;ll spit out the photo in <code>~/.config/google-chrome/Avatars/</code>. Take whatever photo you want to use as a profile pic, rename it to whatever&rsquo;s in the Avatars directory, and replace the Chrome avatar with your custom pic.</p>
<h2 id="font-tweaking">Font Tweaking</h2>
<p>I had two major font tweaks to do - one with my preferred emoji font, and one with my type hinting in LibreOffice.</p>
<p>First, the emojis. I prefer to use <a href="https://twemoji.twitter.com/">Twemoji</a>, which is Twitter&rsquo;s custom emoji font - also the same one used in Discord. I like how round and flat and cohesive it is, but maybe that&rsquo;s just an acquired taste from spending much too long on Discord. Regardless, to make Twemoji work at a baseline level, you&rsquo;ll have to install <a href="https://aur.archlinux.org/packages/ttf-twemoji/">ttf-twemoji</a>. There&rsquo;s another package, <a href="https://aur.archlinux.org/packages/ttf-twemoji-color">ttf-twemoji-color</a>, that provides the colour version of the font, as well as the B&amp;W files. However, Chrome apparently doesn&rsquo;t have full support for SVG colour by default, and the colour version wasn&rsquo;t appearing in other apps like my terminal. So, I had to do some finagling, and install <a href="https://archlinux.org/packages/ttf-bitstream-vera">ttf-bitstream-vera</a>, <em>then</em> ttf-twemoji-color. Finally, I had to create <code>~/.config/fontconfig/fonts.conf</code>, and put the following inside:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">&lt;fontconfig&gt;
  &lt;alias&gt;
    &lt;family&gt;serif&lt;/family&gt;
    &lt;prefer&gt;
      &lt;family&gt;Twemoji Color&lt;/family&gt;
    &lt;/prefer&gt;
  &lt;/alias&gt;
  &lt;alias&gt;
    &lt;family&gt;sans-serif&lt;/family&gt;
    &lt;prefer&gt;
      &lt;family&gt;Twemoji Color&lt;/family&gt;
    &lt;/prefer&gt;
  &lt;/alias&gt;
  &lt;alias&gt;
    &lt;family&gt;monospace&lt;/family&gt;
    &lt;prefer&gt;
      &lt;family&gt;Twemoji Color&lt;/family&gt;
    &lt;/prefer&gt;
  &lt;/alias&gt;
  &lt;alias&gt;
    &lt;family&gt;Apple Color Emoji&lt;/family&gt;
    &lt;prefer&gt;
      &lt;family&gt;Twemoji Color&lt;/family&gt;
    &lt;/prefer&gt;
  &lt;/alias&gt;
&lt;/fontconfig&gt;
</code></pre></div><p>Run <code>fc-cache -f -v</code> to clear the font cache, log out and back in for good measure, and you should be graced with some very quirky, iconic emojis.</p>
<p>I also had a small problem with <a href="https://aur.archlinux.org/packages/ttf-ms-fonts">ttf-ms-fonts</a>, which is a package that includes all the default Windows fonts, like Times New Roman. I&rsquo;m required to use it for school, so I&rsquo;d have to be staring at it quite regularly. A pity then, that LibreOffice wasn&rsquo;t displaying it properly - it was a bit too short and compressed, and there were some spacing issues that came up occasionally. So, I had to further edit my <code>fonts.conf</code>, and add some bitmap edits:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">&lt;match target=&#34;font&#34;&gt;
	&lt;edit name=&#34;embeddedbitmap&#34; mode=&#34;assign&#34;&gt;
		&lt;bool&gt;false&lt;/bool&gt;
	&lt;/edit&gt;
&lt;/match&gt;
</code></pre></div><p>Put this inside the <code>&lt;fontconfig&gt;</code> tag, and run <code>fc-cache -f -v</code> again.</p>
<p>The final <code>~/.config/fontconfig/fonts.conf</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">&lt;fontconfig&gt;
  &lt;alias&gt;
    &lt;family&gt;serif&lt;/family&gt;
    &lt;prefer&gt;
      &lt;family&gt;Twemoji Color&lt;/family&gt;
    &lt;/prefer&gt;
  &lt;/alias&gt;
  &lt;alias&gt;
    &lt;family&gt;sans-serif&lt;/family&gt;
    &lt;prefer&gt;
      &lt;family&gt;Twemoji Color&lt;/family&gt;
    &lt;/prefer&gt;
  &lt;/alias&gt;
  &lt;alias&gt;
    &lt;family&gt;monospace&lt;/family&gt;
    &lt;prefer&gt;
      &lt;family&gt;Twemoji Color&lt;/family&gt;
    &lt;/prefer&gt;
  &lt;/alias&gt;
  &lt;alias&gt;
    &lt;family&gt;Apple Color Emoji&lt;/family&gt;
    &lt;prefer&gt;
      &lt;family&gt;Twemoji Color&lt;/family&gt;
    &lt;/prefer&gt;
  &lt;/alias&gt;
    &lt;match target=&#34;font&#34;&gt;
        &lt;edit name=&#34;embeddedbitmap&#34; mode=&#34;assign&#34;&gt;
            &lt;bool&gt;false&lt;/bool&gt;
        &lt;/edit&gt;
    &lt;/match&gt;
&lt;/fontconfig&gt;
</code></pre></div><h2 id="and-finally-sync">And, Finally, Sync</h2>
<p>No actual problems here - I&rsquo;d just like to keep a note of the rsync command I use to back things up for further reference:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">rsync -r --info=progress2 --exclude=.git --exclude=node_modules --exclude=archive --exclude=&#34;*.mp4&#34; /home/kewbish/Downloads/dev/* /media/kewbish/Seagate\ Basic/dev/
</code></pre></div><h2 id="conclusion">Conclusion</h2>
<p>Every time I set up a laptop, or break something and need to fix it, I&rsquo;ve realized that even though there&rsquo;ll inevitably be trials and tribulations, I end up learning a lot - not just about how to fix said bugs, but in general how computers work. The first time I installed Linux, I had to learn about dual booting, what partitions even were, and how to make partition schemes, and port all my hacky Windows experience over into a whole new world of Unix. When I was trying to troubleshoot my monitor last time, I learned a whole lot about displays and profiles, and likewise when I sorted out my Bluetooth connections. These processes of constantly breaking, then fixing and learning, are what&rsquo;s kind of fun about Linux. Sure, you won&rsquo;t ever have to run into major issues on Windows (as long as you don&rsquo;t do anything too crazy), but it ends up abstracting all the interesting system files and configurations away from the user. Sometimes diving into the <code>/etc/</code> or <code>/usr/</code> directories can lead to a whole lot of research and fun findings - that&rsquo;s why I still bodge my way through Linux, even though I&rsquo;ve been &lsquo;haha linux kid&rsquo;ed so many times.</p>
<p>There&rsquo;s still some things that refuse to work - the fingerprint scanner, and the speakers, for some reason, are either not supported on Linux, or require some <a href="https://bugzilla.kernel.org/show_bug.cgi?id=208555">complicated kernel patches</a> that for the sake of my sanity I don&rsquo;t think I&rsquo;ll attempt. As well, now comes the process of wiping my old HP and figuring out how to reinstall Windows, and then handing it off to a family member. I also need to sort out some small little config problems here and there, but I don&rsquo;t run into them enough to bother. For the most part, what I need to work works fine: I wasn&rsquo;t planning on using the scanner, I have headphones or earbuds for when I need audio, and my programming environment works pretty much identically to my HP anyways. It&rsquo;s good that I managed to set everything up so quickly - I don&rsquo;t have to tote around such a bulky laptop anymore, and the extra battery life&rsquo;s definitely a boon for uni.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The Googled one, as I found Chromium was a bit buggy in some respects, such as not letting me sign into my Gmail because the &lsquo;browser was insecure&rsquo;, and also not letting me save my passwords properly. I haven&rsquo;t found any performance differences, and to be honest, I&rsquo;m okay with not crusading the whole privacy narrative if I&rsquo;ll be able to check my bloody email.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>I never got around to enabling and really using Google Account sync, which apparently takes all your locally saved passwords and associates them with your Google Account instead. This has the added benefit of syncing extensions as well - something that would have been nice to maintain my preferences from. Having sync enabled makes switching installations and machines a lot easier, but I don&rsquo;t know if I want to bother.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
    <item>
      <title>The Process Matters</title>
      <link>https://kewbi.sh/blog/posts/210905/</link>
      <pubDate>05 Sep 2021</pubDate>
      <author>Emilie Ma ◦ Kewbish</author>
      <description>On the journey as an end, not a means.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I feel like I start a lot of these blog posts with stories from when I was little, but here&rsquo;s another: when I was in elementary school, I used to be fascinated by stop-motion animation<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. A very niche thing to be into - but then again, aren&rsquo;t all my hobbies? I watched hours of <a href="https://en.wikipedia.org/wiki/Shaun_the_Sheep">Shawn the Sheep</a>, some of the <a href="https://en.wikipedia.org/wiki/Wallace_and_Gromit">Wallace and Gromit</a> shorts, and tonnes of the little claymation (stop-animations created with clay) shorts on YouTube. I didn&rsquo;t have the access to, or the patience for, the extensive sets and equipment used by professional studios, so I settled for tinkering with my little Lego Friends sets. There was a book at my favourite library branch called <a href="https://www.amazon.ca/Brick-Flicks-Comprehensive-Making-Stop-Motion/dp/1629146498">Brick Flicks</a> that I must have read and reread cover to cover at least a couple times. I made some half decent animations in Windows Movie Maker (the old version packaged with Windows 7, if that means anything to you) just by importing hundreds of photos taken on the family point and shoot, and setting the duration of the slideshow as something like 0.05 seconds. All of a sudden, I could weave together stories about whatever took place in my imagination and act them out with little plastic people - it was nothing short of magical.</p>
<p>Stop motion&rsquo;s a pretty labour-intensive undertaking: each picture has to be lined up almost perfectly with the next, and each tiny movement has to be painstakingly planned. But that&rsquo;s if you&rsquo;re going for a good quality animation - and to be honest, grade-school-me was just looking for hours of free endless entertainment and maybe even a half-decent product at the end. I enjoyed the process of bodging together a camera mount and kneeling at the coffee table fiddling with arms and heads more than the end result, though my &lsquo;movies&rsquo; weren&rsquo;t that terrible either. Interestingly enough, there&rsquo;s a whole genre of behind-the-scenes videos for these stop-motion productions, especially from larger firms who not only film the actual series but also film the making-of. Just Google &lsquo;behind the scenes of [x show]&rsquo; - you&rsquo;ll get tonnes of results. I remember Wallace and Gromit had some interesting ones, as well as the franchise that did Coraline and Kubo - I think it was <a href="https://www.laika.com/">Laika</a>. I was enthralled by hours of BTS footage: I found it incredibly interesting how artists pieced minute movements into full-on action sequences into the final product.</p>
<p>This interest in behind-the-scenes continued throughout the rest of my phases: when I got into electronics and went through my pseudo-engineer stage, I binged <a href="https://www.youtube.com/user/jimmydiresta">Diresta</a>, <a href="https://www.youtube.com/c/Iliketomakestuff">ILTMS</a>, and <a href="https://www.youtube.com/channel/UCiDJtJKMICpb9B1qf7qjEOA">Tested</a>, among other channels. When I got into game development, I loved watching devlogs, getting way too interested in the technical details of whatever new features my favourite developers were working on. These devlogs were posted on a semi-regular schedule, so I had solid chunks of weekly entertainment, and a consistent stream of content. With my more creative interests - like bullet journalling - I turned to the numerous &lsquo;with me&rsquo;s on the Internet. There were &lsquo;plan with me&rsquo;s, &lsquo;paint with me&rsquo;s, &lsquo;Notion with me&rsquo;s, &lsquo;organize with me&rsquo;s, &lsquo;study with me&rsquo;s, &lsquo;bookbind with me&rsquo;s, and a whole other set of para-collaborative videos.</p>
<p>What ties all these things together - what ties all these &lsquo;with me&rsquo;s, behind-the-scenes cuts, and b/v/dev-logs together? Well, the process - the process of creation, development, and innovation. For little me, being able to watch the evolution of amazing large-scale projects I&rsquo;d never have the time, resources, or patience to carry out was like living vicariously through others. It was a sort of motivation and companionship as I tinkered away at my own work. As I look back, it&rsquo;s kind of interesting to note that I always preferred to watch the behind-the-scenes footage and to observe the journey, rather than to watch and marvel the end product. I think there&rsquo;s a reason for that, and I&rsquo;ve been trying to figure out what that reason exactly is.</p>
<p>I haven&rsquo;t quite got all the way there yet, but this is a thought-chain of untangling intrinsic motivations, justifying things I probably don&rsquo;t need to justify, and, most of all: trusting the process.</p>
<h2 id="from-consumption-to-creation">From Consumption To Creation</h2>
<p>I&rsquo;ve set my bio on pretty much all my social media as some variation of &lsquo;work in progress, trust the process&rsquo;. The &lsquo;process&rsquo;, to me, is the doing of things for the sole purpose of doing them, and maybe focusing a bit less on the end result. Maybe I find more enjoyment in just doing things for the sake of doing them, or in watching the development of something instead of taking an interest in what exactly they&rsquo;re making. It&rsquo;s true for a lot of the more conventionally &lsquo;less practical&rsquo; things like sketching in a bullet journal or trying a new recipe - hobbies or pursuits whose pursuits fulfill you more than what you end up creating.</p>
<p>On the topic of creation - I&rsquo;ve realized that I&rsquo;ve gone more from watching stuff about the process (spending hours scrolling through the latest devlogs - I don&rsquo;t want to talk about the amount of YouTube I watched as a kid) into participating in it myself (some of the more creative hobbies I&rsquo;ve been trying to explore this past summer). Even as I write this blog - I think I enjoy the process of writing these thought-chains down, than the end result, which I simply leave for future me to cringe at a couple months down the line.</p>
<p>Maybe some people&rsquo;s creations are fueled more by the goal, but for me it&rsquo;s always been more or less about the process - but I feel like this summer, and this past year, I&rsquo;ve been tending towards it even more. It&rsquo;s not always true for aspects of my life like academics, but maybe I should take some of my own advice and shift towards a more process-focused mindset for that as well. I&rsquo;ve been finding joy in just making stuff - I generally have no idea what I&rsquo;m ever going to do with the end products of my diversions, but I like that hobbies, and things beside tech, take my mind off what I&rsquo;m normally thinking about. When I bake or bookbind or obsessively doodle in my journal, the end product isn&rsquo;t really the goal - yet it also is, in a way, since it&rsquo;s a by-product of the process.</p>
<h2 id="software-for-its-own-sake">Software For Its Own Sake</h2>
<p>Tying all this back into development, I guess I&rsquo;d like to think more about developing software for its own sake. This goes back into a bunch of the ideas I&rsquo;ve had regarding <a href="https://kewbi.sh/blog/posts/210124/">hyperpersonalized</a> software, and what I want to end up creating, maybe even as a career. Often, the more whimsical, what-the-hell, why-not projcets are those that are explored for the journey and the process itself, not just practicality. Those projects are the ones that draw me in - I don&rsquo;t think figuring out web monetization and musing about the metadata possibilities of the web are going to cure cancer or figure into some magical, big-bucks data analysis, and that&rsquo;s fine. I want to build software and tools that I can personally learn from the development of, and enjoy the process of creating. If I&rsquo;m going to be honest, I don&rsquo;t think that those projects&rsquo;ll end up being another pixel-perfect Instagram clone complete with a well-documented REST API to pad my GitHub with.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Still, I don&rsquo;t think I&rsquo;ll ever be able to completely reject the slightly cynical and more pragmatic viewpoint that I&rsquo;ve been working with all this time. This post ended up being me trying to convince myself that accepting some things won&rsquo;t end up being all that practical is natural - and I think that&rsquo;s something I&rsquo;ll be working on for the next while. I&rsquo;d like to tend towards, yes, specifically targetting certain goals, but also enjoying the process. That takes trust in yourself, since you&rsquo;ll be building that process while also striving towards whatever you&rsquo;ve set as an aim. Right now, the more &lsquo;for the process&rsquo;y things I&rsquo;m doing, or have been thinking about, are developing some little TUI tools for personal productivity, and messing with my digital workflows. There&rsquo;s also been a lot of yak-shaving as well - I&rsquo;ve been writing a bunch of small wrapper scripts to automate tiny parts of my workflow - stuff that&rsquo;s not particularly impressive or typically &lsquo;useful&rsquo;, but that I find fun.</p>
<p>This&rsquo;ll be the last article I publish before I properly start UBC. I&rsquo;m honestly quite excited for this whole new fresh start, and most of the worries and concerns I have about the transition, is, I think, a result of having too much time and reflection on starting UBC, and not enough actually <em>starting</em> UBC. The anticipation&rsquo;ll be over soon - at the time of publishing, it&rsquo;ll be a couple days before I have my orientation right before all classes start. I hope to still be able to post somewhat frequently here, especially as I gain new perspectives and consider new ideas from whatever I&rsquo;ll be learning and diving into then. It&rsquo;s been nice to have this space to share my thoughts and work out what I genuinely think about some ideas in tech (see the Zettelkasten mentions and hyperpersonalization threads) - and hey, productive procrastination between assignments is always welcome.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>For a primer on what stop-motion is, individual pictures of various subjects are stitched together with a short frame-rate to create an illusion of movement. It operates on the same principle as the little flipbooks you might&rsquo;ve made or heard of as a kid - each picture contains small differences from the previous shot, thereby making it seem like whatever&rsquo;s in the photos is moving. A bunch of different mediums are used: clay is popular as it&rsquo;s sculptible and very tactile, and so are action figures (including Lego). Anything can really be used, including actual people, everyday objects, and creative paintings, textile art, and more.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
